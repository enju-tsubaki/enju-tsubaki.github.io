<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Coisini</title>
  
  <subtitle>一見旧知のようです、万千の歓喜心が生まれます</subtitle>
  <link href="https://www.enju-tsubaki.icu/atom.xml" rel="self"/>
  
  <link href="https://www.enju-tsubaki.icu/"/>
  <updated>2025-02-10T04:55:02.199Z</updated>
  <id>https://www.enju-tsubaki.icu/</id>
  
  <author>
    <name>Coisini</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hello World</title>
    <link href="https://www.enju-tsubaki.icu/posts/3610a686.html"/>
    <id>https://www.enju-tsubaki.icu/posts/3610a686.html</id>
    <published>2025-02-25T07:26:59.264Z</published>
    <updated>2025-02-10T04:55:02.199Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>🌟 <strong>简单的自我介绍</strong></p><p>大家好，我是 Coisini，来自古城西安，是陕西理工大学数计学院人工智能专业的学生。</p><p>🚀 <strong>编程的目标方向</strong></p><p>我对编程充满热情，尤其专注于人工智能领域的研究与应用，致力于探索机器学习和深度学习算法的潜力。通过结合Spring Boot框架，我能够快速构建稳定的应用程序，为AI算法的实际部署提供强有力的支持。利用MyBatis简化数据库操作，使我更专注于业务逻辑优化和算法实现，而Maven则帮助我高效管理项目依赖和构建过程，使开发更加流畅。每次攻克技术难题、掌握新概念，都让我感到极大的满足与成就，力求在AI技术的研究与实践中不断前进。</p><p>🌱 <strong>未来的学习方向</strong></p><p>在这个快速发展的时代，我立志于紧跟人工智能领域的前沿趋势，深入学习并掌握一系列关键技术，包括但不限于DeepSeek、Cursor、Dify、工作流、智能体以及知识库等。这些技术代表了当前AI技术发展的重要方向，它们不仅能够提升我的专业技能，也为解决复杂问题提供了新的思路和工具。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="个人简介" scheme="https://www.enju-tsubaki.icu/categories/%E4%B8%AA%E4%BA%BA%E7%AE%80%E4%BB%8B/"/>
    
    <category term="编程学习" scheme="https://www.enju-tsubaki.icu/categories/%E4%B8%AA%E4%BA%BA%E7%AE%80%E4%BB%8B/%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="人工智能" scheme="https://www.enju-tsubaki.icu/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="机器学习" scheme="https://www.enju-tsubaki.icu/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="https://www.enju-tsubaki.icu/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="SpringBoot" scheme="https://www.enju-tsubaki.icu/tags/SpringBoot/"/>
    
  </entry>
  
  <entry>
    <title>线性回归</title>
    <link href="https://www.enju-tsubaki.icu/posts/40997091.html"/>
    <id>https://www.enju-tsubaki.icu/posts/40997091.html</id>
    <published>2025-02-25T06:59:50.722Z</published>
    <updated>2025-02-25T06:59:51.841Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🎈2-1-线性回归简介"><a href="#🎈2-1-线性回归简介" class="headerlink" title="🎈2.1 线性回归简介"></a>🎈2.1 线性回归简介</h1><h2 id="🌟学习目标"><a href="#🌟学习目标" class="headerlink" title="🌟学习目标"></a>🌟学习目标</h2><ul><li>了解线性回归的应用场景</li><li>知道线性回归的定义</li></ul><h2 id="🏠线性回归应用场景"><a href="#🏠线性回归应用场景" class="headerlink" title="🏠线性回归应用场景"></a>🏠线性回归应用场景</h2><ul><li>房价预测</li><li>销售额度预测</li><li>贷款额度预测</li></ul><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.png" alt="Alt text"></p><h2 id="🔍2-什么是线性回归"><a href="#🔍2-什么是线性回归" class="headerlink" title="🔍2 什么是线性回归"></a>🔍2 什么是线性回归</h2><h3 id="📄2-1-定义与公式"><a href="#📄2-1-定义与公式" class="headerlink" title="📄2.1 定义与公式"></a>📄2.1 定义与公式</h3><p>线性回归 (Linear regression) 是利用回归方程 (函数) 对一个或多个自变量 (特征值) 和因变量 (目标值) 之间关系进行建模的一种分析方式。</p><ul><li>特点：只有一个自变量的情况称为单变量回归，多于一个自变量情况的叫做多元回归。</li></ul><p><strong>通用公式:</strong></p><script type="math/tex; mode=display">h(w) = w_1 x_1 + w_2 x_2 + w_3 x_3 \ldots + b = w^T x + b \\其中 w, x 可以理解为矩阵: w = \begin{pmatrix} b \\ w_1 \\ w_2 \end{pmatrix}, \quad x = \begin{pmatrix} 1 \\ x_1 \\ x_2 \end{pmatrix}</script><ul><li>线性回归用矩阵表示举例</li></ul><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9F%A9%E9%98%B5%E8%A1%A8%E7%A4%BA%E6%B3%95.png" alt="Alt text"></p><p>理解示例：</p><ul><li>期末成绩：0.7× 考试成绩 + 0.3× 平时成绩</li><li>房子价格 = 0.02× 中心区域的距离 + 0.04× 城市一氧化氮浓度 + (-0.12× 自住房平均房价) + 0.254× 城镇犯罪率</li></ul><p>上面两个例子，特征值与目标值之间建立了一个关系，这个关系可以理解为线性模型。</p><h3 id="📊2-2-线性回归的特征与目标的关系分析"><a href="#📊2-2-线性回归的特征与目标的关系分析" class="headerlink" title="📊2.2 线性回归的特征与目标的关系分析"></a>📊2.2 线性回归的特征与目标的关系分析</h3><p>线性回归当中主要有两种模型，一种是线性关系，另一种是非线性关系。为便于理解，这里都用单个特征或两个特征举例子。</p><h4 id="🔗线性关系"><a href="#🔗线性关系" class="headerlink" title="🔗线性关系"></a>🔗线性关系</h4><ul><li><strong>单变量线性关系</strong>：<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E7%BA%BF%E6%80%A7%E5%85%B3%E7%B3%BB%E5%9B%BE%EF%BC%88%E5%8D%95%E5%8F%98%E9%87%8F%EF%BC%89.png" alt="Alt text"></li><li><strong>多变量线性关系</strong>：<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%85%B3%E7%B3%BB%EF%BC%88%E5%A4%9A%E5%8F%98%E9%87%8F%EF%BC%89.png" alt="Alt text"></li></ul><ul><li>注释：单特征与目标值的关系呈直线关系，或者两个特征与目标值呈现平面的关系。更高维度的关系记住即可。</li></ul><h4 id="🌌非线性关系"><a href="#🌌非线性关系" class="headerlink" title="🌌非线性关系"></a>🌌非线性关系</h4><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%85%B3%E7%B3%BB.png" alt="Alt text"></p><ul><li>注释：若为非线性关系，回归方程可理解为：$ w_1 x_1 + w_2 x_2^2 + w_3 x_3^2$</li></ul><h2 id="🌈3-小结"><a href="#🌈3-小结" class="headerlink" title="🌈3 小结"></a>🌈3 小结</h2><ul><li><strong>线性回归的定义【了解】：</strong>利用回归方程 (函数) 对一个或多个自变量 (特征值) 和因变量 (目标值) 之间关系进行建模的一种分析方式。</li><li><strong>线性回归的分类【知道】</strong>：</li><li>线性关系</li><li>非线性关系</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="机器学习" scheme="https://www.enju-tsubaki.icu/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="线性回归" scheme="https://www.enju-tsubaki.icu/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>案例：Facebook 签到位置预测案例</title>
    <link href="https://www.enju-tsubaki.icu/posts/3b1e1cd9.html"/>
    <id>https://www.enju-tsubaki.icu/posts/3b1e1cd9.html</id>
    <published>2025-02-17T06:20:38.049Z</published>
    <updated>2025-02-17T06:20:41.558Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🎈-Facebook-签到位置预测案例"><a href="#🎈-Facebook-签到位置预测案例" class="headerlink" title="🎈 Facebook 签到位置预测案例"></a>🎈 Facebook 签到位置预测案例</h1><h2 id="🎯一、学习目标"><a href="#🎯一、学习目标" class="headerlink" title="🎯一、学习目标"></a>🎯一、学习目标</h2><p>通过 Facebook 位置预测案例，熟练掌握KNN算法学习内容。</p><h2 id="📌二、项目描述"><a href="#📌二、项目描述" class="headerlink" title="📌二、项目描述"></a>📌二、项目描述</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/Facebook%E7%AD%BE%E5%88%B0%E4%BD%8D%E7%BD%AE%E9%A2%84%E6%B5%8B.png" alt="Alt text"></p><p>本次比赛的目的是预测一个人将要签到的地方。Facebook 创建了一个虚拟世界，这个世界是一个 10 公里 ×10 公里，共 100 平方公里的区域，其中包含约 10 万个地方。对于给定的坐标集，任务是根据用户的位置、准确性和时间戳等信息，预测用户下一次的签到位置。数据被制作成类似于来自移动设备的位置数据。需要注意的是，只能使用提供的数据进行预测 。</p><h2 id="📚三、数据集介绍"><a href="#📚三、数据集介绍" class="headerlink" title="📚三、数据集介绍"></a>📚三、数据集介绍</h2><h3 id="（一）📄数据介绍"><a href="#（一）📄数据介绍" class="headerlink" title="（一）📄数据介绍"></a>（一）📄数据介绍</h3><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/facebook%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D.png" alt="Alt text"></p><p>涉及的文件有 train.csv 和 test.csv ，各字段含义如下：</p><ul><li><strong>row id</strong>：签入事件的 id。</li><li><strong>x y</strong>：坐标。</li><li><strong>accuracy</strong>：准确度，即定位精度。</li><li><strong>time</strong>：时间戳。</li><li><strong>place_id</strong>：签到的位置，这也是需要预测的内容。</li></ul><h3 id="（二）🔗官网"><a href="#（二）🔗官网" class="headerlink" title="（二）🔗官网"></a>（二）🔗官网</h3><p>数据集官网：<a href="https://www.kaggle.com/navoshta/grid-knn/data">https://www.kaggle.com/navoshta/grid-knn/data</a></p><h2 id="🛠️四、步骤分析"><a href="#🛠️四、步骤分析" class="headerlink" title="🛠️四、步骤分析"></a>🛠️四、步骤分析</h2><h3 id="（一）📊数据基本处理"><a href="#（一）📊数据基本处理" class="headerlink" title="（一）📊数据基本处理"></a>（一）📊数据基本处理</h3><p>对数据做一些基本处理（这里的处理不一定能达到最佳效果，只是简单尝试，有些特征可根据特征选择方式进一步处理）。</p><ol><li><strong>缩小数据集范围</strong>：使用 DataFrame.query () 方法。</li><li><strong>选取有用的时间特征</strong> 。</li><li><strong>将签到位置少于 n 个用户的删除</strong> 。</li></ol><h3 id="（二）✂️分割数据集"><a href="#（二）✂️分割数据集" class="headerlink" title="（二）✂️分割数据集"></a>（二）✂️分割数据集</h3><h3 id="（三）⚖️标准化处理"><a href="#（三）⚖️标准化处理" class="headerlink" title="（三）⚖️标准化处理"></a>（三）⚖️标准化处理</h3><h3 id="（四）🔍k-近邻预测"><a href="#（四）🔍k-近邻预测" class="headerlink" title="（四）🔍k - 近邻预测"></a>（四）🔍k - 近邻预测</h3><p>具体步骤如下：</p><ol><li><strong>获取数据集</strong> 。</li><li><strong>基本数据处理</strong><ul><li><strong>缩小数据范围</strong> 。</li><li><strong>选择时间特征</strong> 。</li><li><strong>去掉签到较少的地方</strong> 。</li><li><strong>确定特征值和目标值</strong> 。</li><li><strong>分割数据集</strong> 。</li></ul></li><li><strong>特征工程 — 特征预处理 (标准化)</strong> 。</li><li><strong>机器学习 — knn+cv</strong> 。</li><li><strong>模型评估</strong> 。</li></ol><h2 id="💻五、代码实现"><a href="#💻五、代码实现" class="headerlink" title="💻五、代码实现"></a>💻五、代码实现</h2><h3 id="（一）📥获取数据集"><a href="#（一）📥获取数据集" class="headerlink" title="（一）📥获取数据集"></a>（一）📥获取数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1、获取数据集</span></span><br><span class="line">facebook = pd.read_csv(<span class="string">&quot;./data/FBlocation/train.csv&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="（二）📈基本数据处理"><a href="#（二）📈基本数据处理" class="headerlink" title="（二）📈基本数据处理"></a>（二）📈基本数据处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2.基本数据处理</span></span><br><span class="line"><span class="comment"># 2.1 缩小数据范围</span></span><br><span class="line">facebook_data = facebook.query(<span class="string">&quot;x&gt;2.0 &amp; x&lt;2.5 &amp; y&gt;2.0 &amp; y&lt;2.5&quot;</span>)</span><br><span class="line"><span class="comment"># 2.2 选择时间特征</span></span><br><span class="line">time = pd.to_datetime(facebook_data[<span class="string">&quot;time&quot;</span>], unit=<span class="string">&quot;s&quot;</span>)</span><br><span class="line">time = pd.DatetimeIndex(time)</span><br><span class="line">facebook_data[<span class="string">&quot;day&quot;</span>] = time.day</span><br><span class="line">facebook_data[<span class="string">&quot;hour&quot;</span>] = time.hour</span><br><span class="line">facebook_data[<span class="string">&quot;weekday&quot;</span>] = time.weekday</span><br><span class="line"><span class="comment"># 2.3 去掉签到较少的地方</span></span><br><span class="line">place_count = facebook_data.groupby(<span class="string">&quot;place_id&quot;</span>).count()</span><br><span class="line">place_count = place_count[place_count[<span class="string">&quot;row_id&quot;</span>]&gt;<span class="number">3</span>]</span><br><span class="line">facebook_data = facebook_data[facebook_data[<span class="string">&quot;place_id&quot;</span>].isin(place_count.index)]</span><br><span class="line"><span class="comment"># 2.4 确定特征值和目标值</span></span><br><span class="line">x = facebook_data[[<span class="string">&quot;x&quot;</span>, <span class="string">&quot;y&quot;</span>, <span class="string">&quot;accuracy&quot;</span>, <span class="string">&quot;day&quot;</span>, <span class="string">&quot;hour&quot;</span>, <span class="string">&quot;weekday&quot;</span>]]</span><br><span class="line">y = facebook_data[<span class="string">&quot;place_id&quot;</span>]</span><br><span class="line"><span class="comment"># 2.5 分割数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">22</span>)</span><br></pre></td></tr></table></figure><h3 id="（三）📐特征工程-—-特征预处理-标准化"><a href="#（三）📐特征工程-—-特征预处理-标准化" class="headerlink" title="（三）📐特征工程 — 特征预处理 (标准化)"></a>（三）📐特征工程 — 特征预处理 (标准化)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3.特征工程--特征预处理(标准化)</span></span><br><span class="line"><span class="comment"># 3.1 实例化一个转换器</span></span><br><span class="line">transfer = StandardScaler()</span><br><span class="line"><span class="comment"># 3.2 调用fit_transform</span></span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.fit_transform(x_test)</span><br></pre></td></tr></table></figure><h3 id="（四）🧩机器学习-—knn-cv"><a href="#（四）🧩机器学习-—knn-cv" class="headerlink" title="（四）🧩机器学习 —knn+cv"></a>（四）🧩机器学习 —knn+cv</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4.机器学习--knn+cv</span></span><br><span class="line"><span class="comment"># 4.1 实例化一个估计器</span></span><br><span class="line">estimator = KNeighborsClassifier()</span><br><span class="line"><span class="comment"># 4.2 调用gridsearchCV</span></span><br><span class="line">param_grid = &#123;<span class="string">&quot;n_neighbors&quot;</span>: [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>]&#125;</span><br><span class="line">estimator = GridSearchCV(estimator, param_grid=param_grid, cv=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 4.3 模型训练</span></span><br><span class="line">estimator.fit(x_train, y_train)</span><br></pre></td></tr></table></figure><h3 id="（五）📊模型评估"><a href="#（五）📊模型评估" class="headerlink" title="（五）📊模型评估"></a>（五）📊模型评估</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 5.模型评估</span></span><br><span class="line"><span class="comment"># 5.1 基本评估方式</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最后预测的准确率为:\n&quot;</span>, score)</span><br><span class="line"></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最后的预测值为:\n&quot;</span>, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测值和真实值的对比情况:\n&quot;</span>, y_predict == y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.2 使用交叉验证后的评估方式</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;在交叉验证中验证的最好结果:\n&quot;</span>, estimator.best_score_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最好的参数模型:\n&quot;</span>, estimator.best_estimator_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每次交叉验证后的验证集准确率结果和训练集准确率结果:\n&quot;</span>,estimator.cv_results_)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="机器学习" scheme="https://www.enju-tsubaki.icu/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="KNN" scheme="https://www.enju-tsubaki.icu/tags/KNN/"/>
    
  </entry>
  
  <entry>
    <title>案例：鸢尾花种类预测</title>
    <link href="https://www.enju-tsubaki.icu/posts/6bddf6c7.html"/>
    <id>https://www.enju-tsubaki.icu/posts/6bddf6c7.html</id>
    <published>2025-02-15T05:21:37.654Z</published>
    <updated>2025-02-15T06:34:30.499Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🌼案例：鸢尾花种类预测-—-流程实现🥰"><a href="#🌼案例：鸢尾花种类预测-—-流程实现🥰" class="headerlink" title="🌼案例：鸢尾花种类预测 — 流程实现🥰"></a>🌼案例：鸢尾花种类预测 — 流程实现🥰</h1><h2 id="🎯学习目标"><a href="#🎯学习目标" class="headerlink" title="🎯学习目标"></a>🎯学习目标</h2><ul><li><h3 id="🎯目标"><a href="#🎯目标" class="headerlink" title="🎯目标"></a>🎯目标</h3><ul><li>熟悉：机器学习从数据获取到评估的完整流程</li><li>掌握：KNeighborsClassifier的使用及参数设置</li><li>理解：归一化和标准化原理、区别及适用场景</li><li>明晰：交叉验证和网格搜索概念及作用</li><li>运用：交叉验证和网格搜索优化模型</li></ul></li></ul><h2 id="🔍K-近邻算法-API"><a href="#🔍K-近邻算法-API" class="headerlink" title="🔍K - 近邻算法 API"></a>🔍K - 近邻算法 API</h2><p><code>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, algorithm=&#39;auto&#39;)</code></p><h4 id="📋参数说明"><a href="#📋参数说明" class="headerlink" title="📋参数说明"></a>📋参数说明</h4><ul><li><code>n_neighbors</code>：int，可选（默认 = 5），k_neighbors 查询默认使用的邻居数</li><li><code>algorithm</code>：{‘auto’，‘ball_tree’，‘kd_tree’，‘brute’}，快速 k 近邻搜索算法，默认参数为 auto，可以理解为算法自己决定合适的搜索算法。除此之外，用户也可以自己指定搜索算法：<ul><li><code>brute</code>：蛮力搜索，也就是线性扫描，当训练集很大时，计算非常耗时。</li><li><code>kd_tree</code>：构造kd树存储数据以便对其进行快速检索的树形数据结构，kd树也就是数据结构中的二叉树。以中值切分构造的树，每个结点是一个超矩形，在维数小于20时效率高。</li><li><code>ball_tree</code>：是为了克服kd树高维失效而发明的，其构造过程是以质心C和半径r分割样本空间，每个节点是一个超球体。</li></ul></li></ul><h2 id="💡预处理归一化和标准化的精髓✨"><a href="#💡预处理归一化和标准化的精髓✨" class="headerlink" title="💡预处理归一化和标准化的精髓✨"></a>💡预处理归一化和标准化的精髓✨</h2><h3 id="🔢归一化"><a href="#🔢归一化" class="headerlink" title="🔢归一化"></a>🔢归一化</h3><ul><li><strong>核心定义：</strong>将原始数据通过变换映射到指定范围，通常是[0,1]区间。</li><li><p><strong>公式本质：</strong>每一列数据，通过减去最小值，除以极差（最大值与最小值的差）</p><script type="math/tex; mode=display">X' = \frac{x - \min}{\max - \min}</script><p>再乘以指定区间长度并加上区间下限，实现数据的缩放。</p><script type="math/tex; mode=display">X'' = X' * (mx - mi) + mi</script></li><li>主要作用：消除特征之间的量纲差异，使不同特征在模型中具有相同的“地位”，便于进行比较和分析，有助于提高某些对特征范围敏感的机器学习算法的性能。</li><li>API要点：使用 <code>sklearn.preprocessing.MinMaxScaler</code>类，通过 <code>fit_transform</code>方法对 <code>numpy array</code>格式的数据进行转换，可通过 <code>feature_range</code>参数指定映射范围。</li><li>应用局限：最大值和最小值易受异常点影响，导致归一化结果不稳定，鲁棒性较差，适用于传统精确小数据场景。</li></ul><h3 id="🌟标准化"><a href="#🌟标准化" class="headerlink" title="🌟标准化"></a>🌟标准化</h3><ul><li>核心定义：对原始数据进行变换，使数据转换到均值为0、标准差为1的范围内。</li><li><p>公式本质：</p><script type="math/tex; mode=display">X' = \frac{x - \text{mean}}{\sigma}</script><p>针对每一列数据，减去该列的均值，再除以该列的标准差，从而使数据符合标准正态分布。</p></li><li>主要作用：在消除量纲影响的同时，能让数据具有稳定的均值和标准差，使模型更加稳定和高效，尤其适用于对数据分布有一定要求的算法。</li><li>API要点：利用 <code>sklearn.preprocessing.StandardScaler</code>类的 <code>fit_transform</code>方法处理 <code>numpy array</code>格式的数据，处理后每列数据都聚集在均值0附近，标准差为1。</li><li>应用优势：在样本数据足够多的情况下比较稳定，少量异常点对平均值和方差的影响较小，适合现代嘈杂大数据场景。</li></ul><h2 id="🌸案例：鸢尾花种类预测🌼"><a href="#🌸案例：鸢尾花种类预测🌼" class="headerlink" title="🌸案例：鸢尾花种类预测🌼"></a>🌸案例：鸢尾花种类预测🌼</h2><h3 id="📊数据集介绍"><a href="#📊数据集介绍" class="headerlink" title="📊数据集介绍"></a>📊数据集介绍</h3><p>Iris数据集是常用的分类实验数据集，由Fisher, 1936收集整理。Iris也称鸢尾花卉数据集，是一类多重变量分析的数据集。关于数据集的具体介绍：<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/iris%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D.png" alt="Alt text"></p><h3 id="🚀步骤分析"><a href="#🚀步骤分析" class="headerlink" title="🚀步骤分析"></a>🚀步骤分析</h3><ul><li>获取数据集</li><li>数据基本处理</li><li>特征工程</li><li>机器学习 (模型训练)</li><li>模型评估</li></ul><h3 id="💻代码过程"><a href="#💻代码过程" class="headerlink" title="💻代码过程"></a>💻代码过程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入必要的库</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 获取数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 数据基本处理</span></span><br><span class="line"><span class="comment"># x_train,x_test,y_train,y_test为训练集特征值、测试集特征值、训练集目标值、测试集目标值</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=<span class="number">0.2</span>, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 特征工程：标准化</span></span><br><span class="line">transfer = StandardScaler()</span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 机器学习(模型训练)</span></span><br><span class="line">estimator = KNeighborsClassifier(n_neighbors=<span class="number">9</span>)</span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 模型评估</span></span><br><span class="line"><span class="comment"># 方法1：比对真实值和预测值</span></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测结果为:\n&quot;</span>, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;比对真实值和预测值：\n&quot;</span>, y_predict == y_test)</span><br><span class="line"><span class="comment"># 方法2：直接计算准确率</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率为：\n&quot;</span>, score)</span><br></pre></td></tr></table></figure><h2 id="🔄什么是交叉验证-cross-validation-🌟"><a href="#🔄什么是交叉验证-cross-validation-🌟" class="headerlink" title="🔄什么是交叉验证 (cross validation)🌟"></a>🔄什么是交叉验证 (cross validation)🌟</h2><p>交叉验证是一种用于评估模型性能的重要技术。它将拿到的训练数据，进一步细分为训练集和验证集。例如，把数据分成 4 份，其中一份作为验证集。然后经过 4 次（组）的测试，每次都更换不同的验证集，即得到 4 组模型的结果，取平均值作为最终结果，这也被称为 4 折交叉验证。</p><h3 id="🧐分析"><a href="#🧐分析" class="headerlink" title="🧐分析"></a>🧐分析</h3><p>我们之前了解到数据分为训练集和测试集，但为了让从训练得到的模型结果更加准确，我们做如下处理：</p><ul><li>训练集：进一步拆分为训练集和验证集</li><li>测试集：保持不变</li></ul><h3 id="🤔为什么需要交叉验证"><a href="#🤔为什么需要交叉验证" class="headerlink" title="🤔为什么需要交叉验证"></a>🤔为什么需要交叉验证</h3><p>交叉验证的目的是为了让被评估的模型更加准确可信。不过，这只是提升了模型评估的准确性，那如何选择或者调优参数呢？这就引出了网格搜索。</p><h2 id="🔍什么是网格搜索-Grid-Search-🌈"><a href="#🔍什么是网格搜索-Grid-Search-🌈" class="headerlink" title="🔍什么是网格搜索 (Grid Search)🌈"></a>🔍什么是网格搜索 (Grid Search)🌈</h2><p>通常情况下，有很多参数是需要手动指定的（如 k - 近邻算法中的 K 值），这种参数被称为超参数。手动调整超参数的过程繁杂，所以我们需要对模型预设几种超参数组合。每组超参数都采用交叉验证来进行评估，最后选出最优参数组合建立模型。</p><h2 id="🛠交叉验证，网格搜索（模型选择与调优）API📚"><a href="#🛠交叉验证，网格搜索（模型选择与调优）API📚" class="headerlink" title="🛠交叉验证，网格搜索（模型选择与调优）API📚"></a>🛠交叉验证，网格搜索（模型选择与调优）API📚</h2><p><code>sklearn.model_selection.GridSearchCV(estimator, param_grid=None, cv=None)</code> 用于对估计器的指定参数值进行详尽搜索。</p><h4 id="📋参数说明-1"><a href="#📋参数说明-1" class="headerlink" title="📋参数说明"></a>📋参数说明</h4><ul><li><code>estimator</code>：估计器对象</li><li><code>param_grid</code>：估计器参数（字典形式），例如 <code>&#123;&quot;n_neighbors&quot;: [1, 3, 5]&#125;</code></li><li><code>cv</code>：指定几折交叉验证</li><li><code>fit</code>：输入训练数据</li><li><code>score</code>：计算准确率</li></ul><h3 id="📈结果分析"><a href="#📈结果分析" class="headerlink" title="📈结果分析"></a>📈结果分析</h3><ul><li><code>best_score_</code>：在交叉验证中验证的最好结果</li><li><code>best_estimator_</code>：最好的参数模型</li><li><code>cv_results_</code>：每次交叉验证后的验证集准确率结果和训练集准确率结果</li></ul><h2 id="🌺鸢尾花案例增加-K-值调优💐"><a href="#🌺鸢尾花案例增加-K-值调优💐" class="headerlink" title="🌺鸢尾花案例增加 K 值调优💐"></a>🌺鸢尾花案例增加 K 值调优💐</h2><p>以下是使用 <code>GridSearchCV</code> 构建估计器的完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、获取数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、数据基本处理 -- 划分数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、特征工程：标准化</span></span><br><span class="line"><span class="comment"># 实例化一个转换器类</span></span><br><span class="line">transfer = StandardScaler()</span><br><span class="line"><span class="comment"># 调用 fit_transform</span></span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、KNN 预估器流程</span></span><br><span class="line"><span class="comment">#  4.1 实例化预估器类</span></span><br><span class="line">estimator = KNeighborsClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.2 模型选择与调优——网格搜索和交叉验证</span></span><br><span class="line"><span class="comment"># 准备要调的超参数</span></span><br><span class="line">param_dict = &#123;<span class="string">&quot;n_neighbors&quot;</span>: [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>]&#125;</span><br><span class="line">estimator = GridSearchCV(estimator, param_grid=param_dict, cv=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.3 fit 数据进行训练</span></span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、评估模型效果</span></span><br><span class="line"><span class="comment"># 方法 a：比对预测结果和真实值</span></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;比对预测结果和真实值：\n&quot;</span>, y_predict == y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法 b：直接计算准确率</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;直接计算准确率：\n&quot;</span>, score)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看最终选择的结果和交叉验证的结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;在交叉验证中验证的最好结果：\n&quot;</span>, estimator.best_score_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最好的参数模型：\n&quot;</span>, estimator.best_estimator_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每次交叉验证后的准确率结果：\n&quot;</span>, estimator.cv_results_)</span><br></pre></td></tr></table></figure><h3 id="💻代码运行输出结果👇"><a href="#💻代码运行输出结果👇" class="headerlink" title="💻代码运行输出结果👇"></a>💻代码运行输出结果👇</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">比对预测结果和真实值：</span><br><span class="line"> [ True  True  True  True  True  True  True False  True  True  True  True</span><br><span class="line">  True  True  True  True  True  True False  True  True  True  True  True</span><br><span class="line">  True  True  True  True  True  True  True  True  True  True  True  True</span><br><span class="line">  True  True]</span><br><span class="line">直接计算准确率：</span><br><span class="line"> 0.947368421053</span><br><span class="line">在交叉验证中验证的最好结果：</span><br><span class="line"> 0.973214285714</span><br><span class="line">最好的参数模型：</span><br><span class="line"> KNeighborsClassifier(algorithm=&#x27;auto&#x27;, leaf_size=30, metric=&#x27;minkowski&#x27;,</span><br><span class="line">           metric_params=None, n_jobs=1, n_neighbors=5, p=2,</span><br><span class="line">           weights=&#x27;uniform&#x27;)</span><br><span class="line">每次交叉验证后的准确率结果：</span><br><span class="line"> &#123;&#x27;mean_fit_time&#x27;: array([ 0.00114751,  0.00027037,  0.00024462]), &#x27;std_fit_time&#x27;: array([  1.13901511e-03,   1.25300249e-05,   1.11011951e-05]), &#x27;mean_score_time&#x27;: array([ 0.00085751,  0.00048693,  0.00045625]), &#x27;std_score_time&#x27;: array([  3.52785082e-04,   2.87650037e-05,   5.29673344e-06]), &#x27;param_n_neighbors&#x27;: masked_array(data = [1 3 5],</span><br><span class="line">             mask = [False False False],</span><br><span class="line">       fill_value = ?), &#x27;params&#x27;: [&#123;&#x27;n_neighbors&#x27;: 1&#125;, &#123;&#x27;n_neighbors&#x27;: 3&#125;, &#123;&#x27;n_neighbors&#x27;: 5&#125;], &#x27;split0_test_score&#x27;: array([ 0.97368421,  0.97368421,  0.97368421]), &#x27;split1_test_score&#x27;: array([ 0.97297297,  0.97297297,  0.97297297]), &#x27;split2_test_score&#x27;: array([ 0.94594595,  0.89189189,  0.97297297]), &#x27;mean_test_score&#x27;: array([ 0.96428571,  0.94642857,  0.97321429]), &#x27;std_test_score&#x27;: array([ 0.01288472,  0.03830641,  0.00033675]), &#x27;rank_test_score&#x27;: array([2, 3, 1], dtype=int32), &#x27;split0_train_score&#x27;: array([ 1.        ,  0.95945946,  0.97297297]), &#x27;split1_train_score&#x27;: array([ 1.        ,  0.96      ,  0.97333333]), &#x27;split2_train_score&#x27;: array([ 1.  ,  0.96,  0.96]), &#x27;mean_train_score&#x27;: array([ 1.        ,  0.95981982,  0.96876877]), &#x27;std_train_score&#x27;: array([ 0.        ,  0.00025481,  0.0062022 ])&#125;</span><br></pre></td></tr></table></figure><h2 id="📝总结🎉"><a href="#📝总结🎉" class="headerlink" title="📝总结🎉"></a>📝总结🎉</h2><p>本文围绕鸢尾花种类预测案例，详细介绍了机器学习从数据获取到模型评估的完整流程，以及相关的数据预处理、模型调优等重要技术，具体内容总结如下：</p><h3 id="🚀机器学习流程与核心算法"><a href="#🚀机器学习流程与核心算法" class="headerlink" title="🚀机器学习流程与核心算法"></a>🚀机器学习流程与核心算法</h3><ul><li><strong>完整流程</strong>：涵盖获取数据集、数据基本处理、特征工程、模型训练和模型评估等环节，清晰展示了运用机器学习解决实际分类问题的步骤。</li><li><strong>K - 近邻算法</strong>：<code>KNeighborsClassifier</code> 是常用的分类算法，可通过设置 <code>n_neighbors</code> 和 <code>algorithm</code> 等参数进行灵活调整。不同的 <code>algorithm</code> 选项（如 <code>auto</code>、<code>ball_tree</code>、<code>kd_tree</code>、<code>brute</code>）适用于不同的数据规模和维度场景。</li></ul><h3 id="💾数据预处理"><a href="#💾数据预处理" class="headerlink" title="💾数据预处理"></a>💾数据预处理</h3><ul><li><strong>归一化</strong>：将数据映射到指定范围（通常是 [0,1]），能消除特征量纲差异，但易受异常点影响，鲁棒性较差，适用于传统精确小数据场景。使用 <code>sklearn.preprocessing.MinMaxScaler</code> 类实现。</li><li><strong>标准化</strong>：把数据变换到均值为 0、标准差为 1 的范围内，在处理大数据时更为稳定，受异常点影响较小，适合现代嘈杂大数据场景。使用 <code>sklearn.preprocessing.StandardScaler</code> 类实现。</li></ul><h3 id="📊模型评估与调优"><a href="#📊模型评估与调优" class="headerlink" title="📊模型评估与调优"></a>📊模型评估与调优</h3><ul><li><strong>交叉验证</strong>：通过将训练数据划分为多个子集进行多次验证，取结果平均值，可使模型评估结果更加准确可信，提高模型的泛化能力。</li><li><strong>网格搜索</strong>：针对超参数（如 K - 近邻算法中的 <code>n_neighbors</code>）预设多种组合，利用交叉验证评估每组参数的效果，从而选出最优参数组合，优化模型性能。使用 <code>sklearn.model_selection.GridSearchCV</code> 类实现。</li></ul><p>通过鸢尾花种类预测案例，我们不仅掌握了 <code>KNeighborsClassifier</code> 算法的使用，还学会了如何运用数据预处理、交叉验证和网格搜索等技术，提升模型的准确性和稳定性。这些方法和技术在解决各类机器学习分类问题中具有广泛的应用价值。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    
    <category term="KNN" scheme="https://www.enju-tsubaki.icu/tags/KNN/"/>
    
    <category term="特征工程" scheme="https://www.enju-tsubaki.icu/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="交叉验证" scheme="https://www.enju-tsubaki.icu/tags/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/"/>
    
    <category term="网格搜索" scheme="https://www.enju-tsubaki.icu/tags/%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2/"/>
    
  </entry>
  
  <entry>
    <title>K-近邻算法API</title>
    <link href="https://www.enju-tsubaki.icu/posts/d5f3c9dd.html"/>
    <id>https://www.enju-tsubaki.icu/posts/d5f3c9dd.html</id>
    <published>2025-02-14T05:51:33.482Z</published>
    <updated>2025-02-14T06:31:45.089Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🌟1-2-k近邻算法api初步使用🌟"><a href="#🌟1-2-k近邻算法api初步使用🌟" class="headerlink" title="🌟1.2 k近邻算法api初步使用🌟"></a>🌟1.2 k近邻算法api初步使用🌟</h1><h2 id="🌈学习目标"><a href="#🌈学习目标" class="headerlink" title="🌈学习目标"></a>🌈学习目标</h2><h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><ul><li>了解sklearn工具的优点和包含内容</li><li>应用sklearn中的api实现KNN算法的简单使用</li></ul><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="Alt text"></p><ol><li>获取数据集</li><li>数据基本处理</li><li>特征工程</li><li>机器学习</li><li>模型评估</li></ol><h2 id="🛠️Scikit-learn-工具介绍"><a href="#🛠️Scikit-learn-工具介绍" class="headerlink" title="🛠️Scikit-learn 工具介绍"></a>🛠️Scikit-learn 工具介绍</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/scikitlearn.png" alt="Alt text"></p><p>Scikit-learn是Python语言的机器学习工具，它具有以下特点：</p><ul><li>包括许多知名的机器学习算法的实现</li><li>文档完善，容易上手，拥有丰富的AP</li></ul><h3 id="🔧安装"><a href="#🔧安装" class="headerlink" title="🔧安装"></a>🔧安装</h3><p>使用以下命令进行安装：<br><code>pip3 install scikit-learn</code></p><p>安装好之后可以通过以下命令查看是否安装成功：<br><code>import sklearn</code></p><p>注：安装scikit-learn需要Numpy, Scipy等库。</p><h3 id="📦Scikit-learn包含的内容"><a href="#📦Scikit-learn包含的内容" class="headerlink" title="📦Scikit-learn包含的内容"></a>📦Scikit-learn包含的内容</h3><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/sklearn%E5%8C%85%E5%90%AB%E5%86%85%E5%AE%B9.png" alt="Alt text"></p><ul><li>分类、聚类、回归 - 特征工程</li><li>模型选择、调优</li></ul><h2 id="📌K-近邻算法API"><a href="#📌K-近邻算法API" class="headerlink" title="📌K-近邻算法API"></a>📌K-近邻算法API</h2><p><code>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5)</code></p><ul><li><code>n_neighbors</code>：int，可选（默认 = 5），k_neighbors 查询默认使用的邻居数</li></ul><h2 id="📋案例"><a href="#📋案例" class="headerlink" title="📋案例"></a>📋案例</h2><h3 id="👣步骤分析"><a href="#👣步骤分析" class="headerlink" title="👣步骤分析"></a>👣步骤分析</h3><ol><li>获取数据集</li><li>数据基本处理（该案例中省略）</li><li>特征工程（该案例中省略）</li><li>机器学习</li><li>模型评估（该案例中省略）</li></ol><h3 id="💻代码过程"><a href="#💻代码过程" class="headerlink" title="💻代码过程"></a>💻代码过程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入模块</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造数据集</span></span><br><span class="line">x = [[<span class="number">0</span>], [<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 机器学习 -- 模型训练</span></span><br><span class="line"><span class="comment"># 实例化API</span></span><br><span class="line">estimator = KNeighborsClassifier(n_neighbors=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 使用fit方法进行训练</span></span><br><span class="line">estimator.fit(x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行预测</span></span><br><span class="line">result = estimator.predict([[<span class="number">1</span>]])</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure><h2 id="❓问题解答"><a href="#❓问题解答" class="headerlink" title="❓问题解答"></a>❓问题解答</h2><h3 id="1-选取K值的大小？"><a href="#1-选取K值的大小？" class="headerlink" title="1. 选取K值的大小？"></a>1. 选取K值的大小？</h3><p>K值的选择对KNN模型有重要影响：</p><ul><li><strong>K值过小：</strong><ul><li>容易受到异常点的影响</li><li>容易过拟合，即“学习”近似误差会减小，但“学习”的估计误差会增大，整体模型变得复杂。</li></ul></li><li><strong>K值过大：</strong><ul><li>受到样本均衡的问题</li><li>容易欠拟合，学习的近似误差会增大，模型变得简单。</li></ul></li><li><strong>K=N（N为训练样本个数）：</strong>完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的类，模型过于简单，忽略了训练实例中大量有用信息。</li></ul><p>在实际应用中，K值一般取一个比较小的数值，例如采用交叉验证法（简单来说，就是把训练数据再分成两组：训练集和验证集）来选择最优的K值。</p><p><strong>近似误差：</strong>对现有训练集的训练误差，关注训练集。如果近似误差过小可能会出现过拟合的现象，对现有的训练集能有很好的预测，但是对未知的测试样本将会出现较大偏差的预测，模型本身不是最接近最佳模型。</p><p><strong>估计误差：</strong>可以理解为对测试集的测试误差，关注测试集。估计误差小说明对未知数据的预测能力好，模型本身最接近最佳模型。</p><h3 id="2-api中其他参数的具体含义？"><a href="#2-api中其他参数的具体含义？" class="headerlink" title="2. api中其他参数的具体含义？"></a>2. api中其他参数的具体含义？</h3><p><code>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, algorithm=&#39;auto&#39;)</code></p><ul><li><code>n_neighbors</code>：int，可选（默认 = 5），k_neighbors 查询默认使用的邻居数</li><li><code>algorithm</code>：{‘auto’，‘ball_tree’，‘kd_tree’，‘brute’}，快速 k 近邻搜索算法，默认参数为 auto，可以理解为算法自己决定合适的搜索算法。除此之外，用户也可以自己指定搜索算法：<ul><li><code>brute</code>：蛮力搜索，也就是线性扫描，当训练集很大时，计算非常耗时。</li><li><code>kd_tree</code>：构造kd树存储数据以便对其进行快速检索的树形数据结构，kd树也就是数据结构中的二叉树。以中值切分构造的树，每个结点是一个超矩形，在维数小于20时效率高。</li><li><code>ball_tree</code>：是为了克服kd树高维失效而发明的，其构造过程是以质心C和半径r分割样本空间，每个节点是一个超球体。</li></ul></li></ul><h2 id="📚总结"><a href="#📚总结" class="headerlink" title="📚总结"></a>📚总结</h2><h3 id="sklearn的优势"><a href="#sklearn的优势" class="headerlink" title="sklearn的优势"></a>sklearn的优势</h3><ul><li>文档多，且规范</li><li>包含的算法多 - 实现起来容易</li></ul><h3 id="knn中的api"><a href="#knn中的api" class="headerlink" title="knn中的api"></a>knn中的api</h3><p><code>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, algorithm=&#39;auto&#39;)</code></p><h3 id="KNN中K值大小选择对模型的影响"><a href="#KNN中K值大小选择对模型的影响" class="headerlink" title="KNN中K值大小选择对模型的影响"></a>KNN中K值大小选择对模型的影响</h3><ul><li>K值过小：容易受到异常点的影响，容易过拟合</li><li>K值过大：受到样本均衡的问题，容易欠拟合</li></ul><p>通过以上内容，我们对sklearn工具和KNN算法的API有了初步的了解，并且掌握了如何使用sklearn中的KNN算法进行简单的模型训练和预测。同时，我们也了解了K值选择对模型的影响以及API中其他参数的含义。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="机器学习" scheme="https://www.enju-tsubaki.icu/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="KNN" scheme="https://www.enju-tsubaki.icu/tags/KNN/"/>
    
    <category term="API" scheme="https://www.enju-tsubaki.icu/tags/API/"/>
    
  </entry>
  
  <entry>
    <title>K-近邻算法</title>
    <link href="https://www.enju-tsubaki.icu/posts/2431c9eb.html"/>
    <id>https://www.enju-tsubaki.icu/posts/2431c9eb.html</id>
    <published>2025-02-10T05:26:18.410Z</published>
    <updated>2025-02-14T06:00:04.438Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🎈1-1-K-近邻算法简介"><a href="#🎈1-1-K-近邻算法简介" class="headerlink" title="🎈1.1 K - 近邻算法简介"></a>🎈1.1 K - 近邻算法简介</h1><h2 id="🌟学习目标"><a href="#🌟学习目标" class="headerlink" title="🌟学习目标"></a>🌟学习目标</h2><ul><li><strong>目标</strong>：了解什么是 KNN 算法</li><li><strong>知道</strong>：KNN 算法求解过程</li></ul><h2 id="🌸1-什么是-K-近邻算法"><a href="#🌸1-什么是-K-近邻算法" class="headerlink" title="🌸1 什么是 K - 近邻算法"></a>🌸1 什么是 K - 近邻算法</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/%E5%9C%B0%E5%9B%BEK%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95.png" alt="Alt text"></p><p>根据你的 “邻居” 来推断出你的类别。</p><h3 id="🐾1-1-K-近邻算法-KNN-概念"><a href="#🐾1-1-K-近邻算法-KNN-概念" class="headerlink" title="🐾1.1 K - 近邻算法 (KNN) 概念"></a>🐾1.1 K - 近邻算法 (KNN) 概念</h3><p>K Nearest Neighbor 算法又叫 KNN 算法，这个算法是机器学习里面一个比较经典的算法，总体来说 KNN 算法是相对比较容易理解的算法。</p><h4 id="💡定义"><a href="#💡定义" class="headerlink" title="💡定义"></a>💡定义</h4><p>如果一个样本在特征空间中的 k 个最相似 (即特征空间中最邻近) 的样本中的大多数属于某一个类别，则该样本也属于这个类别。例如，在一个水果分类问题中，我们有一堆已知类别的水果样本（苹果、橙子等），对于一个未知类别的水果，我们通过计算它与已知水果样本的相似度（距离），找到最相似的 k 个样本，如果这 k 个样本中大多数是苹果，那么我们就可以推断这个未知水果也可能是苹果。</p><h4 id="🌟来源"><a href="#🌟来源" class="headerlink" title="🌟来源"></a>🌟来源</h4><p>KNN 算法最早是由 Cover 和 Hart 提出的一种分类算法。</p><h4 id="📏距离公式"><a href="#📏距离公式" class="headerlink" title="📏距离公式"></a>📏距离公式</h4><p>两个样本的距离可以通过如下公式计算，又叫欧式距离 。<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/%E6%AC%A7%E6%B0%8F%E8%B7%9D%E7%A6%BB.png" alt="Alt text"></p><script type="math/tex; mode=display">对于二维平面上点a(x_{1}, y_{1})与b(x{2}, y{2}) 之间的欧氏距离：</script><script type="math/tex; mode=display">d_{12} = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}</script><script type="math/tex; mode=display">对于三维空间点 a(x{_1}, y{_1}, z{_1})与b(x{_2}, y{_2}, z{_2}) 之间的欧氏距离：</script><script type="math/tex; mode=display">d_{12} = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2 + (z_1 - z_2)^2}</script><script type="math/tex; mode=display">对于n维空间点 a(x_{11}, x_{12}, \ldots, x_{1n})与b(x_{21}, x_{22}, \ldots, x_{2n}) 之间的欧氏距离（两个n维向量）：</script><script type="math/tex; mode=display">d_{12} = \sqrt{\sum_{k=1}^{n} (x_{1k} - x_{2k})^2}</script><h3 id="🍿1-2-电影类型分析"><a href="#🍿1-2-电影类型分析" class="headerlink" title="🍿1.2 电影类型分析"></a>🍿1.2 电影类型分析</h3><p>假设我们现在有几部电影（电影数据表格，包含电影名称、特征数据、类别等信息）。其中有一部 “？号电影” 不知道类别，如何去预测？我们可以利用 K 近邻算法的思想。</p><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/%E7%94%B5%E5%BD%B1%E4%B8%BE%E4%BE%8B.png" alt="Alt text"></p><p>分别计算每个电影和被预测电影的距离，然后求解。比如，我们可以从电影的多个特征（如搞笑镜头、拥抱镜头、打斗镜头等）来计算它们之间的距离。</p><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/%E7%94%B5%E5%BD%B1%E4%B8%BE%E4%BE%8B2.png" alt="Alt text"></p><p>假设我们已经计算出了各电影与 “？号电影” 的距离，如下表所示（示例数据）：<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/%E7%94%B5%E5%BD%B1%E4%B8%BE%E4%BE%8B3.png" alt="Alt text"></p><h3 id="🐼分类过程🐠"><a href="#🐼分类过程🐠" class="headerlink" title="🐼分类过程🐠"></a>🐼分类过程🐠</h3><p>当 (K = 5) 时，从表格中可知距离《唐人街探案》最近的 5 部电影分别是《功夫熊猫》《美人鱼》《宝贝当家》《新步步惊心》《代理情人》。</p><ul><li>这 5 部电影中：</li><li>《功夫熊猫》《美人鱼》《宝贝当家》是喜剧片；</li><li>《新步步惊心》和《代理情人》是爱情片。</li></ul><p>喜剧片的数量为 3，爱情片的数量为 2。  根据 KNN 算法中多数表决的原则，在这 5 个最近邻中，喜剧片的数量占多数。</p><h3 id="🎬结论"><a href="#🎬结论" class="headerlink" title="🎬结论"></a>🎬结论</h3><p>通过 KNN 分析，预测《唐人街探案》的电影类型为喜剧片。因为在距离它最近的 5 部电影中，喜剧片的数量多于其他类型的电影数量。</p><h3 id="📈1-3-KNN-算法流程总结"><a href="#📈1-3-KNN-算法流程总结" class="headerlink" title="📈1.3 KNN 算法流程总结"></a>📈1.3 KNN 算法流程总结</h3><ol><li><strong>计算已知类别数据集中的点与当前点之间的距离</strong>：利用距离公式（如欧氏距离），计算每个已知样本点与待预测点的距离。</li><li><strong>按距离递增次序排序</strong>：将计算得到的距离从小到大进行排序。</li><li><strong>选取与当前点距离最小的 k 个点</strong>：从排序后的距离列表中，选取前 k 个最小距离对应的样本点。</li><li><strong>统计前 k 个点所在的类别出现的频率</strong>：查看这 k 个点分别属于哪些类别，并统计每个类别出现的次数。</li><li><strong>返回前 k 个点出现频率最高的类别作为当前点的预测分类</strong>：如果这 k 个点中属于动作片类别的点最多，那么就预测待预测电影为动作片。</li></ol><h2 id="🌈2-小结"><a href="#🌈2-小结" class="headerlink" title="🌈2 小结"></a>🌈2 小结</h2><ul><li><strong>K - 近邻算法简介【了解】</strong>：就是通过你的 “邻居” 来判断你属于哪个类别。</li><li><strong>如何计算你到你的 “邻居” 的距离</strong>：一般时候，都是使用欧氏距离。欧氏距离能够直观地衡量两个样本在特征空间中的距离远近，帮助我们找到最邻近的样本。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="机器学习" scheme="https://www.enju-tsubaki.icu/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="KNN" scheme="https://www.enju-tsubaki.icu/tags/KNN/"/>
    
  </entry>
  
</feed>
