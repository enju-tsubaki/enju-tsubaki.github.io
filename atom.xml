<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Coisini</title>
  
  <subtitle>一見旧知のようです、万千の歓喜心が生まれます</subtitle>
  <link href="https://www.enju-tsubaki.icu/atom.xml" rel="self"/>
  
  <link href="https://www.enju-tsubaki.icu/"/>
  <updated>2025-02-10T04:55:02.199Z</updated>
  <id>https://www.enju-tsubaki.icu/</id>
  
  <author>
    <name>Coisini</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hello World</title>
    <link href="https://www.enju-tsubaki.icu/posts/3610a686.html"/>
    <id>https://www.enju-tsubaki.icu/posts/3610a686.html</id>
    <published>2025-02-13T06:27:38.146Z</published>
    <updated>2025-02-10T04:55:02.199Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>🌟 <strong>简单的自我介绍</strong></p><p>大家好，我是 Coisini，来自古城西安，是陕西理工大学数计学院人工智能专业的学生。</p><p>🚀 <strong>编程的目标方向</strong></p><p>我对编程充满热情，尤其专注于人工智能领域的研究与应用，致力于探索机器学习和深度学习算法的潜力。通过结合Spring Boot框架，我能够快速构建稳定的应用程序，为AI算法的实际部署提供强有力的支持。利用MyBatis简化数据库操作，使我更专注于业务逻辑优化和算法实现，而Maven则帮助我高效管理项目依赖和构建过程，使开发更加流畅。每次攻克技术难题、掌握新概念，都让我感到极大的满足与成就，力求在AI技术的研究与实践中不断前进。</p><p>🌱 <strong>未来的学习方向</strong></p><p>在这个快速发展的时代，我立志于紧跟人工智能领域的前沿趋势，深入学习并掌握一系列关键技术，包括但不限于DeepSeek、Cursor、Dify、工作流、智能体以及知识库等。这些技术代表了当前AI技术发展的重要方向，它们不仅能够提升我的专业技能，也为解决复杂问题提供了新的思路和工具。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="个人简介" scheme="https://www.enju-tsubaki.icu/categories/%E4%B8%AA%E4%BA%BA%E7%AE%80%E4%BB%8B/"/>
    
    <category term="编程学习" scheme="https://www.enju-tsubaki.icu/categories/%E4%B8%AA%E4%BA%BA%E7%AE%80%E4%BB%8B/%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="人工智能" scheme="https://www.enju-tsubaki.icu/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="机器学习" scheme="https://www.enju-tsubaki.icu/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="https://www.enju-tsubaki.icu/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="SpringBoot" scheme="https://www.enju-tsubaki.icu/tags/SpringBoot/"/>
    
  </entry>
  
  <entry>
    <title>KNN</title>
    <link href="https://www.enju-tsubaki.icu/posts/7c10b52f.html"/>
    <id>https://www.enju-tsubaki.icu/posts/7c10b52f.html</id>
    <published>2025-02-10T05:26:18.410Z</published>
    <updated>2025-02-13T06:24:25.433Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🎈1-1-K-近邻算法简介"><a href="#🎈1-1-K-近邻算法简介" class="headerlink" title="🎈1.1 K - 近邻算法简介"></a>🎈1.1 K - 近邻算法简介</h1><h2 id="🌟学习目标"><a href="#🌟学习目标" class="headerlink" title="🌟学习目标"></a>🌟学习目标</h2><ul><li><strong>目标</strong>：了解什么是 KNN 算法</li><li><strong>知道</strong>：KNN 算法求解过程</li></ul><h2 id="🌸1-什么是-K-近邻算法"><a href="#🌸1-什么是-K-近邻算法" class="headerlink" title="🌸1 什么是 K - 近邻算法"></a>🌸1 什么是 K - 近邻算法</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/%E5%9C%B0%E5%9B%BEK%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95.png" alt="Alt text"></p><p>根据你的 “邻居” 来推断出你的类别。</p><h3 id="🐾1-1-K-近邻算法-KNN-概念"><a href="#🐾1-1-K-近邻算法-KNN-概念" class="headerlink" title="🐾1.1 K - 近邻算法 (KNN) 概念"></a>🐾1.1 K - 近邻算法 (KNN) 概念</h3><p>K Nearest Neighbor 算法又叫 KNN 算法，这个算法是机器学习里面一个比较经典的算法，总体来说 KNN 算法是相对比较容易理解的算法。</p><h4 id="💡定义"><a href="#💡定义" class="headerlink" title="💡定义"></a>💡定义</h4><p>如果一个样本在特征空间中的 k 个最相似 (即特征空间中最邻近) 的样本中的大多数属于某一个类别，则该样本也属于这个类别。例如，在一个水果分类问题中，我们有一堆已知类别的水果样本（苹果、橙子等），对于一个未知类别的水果，我们通过计算它与已知水果样本的相似度（距离），找到最相似的 k 个样本，如果这 k 个样本中大多数是苹果，那么我们就可以推断这个未知水果也可能是苹果。</p><h4 id="🌟来源"><a href="#🌟来源" class="headerlink" title="🌟来源"></a>🌟来源</h4><p>KNN 算法最早是由 Cover 和 Hart 提出的一种分类算法。</p><h4 id="📏距离公式"><a href="#📏距离公式" class="headerlink" title="📏距离公式"></a>📏距离公式</h4><p>两个样本的距离可以通过如下公式计算，又叫欧式距离 。<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/%E6%AC%A7%E6%B0%8F%E8%B7%9D%E7%A6%BB.png" alt="Alt text"><br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/%E8%B7%9D%E7%A6%BB%E5%85%AC%E5%BC%8F.png" alt="Alt text"></p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">对于二维平面上点 a(x<span class="built_in">_</span>&#123;1&#125;, y<span class="built_in">_</span>&#123;1&#125;)与b(x<span class="built_in">_</span>&#123;2&#125;, y<span class="built_in">_</span>&#123;2&#125;) 之间的欧氏距离：</span><br><span class="line"><span class="keyword">\\</span> d<span class="built_in">_</span>&#123;12&#125; = <span class="keyword">\sqrt</span>&#123;(x<span class="built_in">_</span>1 - x<span class="built_in">_</span>2)<span class="built_in">^</span>2 + (y<span class="built_in">_</span>1 - y<span class="built_in">_</span>2)<span class="built_in">^</span>2&#125; </span><br><span class="line"><span class="keyword">\\</span>对于三维空间点 a(x<span class="built_in">_</span>&#123;1&#125;, y<span class="built_in">_</span>&#123;1&#125;, z<span class="built_in">_</span>&#123;1&#125;)与b(x<span class="built_in">_</span>&#123;2&#125;, y<span class="built_in">_</span>&#123;2&#125;, z<span class="built_in">_</span>&#123;2&#125;) 之间的欧氏距离：</span><br><span class="line"><span class="keyword">\\</span> d<span class="built_in">_</span>&#123;12&#125; = <span class="keyword">\sqrt</span>&#123;(x<span class="built_in">_</span>1 - x<span class="built_in">_</span>2)<span class="built_in">^</span>2 + (y<span class="built_in">_</span>1 - y<span class="built_in">_</span>2)<span class="built_in">^</span>2 + (z<span class="built_in">_</span>1 - z<span class="built_in">_</span>2)<span class="built_in">^</span>2&#125; </span><br><span class="line"><span class="keyword">\\</span>对于n维空间点 a(x<span class="built_in">_</span>&#123;11&#125;, x<span class="built_in">_</span>&#123;12&#125;, <span class="keyword">\ldots</span>, x<span class="built_in">_</span>&#123;1n&#125;)与b(x<span class="built_in">_</span>&#123;21&#125;, x<span class="built_in">_</span>&#123;22&#125;, <span class="keyword">\ldots</span>, x<span class="built_in">_</span>&#123;2n&#125;) 之间的欧氏距离（两个n维向量）：</span><br><span class="line"><span class="keyword">\\</span> d<span class="built_in">_</span>&#123;12&#125; = <span class="keyword">\sqrt</span>&#123;<span class="keyword">\sum</span><span class="built_in">_</span>&#123;k=1&#125;<span class="built_in">^</span>&#123;n&#125; (x<span class="built_in">_</span>&#123;1k&#125; - x<span class="built_in">_</span>&#123;2k&#125;)<span class="built_in">^</span>2&#125;</span><br></pre></td></tr></table></figure><h3 id="🍿1-2-电影类型分析"><a href="#🍿1-2-电影类型分析" class="headerlink" title="🍿1.2 电影类型分析"></a>🍿1.2 电影类型分析</h3><p>假设我们现在有几部电影（电影数据表格，包含电影名称、特征数据、类别等信息）。其中有一部 “？号电影” 不知道类别，如何去预测？我们可以利用 K 近邻算法的思想。</p><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/%E7%94%B5%E5%BD%B1%E4%B8%BE%E4%BE%8B.png" alt="Alt text"></p><p>分别计算每个电影和被预测电影的距离，然后求解。比如，我们可以从电影的多个特征（如搞笑镜头、拥抱镜头、打斗镜头等）来计算它们之间的距离。</p><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/%E7%94%B5%E5%BD%B1%E4%B8%BE%E4%BE%8B2.png" alt="Alt text"></p><p>假设我们已经计算出了各电影与 “？号电影” 的距离，如下表所示（示例数据）：<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/img/knn/%E7%94%B5%E5%BD%B1%E4%B8%BE%E4%BE%8B3.png" alt="Alt text"></p><h3 id="🐼分类过程🐠"><a href="#🐼分类过程🐠" class="headerlink" title="🐼分类过程🐠"></a>🐼分类过程🐠</h3><p>当 (K = 5) 时，从表格中可知距离《唐人街探案》最近的 5 部电影分别是《功夫熊猫》《美人鱼》《宝贝当家》《新步步惊心》《代理情人》。</p><ul><li>这 5 部电影中：</li><li>《功夫熊猫》《美人鱼》《宝贝当家》是喜剧片；</li><li>《新步步惊心》和《代理情人》是爱情片。</li></ul><p>喜剧片的数量为 3，爱情片的数量为 2。  根据 KNN 算法中多数表决的原则，在这 5 个最近邻中，喜剧片的数量占多数。</p><h3 id="🎬结论"><a href="#🎬结论" class="headerlink" title="🎬结论"></a>🎬结论</h3><p>通过 KNN 分析，预测《唐人街探案》的电影类型为喜剧片。因为在距离它最近的 5 部电影中，喜剧片的数量多于其他类型的电影数量。</p><h3 id="📈1-3-KNN-算法流程总结"><a href="#📈1-3-KNN-算法流程总结" class="headerlink" title="📈1.3 KNN 算法流程总结"></a>📈1.3 KNN 算法流程总结</h3><ol><li><strong>计算已知类别数据集中的点与当前点之间的距离</strong>：利用距离公式（如欧氏距离），计算每个已知样本点与待预测点的距离。</li><li><strong>按距离递增次序排序</strong>：将计算得到的距离从小到大进行排序。</li><li><strong>选取与当前点距离最小的 k 个点</strong>：从排序后的距离列表中，选取前 k 个最小距离对应的样本点。</li><li><strong>统计前 k 个点所在的类别出现的频率</strong>：查看这 k 个点分别属于哪些类别，并统计每个类别出现的次数。</li><li><strong>返回前 k 个点出现频率最高的类别作为当前点的预测分类</strong>：如果这 k 个点中属于动作片类别的点最多，那么就预测待预测电影为动作片。</li></ol><h2 id="🌈2-小结"><a href="#🌈2-小结" class="headerlink" title="🌈2 小结"></a>🌈2 小结</h2><ul><li><strong>K - 近邻算法简介【了解】</strong>：就是通过你的 “邻居” 来判断你属于哪个类别。</li><li><strong>如何计算你到你的 “邻居” 的距离</strong>：一般时候，都是使用欧氏距离。欧氏距离能够直观地衡量两个样本在特征空间中的距离远近，帮助我们找到最邻近的样本。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="机器学习" scheme="https://www.enju-tsubaki.icu/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="KNN" scheme="https://www.enju-tsubaki.icu/tags/KNN/"/>
    
  </entry>
  
</feed>
