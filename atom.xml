<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Coisini</title>
  
  <subtitle>一見旧知のようです、万千の歓喜心が生まれます</subtitle>
  <link href="https://www.enju-tsubaki.icu/atom.xml" rel="self"/>
  
  <link href="https://www.enju-tsubaki.icu/"/>
  <updated>2025-02-10T04:55:02.199Z</updated>
  <id>https://www.enju-tsubaki.icu/</id>
  
  <author>
    <name>Coisini</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hello World</title>
    <link href="https://www.enju-tsubaki.icu/posts/3610a686.html"/>
    <id>https://www.enju-tsubaki.icu/posts/3610a686.html</id>
    <published>2025-03-15T09:42:24.901Z</published>
    <updated>2025-02-10T04:55:02.199Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>🌟 <strong>简单的自我介绍</strong></p><p>大家好，我是 Coisini，来自古城西安，是陕西理工大学数计学院人工智能专业的学生。</p><p>🚀 <strong>编程的目标方向</strong></p><p>我对编程充满热情，尤其专注于人工智能领域的研究与应用，致力于探索机器学习和深度学习算法的潜力。通过结合Spring Boot框架，我能够快速构建稳定的应用程序，为AI算法的实际部署提供强有力的支持。利用MyBatis简化数据库操作，使我更专注于业务逻辑优化和算法实现，而Maven则帮助我高效管理项目依赖和构建过程，使开发更加流畅。每次攻克技术难题、掌握新概念，都让我感到极大的满足与成就，力求在AI技术的研究与实践中不断前进。</p><p>🌱 <strong>未来的学习方向</strong></p><p>在这个快速发展的时代，我立志于紧跟人工智能领域的前沿趋势，深入学习并掌握一系列关键技术，包括但不限于DeepSeek、Cursor、Dify、工作流、智能体以及知识库等。这些技术代表了当前AI技术发展的重要方向，它们不仅能够提升我的专业技能，也为解决复杂问题提供了新的思路和工具。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="个人简介" scheme="https://www.enju-tsubaki.icu/categories/%E4%B8%AA%E4%BA%BA%E7%AE%80%E4%BB%8B/"/>
    
    <category term="编程学习" scheme="https://www.enju-tsubaki.icu/categories/%E4%B8%AA%E4%BA%BA%E7%AE%80%E4%BB%8B/%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="人工智能" scheme="https://www.enju-tsubaki.icu/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="机器学习" scheme="https://www.enju-tsubaki.icu/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="https://www.enju-tsubaki.icu/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="SpringBoot" scheme="https://www.enju-tsubaki.icu/tags/SpringBoot/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch 入门指南2：Tensor 的深度解析（概念篇）</title>
    <link href="https://www.enju-tsubaki.icu/posts/ea1d749f.html"/>
    <id>https://www.enju-tsubaki.icu/posts/ea1d749f.html</id>
    <published>2025-03-15T08:45:12.803Z</published>
    <updated>2025-03-15T09:13:27.834Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="📚PyTorch-入门指南2：Tensor-的深度解析（概念篇）"><a href="#📚PyTorch-入门指南2：Tensor-的深度解析（概念篇）" class="headerlink" title="📚PyTorch 入门指南2：Tensor 的深度解析（概念篇）"></a>📚PyTorch 入门指南2：Tensor 的深度解析（概念篇）</h1><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/PyTorch%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.jpg" alt="PyTorch的基本概念"></p><p>在 PyTorch 框架里，<code>Tensor（张量）</code> 是核心数据结构之一，与 <code>Variable（autograd）</code>、<code>nn.Module</code> 共同构成 PyTorch 的基础概念体系。Tensor 本质是多维数组，是标量、向量、矩阵在高维空间的延伸，支持 GPU 加速计算，是深度学习模型构建的基础数据形式。</p><h2 id="🌐一、Tensor-的维度概念"><a href="#🌐一、Tensor-的维度概念" class="headerlink" title="🌐一、Tensor 的维度概念"></a>🌐一、Tensor 的维度概念</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/Tensor%20%E7%9A%84%E7%BB%B4%E5%BA%A6.jpg" alt="Tensor 的维度"></p><p>从维度视角理解，Tensor 包含以下典型形式：<img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/Tensor%E7%BB%B4%E5%BA%A6%E7%9F%A9%E9%98%B5.jpg" alt="Tensor维度矩阵"></p><ul><li>🔢<strong>标量（零维张量）</strong>：最基础的张量，仅有一个数值（如 3），代表零维数据。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scalar = torch.tensor(<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(scalar.shape)  <span class="comment"># 输出: torch.Size([])</span></span><br></pre></td></tr></table></figure><ul><li><p>📊<strong>向量（一维张量）</strong>：一维数组（如</p><script type="math/tex; mode=display">\begin{bmatrix}3 \\2 \\1 \\4\end{bmatrix}</script><p>)，用于表示线性数据，对应一维张量。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector = torch.tensor([<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line"><span class="built_in">print</span>(vector.shape)  <span class="comment"># 输出: torch.Size([4])</span></span><br></pre></td></tr></table></figure><ul><li><p>📄<strong>矩阵（二维张量）</strong>：具有行列结构的二维数组，形如 $n \times m$（如</p><script type="math/tex; mode=display">\begin{bmatrix}3 & 7 & 10 & 6 \\2 & 8 & 5 & 2 \\1 & 9 & 11 & 3 \\4 & 6 & 7 & 8\end{bmatrix}</script><p>)，是二维张量，用于表示平面数据。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">matrix = torch.tensor([</span><br><span class="line">    [<span class="number">3</span>, <span class="number">7</span>, <span class="number">10</span>, <span class="number">6</span>],</span><br><span class="line">    [<span class="number">2</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">2</span>],</span><br><span class="line">    [<span class="number">1</span>, <span class="number">9</span>, <span class="number">11</span>, <span class="number">3</span>],</span><br><span class="line">    [<span class="number">4</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line">])</span><br><span class="line"><span class="built_in">print</span>(matrix.shape)  <span class="comment"># 输出: torch.Size([4, 4])</span></span><br></pre></td></tr></table></figure><p><img src="https://i-blog.csdnimg.cn/direct/765fe9900b2b49f2b93e6733750b363b.jpeg#pic_center" alt="多维的扩展"></p><ul><li>🔭<strong>张量（多维扩展）</strong>：维度超过二维的统称，以三维张量为例，其形式为 ($n \times m \times C$)，表示在二维矩阵 ($n \times m$) 的基础上，沿着第三个维度（如通道、时间等）延伸出 $\mathbf{C}$ 个切片，形成立体结构。<br>例如：<ul><li>三维张量可表示立体数据（如视频帧序列 $T \times H \times W$，即时间 × 高度 × 宽度），其中每个二维切片$H \times W$对应一帧图像，沿时间维度延伸 $\mathbf{T}$ 个连续帧，共同构成三维张量。</li><li>彩色图像的维度为 $H \times W \times 3$(高度 × 宽度 × 通道数），其中每个二维切片$H \times W$对应红、绿、蓝三个颜色通道，沿通道维度组合形成三维张量。</li><li>更高维张量适用于复杂场景（如图像批量处理 $B \times H \times W \times C$，即批次 × 高度 × 宽度 × 通道数），其中每个四维张量由 B 个三维图像$H \times W \times C$沿批次维度堆叠，每个三维图像内部包含空间和通道信息。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 三维张量（时间 × 高度 × 宽度）</span></span><br><span class="line">video = torch.randn(<span class="number">10</span>, <span class="number">224</span>, <span class="number">224</span>)  <span class="comment"># 10帧，224×224像素</span></span><br><span class="line"><span class="comment"># 四维张量（批次 × 高度 × 宽度 × 通道）</span></span><br><span class="line">batch_images = torch.randn(<span class="number">32</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>)  <span class="comment"># 32张彩色图像</span></span><br></pre></td></tr></table></figure><p>总结来看，<strong>标量是零维张量，向量是一维张量，矩阵是二维张量</strong>，而张量本身是这些结构在高维空间的泛化，其维度形式可抽象为：</p><script type="math/tex; mode=display">\text{Tensor} = \underbrace{\text{标量}}_{0\text{D}} \rightarrow \underbrace{\text{向量}}_{1\text{D}} \rightarrow \underbrace{\text{矩阵}}_{2\text{D}} \rightarrow \underbrace{\text{高维张量}}_{3\text{D+}}</script><p>这种结构支撑着 PyTorch 数据存储、运算及模型训练的核心功能。</p><h2 id="🤖二、Tensor-与机器学习的关系"><a href="#🤖二、Tensor-与机器学习的关系" class="headerlink" title="🤖二、Tensor 与机器学习的关系"></a>🤖二、Tensor 与机器学习的关系</h2><p><img src="https://i-blog.csdnimg.cn/direct/23561b4d39bf4ee6bf9a09e768a0c8c1.png#pic_center" alt="Tensor 与机器学习的关系"></p><p>在机器学习领域，Tensor（张量）是核心数据结构之一，承载着数据表示与运算的关键功能。从机器学习模型的运行逻辑来看，样本数据与模型参数的交互依赖Tensor实现。例如经典的线性模型公式 <strong>Y = WX + b</strong>，其中输入样本 <strong>X</strong>、权重 <strong>W</strong>、偏置 <strong>b</strong> 以及输出 <strong>Y</strong> 均可由Tensor表示，机器学习框架通过对Tensor的高效运算完成模型训练与推理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用 PyTorch 实现线性模型</span></span><br><span class="line">X = torch.tensor([[<span class="number">1.0</span>], [<span class="number">2.0</span>], [<span class="number">3.0</span>]])  <span class="comment"># 输入特征（3样本 × 1特征）</span></span><br><span class="line">W = torch.tensor([[<span class="number">2.0</span>]], requires_grad=<span class="literal">True</span>)  <span class="comment"># 权重（1特征 × 1输出）</span></span><br><span class="line">b = torch.tensor([<span class="number">0.5</span>], requires_grad=<span class="literal">True</span>)  <span class="comment"># 偏置</span></span><br><span class="line">Y_pred = W * X + b  <span class="comment"># 计算预测值</span></span><br><span class="line"><span class="built_in">print</span>(Y_pred)  <span class="comment"># 输出: tensor([[2.5000], [4.5000], [6.5000]])</span></span><br></pre></td></tr></table></figure><h3 id="💼Tensor在机器学习中的核心价值"><a href="#💼Tensor在机器学习中的核心价值" class="headerlink" title="💼Tensor在机器学习中的核心价值"></a>💼Tensor在机器学习中的核心价值</h3><ol><li>📂<strong>数据表示</strong>：<br>多维统一：用 Tensor 表示图像（3D）、文本（序列）、视频（4D）等高维数据，支持批量处理。<br>参数存储：神经网络的权重和偏置以 Tensor 形式存储，便于优化和保存。</li><li>🚀<strong>运算与加速</strong>：<br>数学运算：支持矩阵乘法、卷积等操作，适配神经网络的复杂计算需求。<br>硬件优化：直接在 GPU/TPU 上运行，通过并行计算加速模型训练（如 ResNet 训练时间从天级缩短至小时级）。</li><li>🔗<strong>框架生态与功能</strong>：<br>自动微分：PyTorch/TensorFlow 通过 Tensor 自动推导梯度，简化反向传播实现。<br>动态计算图：允许运行时调整模型结构（如条件分支），提升灵活性。<br>广播与维度：隐式扩展维度，避免手动处理形状（如标量与矩阵相加）。</li></ol><h2 id="✨三、Tensor-的核心优势"><a href="#✨三、Tensor-的核心优势" class="headerlink" title="✨三、Tensor 的核心优势"></a>✨三、Tensor 的核心优势</h2><ol><li>🌈<strong>统一表示</strong>：用单一数据结构承载所有类型的数据，降低开发复杂度。</li><li>⚡<strong>硬件无关性</strong>：代码可在 CPU、GPU 甚至分布式集群上无缝运行。</li><li>🌱<strong>生态整合</strong>：与 PyTorch 的 <code>nn.Module</code>、<code>autograd</code> 等模块深度集成，支持端到端的模型开发。</li></ol><h2 id="🎯四、总结"><a href="#🎯四、总结" class="headerlink" title="🎯四、总结"></a>🎯四、总结</h2><p>Tensor 不仅是 PyTorch 的基础数据结构，更是机器学习算法的“血液”。通过维度扩展、硬件加速和框架生态整合，Tensor 实现了从原始数据到智能模型的高效转化。下一篇文章将聚焦 Tensor 的创建方式与核心属性，帮助读者掌握其编程实践技巧。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="深度学习" scheme="https://www.enju-tsubaki.icu/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="pytorch" scheme="https://www.enju-tsubaki.icu/tags/pytorch/"/>
    
    <category term="tensor" scheme="https://www.enju-tsubaki.icu/tags/tensor/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch 入门指南1：机器学习基础</title>
    <link href="https://www.enju-tsubaki.icu/posts/b2b2014e.html"/>
    <id>https://www.enju-tsubaki.icu/posts/b2b2014e.html</id>
    <published>2025-03-09T05:13:54.693Z</published>
    <updated>2025-03-09T05:28:49.637Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🐍-PyTorch-入门指南-1：机器学习基础"><a href="#🐍-PyTorch-入门指南-1：机器学习基础" class="headerlink" title="🐍 PyTorch 入门指南 1：机器学习基础"></a>🐍 PyTorch 入门指南 1：机器学习基础</h1><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98.png" alt="机器学习的核心问题"></p><h2 id="🔍一、机器学习的核心问题：分类与回归"><a href="#🔍一、机器学习的核心问题：分类与回归" class="headerlink" title="🔍一、机器学习的核心问题：分类与回归"></a>🔍一、机器学习的核心问题：分类与回归</h2><h3 id="🎯1-1-分类问题：离散标签的预测"><a href="#🎯1-1-分类问题：离散标签的预测" class="headerlink" title="🎯1.1 分类问题：离散标签的预测"></a>🎯1.1 分类问题：离散标签的预测</h3><p><strong>定义</strong>：分类任务旨在将输入数据划分到有限个离散的类别中。模型通过学习数据特征，输出样本属于各个类别的概率或直接判定类别。</p><ul><li><strong>数学形式</strong>：给定输入特征向量$\mathbf{x}$，模型学习映射$f: \mathbf{x} \to y$，其中 $y$  是离散类别（如$y \in {0, 1, 2, \dots, C-1}$)，$C$为类别总数）。</li><li><strong>应用场景</strong>：垃圾邮件识别（垃圾/非垃圾）、图像分类（如图二中“airplane”“automobile”等类别判断）。<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/%E5%88%86%E7%B1%BB.png" alt="分类"></li><li><strong>输出特点</strong>：以图二为例，模型输出概率向量 <code>[0.1, 0.1, 0.1, 0.1, 0, 0, 0, 0.5, 0.1, 0]</code>，表示样本属于 10 个类别的概率，最终选择概率最高的类别（第 8 类，概率 0.5）作为预测结果。</li></ul><h3 id="📈1-2-回归问题：连续值的预测"><a href="#📈1-2-回归问题：连续值的预测" class="headerlink" title="📈1.2 回归问题：连续值的预测"></a>📈1.2 回归问题：连续值的预测</h3><p><strong>定义</strong>：回归任务用于预测连续的数值型结果，关注输入与输出之间的定量关系。</p><ul><li><strong>数学形式</strong>：模型学习映射$f: \mathbf{x} \to y$，其中$y$是连续数值（如房价、股票价格涨幅）。</li><li><strong>应用场景</strong>：图三的股票数据预测，通过历史交易数据（开盘价、成交量等特征）预测股票指数（如 2991.56 点）或涨幅（+0.54%）。<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/%E5%9B%9E%E5%BD%92.png" alt="回归"></li><li><strong>输出特点</strong>：直接输出连续数值，用于描述趋势或具体量值，无类别划分。</li></ul><h3 id="🔀1-3-分类与回归的核心区别"><a href="#🔀1-3-分类与回归的核心区别" class="headerlink" title="🔀1.3 分类与回归的核心区别"></a>🔀1.3 分类与回归的核心区别</h3><div class="table-container"><table><thead><tr><th>维度</th><th>分类问题</th><th>回归问题</th></tr></thead><tbody><tr><td>目标输出</td><td>离散类别</td><td>连续数值</td></tr><tr><td>评价指标</td><td>准确率、精确率、召回率等</td><td>均方误差（MSE）、平均绝对误差（MAE）等</td></tr><tr><td>典型模型</td><td>逻辑回归、决策树、神经网络分类器</td><td>线性回归、随机森林回归、神经网络回归</td></tr></tbody></table></div><hr><h2 id="🖼️二、分类问题实战：图像分类案例分析"><a href="#🖼️二、分类问题实战：图像分类案例分析" class="headerlink" title="🖼️二、分类问题实战：图像分类案例分析"></a>🖼️二、分类问题实战：图像分类案例分析</h2><h3 id="📁2-1-图像分类任务流程"><a href="#📁2-1-图像分类任务流程" class="headerlink" title="📁2.1 图像分类任务流程"></a>📁2.1 图像分类任务流程</h3><ol><li><strong>数据准备</strong>：收集标注好的图像数据集（如图二中包含“airplane”“bird”“cat”等类别的图像）。</li><li><strong>特征提取</strong>：通过卷积神经网络（CNN）提取图像的纹理、形状等高层特征。</li><li><strong>模型训练</strong>：使用分类模型（如 ResNet、VGG）学习特征与类别的映射关系。</li><li><strong>预测推断</strong>：输入新图像，模型输出类别概率向量，选择概率最高的类别作为结果。</li></ol><h3 id="📋2-2-输出向量解读"><a href="#📋2-2-输出向量解读" class="headerlink" title="📋2.2 输出向量解读"></a>📋2.2 输出向量解读</h3><p>图二中的概率向量 <code>[0.1, 0.1, 0.1, 0.1, 0, 0, 0, 0.5, 0.1, 0]</code> 表示：</p><ul><li>向量长度对应类别总数（10 类）；</li><li>每个元素值表示属于对应类别的概率，数值越大，属于该类的可能性越高。</li></ul><hr><h2 id="📉三、回归问题实战：股票数据预测"><a href="#📉三、回归问题实战：股票数据预测" class="headerlink" title="📉三、回归问题实战：股票数据预测"></a>📉三、回归问题实战：股票数据预测</h2><h3 id="📊3-1-股票数据特征与目标"><a href="#📊3-1-股票数据特征与目标" class="headerlink" title="📊3.1 股票数据特征与目标"></a>📊3.1 股票数据特征与目标</h3><ul><li><strong>输入特征</strong>：图三中的“今开”“昨收”“成交量”“成交额”等数据，构成特征向量$\mathbf{x}$。</li><li><strong>预测目标</strong>：股票指数（如 2991.56）、涨幅（+0.54%）等连续值。</li></ul><h3 id="🚀3-2-回归模型构建思路"><a href="#🚀3-2-回归模型构建思路" class="headerlink" title="🚀3.2 回归模型构建思路"></a>🚀3.2 回归模型构建思路</h3><ol><li><strong>数据预处理</strong>：对时间序列数据进行归一化、滑动窗口处理（提取历史序列特征）。</li><li><strong>模型选择</strong>：使用线性回归、LSTM（处理时序数据）或 Transformer 模型。</li><li><strong>训练优化</strong>：以均方误差为损失函数，优化模型参数，拟合数据规律。</li></ol><hr><h2 id="🧩四、机器学习问题的构成元素"><a href="#🧩四、机器学习问题的构成元素" class="headerlink" title="🧩四、机器学习问题的构成元素"></a>🧩四、机器学习问题的构成元素</h2><p>如图四所示，机器学习问题由以下核心元素构成：<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98%E7%9A%84%E6%9E%84%E6%88%90%E5%85%83%E7%B4%A0.png" alt="机器学习问题的构成元素"></p><h3 id="📇4-1-样本（数据）"><a href="#📇4-1-样本（数据）" class="headerlink" title="📇4.1 样本（数据）"></a>📇4.1 样本（数据）</h3><ul><li><strong>定义</strong>：用于训练和测试的数据集，包含特征（输入）和标签（输出）。</li><li><strong>作用</strong>：模型通过学习样本数据，捕捉数据中的潜在规律。例如图像分类的样本是“图像特征+类别标签”，股票回归的样本是“交易特征+价格标签”。</li></ul><h3 id="🤖4-2-模型"><a href="#🤖4-2-模型" class="headerlink" title="🤖4.2 模型"></a>🤖4.2 模型</h3><ul><li><strong>定义</strong>：描述输入与输出关系的数学结构，如线性模型、神经网络、决策树等。</li><li><strong>设计原则</strong>：根据任务类型选择模型（分类用 Softmax 输出，回归用线性输出），平衡模型复杂度与泛化能力。</li></ul><h3 id="🔄4-3-训练"><a href="#🔄4-3-训练" class="headerlink" title="🔄4.3 训练"></a>🔄4.3 训练</h3><ul><li><strong>流程</strong>：<ol><li>定义损失函数（分类用交叉熵，回归用均方误差）；</li><li>选择优化器（如 SGD、Adam）；</li><li>通过反向传播调整模型参数，最小化损失。</li></ol></li><li><strong>目标</strong>：让模型在训练样本上学习到正确的映射关系。</li></ul><h3 id="🌟4-4-测试"><a href="#🌟4-4-测试" class="headerlink" title="🌟4.4 测试"></a>🌟4.4 测试</h3><ul><li><strong>作用</strong>：使用未参与训练的测试样本评估模型性能，验证模型的泛化能力。</li><li><strong>指标</strong>：分类任务关注准确率，回归任务关注 MSE 等。</li></ul><h3 id="🌌4-5-推理"><a href="#🌌4-5-推理" class="headerlink" title="🌌4.5 推理"></a>🌌4.5 推理</h3><ul><li><strong>定义</strong>：使用训练好的模型对新数据进行预测，输出分类结果或回归值。</li><li><strong>应用</strong>：部署模型到实际场景（如股票预测系统、图像分类APP），提供实时预测服务。</li></ul><hr><h2 id="🎉五、总结"><a href="#🎉五、总结" class="headerlink" title="🎉五、总结"></a>🎉五、总结</h2><p>机器学习通过解决分类与回归问题，赋能图像识别、金融预测等众多领域。理解分类与回归的本质区别，掌握样本、模型、训练等构成元素，是构建高效机器学习系统的基础。无论是处理离散类别还是连续数值，围绕核心元素设计流程，才能让模型在实际场景中发挥价值。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="深度学习" scheme="https://www.enju-tsubaki.icu/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="pytorch" scheme="https://www.enju-tsubaki.icu/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>线性回归的优化</title>
    <link href="https://www.enju-tsubaki.icu/posts/7f94e68d.html"/>
    <id>https://www.enju-tsubaki.icu/posts/7f94e68d.html</id>
    <published>2025-03-04T06:47:54.849Z</published>
    <updated>2025-03-08T10:56:49.611Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🐰线性回归优化😜"><a href="#🐰线性回归优化😜" class="headerlink" title="🐰线性回归优化😜"></a>🐰线性回归优化😜</h1><p>在机器学习的领域中，线性回归作为一种基础且重要的算法，有着广泛的应用。然而，在实际运用过程中，我们常常会遇到欠拟合和过拟合的问题，它们如同拦路虎一般，影响着模型的性能。接下来，就让我们深入了解这两个问题以及如何对线性回归进行优化。</p><h2 id="🐱‍🏍一、欠拟合与过拟合的定义"><a href="#🐱‍🏍一、欠拟合与过拟合的定义" class="headerlink" title="🐱‍🏍一、欠拟合与过拟合的定义"></a>🐱‍🏍一、欠拟合与过拟合的定义</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%AC%A0%E6%8B%9F%E5%90%88%E8%BF%87%E6%8B%9F%E5%90%88%E5%9B%BE%E7%A4%BA.png" alt="Alt text"></p><h3 id="🐻（一）过拟合"><a href="#🐻（一）过拟合" class="headerlink" title="🐻（一）过拟合"></a>🐻（一）过拟合</h3><p>过拟合指的是一个假设在训练数据上能够获得比其他假设更好的拟合效果，但是在测试数据集上却不能很好地拟合数据。这通常是因为模型过于复杂，它努力去适应训练数据中的每一个细节，包括一些噪声，从而导致在面对新数据时缺乏泛化能力。比如，在一个预测房价的模型中，如果模型把训练数据中某几个特殊房子的独特特征（如房子旁边恰好有个独特的小雕塑）过度学习，而这些特征并非普遍影响房价的因素，那么在遇到没有这个小雕塑的房子时，模型的预测就会出现偏差。</p><h3 id="🐼（二）欠拟合"><a href="#🐼（二）欠拟合" class="headerlink" title="🐼（二）欠拟合"></a>🐼（二）欠拟合</h3><p>欠拟合则是一个假设在训练数据上不能获得良好的拟合，并且在测试数据集上同样不能很好地拟合数据。原因是模型过于简单，无法捕捉到数据中的足够特征和规律。继续以房价预测为例，如果模型仅仅考虑房子的面积这一个特征，而忽略了诸如房间数量、地段等其他重要因素，那么它对房价的预测结果必然是不准确的，这就是典型的欠拟合现象。</p><h2 id="🐥二、欠拟合与过拟合的原因及解决办法"><a href="#🐥二、欠拟合与过拟合的原因及解决办法" class="headerlink" title="🐥二、欠拟合与过拟合的原因及解决办法"></a>🐥二、欠拟合与过拟合的原因及解决办法</h2><h3 id="🐶（一）欠拟合"><a href="#🐶（一）欠拟合" class="headerlink" title="🐶（一）欠拟合"></a>🐶（一）欠拟合</h3><h4 id="🐹1-原因"><a href="#🐹1-原因" class="headerlink" title="🐹1. 原因"></a>🐹1. 原因</h4><p>学习到的数据特征过少，无法全面描述数据中的规律和关系。</p><h4 id="🐰2-解决办法"><a href="#🐰2-解决办法" class="headerlink" title="🐰2. 解决办法"></a>🐰2. 解决办法</h4><ul><li><strong>添加其他特征项</strong>：有时候模型欠拟合是因为特征项不够丰富。我们可以添加多种类型的特征，例如 “组合” 特征（如将房子的面积和房间数量组合成一个新特征，表示单位房间的平均面积）、“泛化” 特征（从一些具体特征中抽象出更宽泛的特征，如将房子所在街道名称泛化为所在区域）、“相关性” 特征（找出与房价有潜在关联的特征，如附近学校的质量）。此外，“上下文特征”（如房子所在小区的整体环境描述）、“平台特征”（如果数据来源于某个特定平台，平台相关的属性特征）等也可以作为添加的选项。</li><li><strong>添加多项式特征</strong>：在机器学习算法中，这是一种常用的手段。比如对于线性模型，我们可以通过添加二次项（如面积的平方）或者三次项（如面积的立方），让模型能够学习到更复杂的关系，从而增强模型的泛化能力。</li></ul><h3 id="🐱（二）过拟合"><a href="#🐱（二）过拟合" class="headerlink" title="🐱（二）过拟合"></a>🐱（二）过拟合</h3><h4 id="🐭1-原因"><a href="#🐭1-原因" class="headerlink" title="🐭1. 原因"></a>🐭1. 原因</h4><p>原始特征过多，其中存在一些嘈杂的特征，导致模型过于复杂，试图去兼顾各个测试数据点，包括噪声点，从而失去了对整体数据趋势的把握。</p><h4 id="🐮2-解决办法"><a href="#🐮2-解决办法" class="headerlink" title="🐮2. 解决办法"></a>🐮2. 解决办法</h4><ul><li><strong>重新清洗数据</strong>：数据不纯可能是导致过拟合的一个原因。如果数据中存在错误标注、异常值或者大量重复数据等杂质，模型在学习过程中可能会受到干扰，从而产生过拟合。此时，重新清洗数据，去除这些杂质，能够让模型学习到更准确的模式。</li><li><strong>增大数据的训练量</strong>：当用于训练的数据量太小，训练数据占总数据的比例过小时，模型可能无法充分学习到数据的全貌和规律，容易对训练数据中的噪声过度拟合。增加训练数据量，可以让模型看到更多的样本，从而更好地泛化到新的数据上。</li><li><strong>正则化</strong>：这是一种重要的防止过拟合的方法，通过对模型的参数进行约束，使得模型在拟合数据的同时，尽量保持简单。下面我们会详细介绍正则化的相关内容。</li><li><strong>减少特征维度</strong>：过多的特征维度可能会引发维灾难，导致模型复杂度增加和过拟合风险上升。我们可以通过一些特征选择的方法，去除那些对模型贡献不大或者相关性过高的特征，降低特征维度，提高模型的性能。</li></ul><h2 id="🐷三、正则化：防止过拟合的神奇魔法棒"><a href="#🐷三、正则化：防止过拟合的神奇魔法棒" class="headerlink" title="🐷三、正则化：防止过拟合的神奇魔法棒"></a>🐷三、正则化：防止过拟合的神奇魔法棒</h2><h3 id="🐸（一）什么是正则化"><a href="#🐸（一）什么是正则化" class="headerlink" title="🐸（一）什么是正则化"></a>🐸（一）什么是正则化</h3><p>在解决回归过拟合问题时，我们常常会选择正则化。实际上，对于其他机器学习算法如分类算法，同样可能出现过拟合问题，除了一些算法本身具有防止过拟合的机制（如决策树通过剪枝、神经网络通过一些结构设计和训练技巧）外，我们更多时候需要自己进行特征选择。</p><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%A8%A1%E5%9E%8B%E5%A4%8D%E6%9D%82.png" alt="Alt text"></p><p><strong>如何解决？</strong></p><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%AD%A3%E5%88%99%E5%8C%96.png" alt="Alt text"></p><p>正则化的核心思想是，在学习过程中，当数据提供的某些特征对模型复杂度有较大影响或者这些特征的数据点异常较多时，算法会尽量减少这些特征的影响，甚至删除某个特征的影响。不过需要注意的是，算法在调整时并不知道具体是哪个特征产生影响，而是通过调整参数来达到优化的结果。</p><h3 id="🐯（二）正则化类别"><a href="#🐯（二）正则化类别" class="headerlink" title="🐯（二）正则化类别"></a>🐯（二）正则化类别</h3><h4 id="🐴1-L2-正则化"><a href="#🐴1-L2-正则化" class="headerlink" title="🐴1. L2 正则化"></a>🐴1. L2 正则化</h4><ul><li><strong>作用</strong>：可以使得模型中的一些权重系数 W 都变得很小，接近于 0，从而削弱某个特征的影响。例如在房价预测中，如果某个特征（如房子旁边树木的数量）对房价的影响较小，通过 L2 正则化，该特征对应的权重系数就会被调整得很小。</li><li><strong>优点</strong>：越小的参数说明模型越简单，而越简单的模型则越不容易产生过拟合现象。这是因为简单模型不会过于复杂地去拟合训练数据中的噪声和特殊情况，能够更好地捕捉数据的整体趋势，从而在新数据上有更好的泛化能力。以岭回归（Ridge Regression）为代表的模型应用了 L2 正则化。</li></ul><h4 id="🐵2-L1-正则化"><a href="#🐵2-L1-正则化" class="headerlink" title="🐵2. L1 正则化"></a>🐵2. L1 正则化</h4><ul><li><strong>作用</strong>：可以使得其中一些权重系数 W 的值直接变为 0，相当于删除了这个特征的影响。比如在众多影响房价的特征中，如果某个特征（如房子窗户的颜色）实际上与房价并无关联，L1 正则化可能会将其对应的权重系数置为 0，从而在模型中去除这个无关特征。</li><li><strong>代表模型</strong>：LASSO 回归（Least Absolute Shrinkage and Selection Operator Regression）是应用 L1 正则化的典型模型。LASSO 回归有一个重要性质，它倾向于完全消除不重要的权重。当正则化参数 α 取值相对较大时，高阶多项式退化为二次甚至线性，即高阶多项式特征的权重被置为 0，能够自动进行特征选择，并输出一个稀疏模型（只有少数特征的权重是非零的）。</li></ul><h2 id="🐝四、正则化线性模型"><a href="#🐝四、正则化线性模型" class="headerlink" title="🐝四、正则化线性模型"></a>🐝四、正则化线性模型</h2><h3 id="🐛（一）岭回归（Ridge-Regression，又名-Tikhonov-regularization）"><a href="#🐛（一）岭回归（Ridge-Regression，又名-Tikhonov-regularization）" class="headerlink" title="🐛（一）岭回归（Ridge Regression，又名 Tikhonov regularization）"></a>🐛（一）岭回归（Ridge Regression，又名 Tikhonov regularization）</h3><p>岭回归是线性回归的正则化版本，它在原来线性回归的代价函数中添加了正则项（regularization term）。其代价函数为：</p><script type="math/tex; mode=display">J(\theta) = MSE(\theta) + \alpha \frac{1}{2} \sum_{i=1}^{n} \theta_{i}^{2}</script><p>，其中 $ MSE(\theta)$ 是均方误差，α 是正则化参数，$  \theta_{i}$是模型的权重系数。当 α = 0 时，岭回归退化为线性回归。岭回归的目的是在拟合数据的同时，使模型权重尽可能小，从而防止过拟合。在 Python 的 scikit - learn 库中，可以使用<code>Ridge</code>类来实现岭回归：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line">estimator = Ridge(alpha = <span class="number">1.0</span>, fit_intercept = <span class="literal">True</span>, solver = <span class="string">&quot;auto&quot;</span>, normalize = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure><ul><li><code>alpha</code>：正则化力度，也叫 λ，取值范围一般为 0~1 或 1~10 等，值越大，正则化力度越强，权重系数会越小；值越小，正则化力度越弱，权重系数会越大。</li><li><code>solver</code>：会根据数据自动选择优化方法，例如当数据集和特征都比较大时，可以选择<code>sag</code>随机梯度下降优化方法。</li><li><code>normalize</code>：数据是否进行标准化，<code>normalize = False</code>时，可以在<code>fit</code>之前调用<code>preprocessing.StandardScaler</code>对数据进行标准化处理。</li><li><code>Ridge.coef_</code>：可以获取回归权重。</li><li><code>Ridge.intercept_</code>：可以获取回归偏置。</li></ul><p>Ridge 方法相当于 SGDRegressor (penalty=’l2’, loss=”squared_loss”)，只不过 SGDRegressor 实现了一个普通的随机梯度下降学习，推荐使用 Ridge (实现了 SAG)。</p><p>另外，<code>sklearn.linear_model.RidgeCV(_BaseRidgeCV, RegressorMixin)</code>是具有 l2 正则化且可以进行交叉验证的线性回归。其中：</p><ul><li><code>coef_</code>可获取回归系数。</li><li><code>class _BaseRidgeCV(LinearModel)</code>的初始化参数有<code>alphas=(0.1, 1.0, 10.0)</code>（用于指定交叉验证时尝试的不同正则化参数值），<code>fit_intercept=True</code>（是否计算截距），<code>normalize=False</code>（数据是否标准化），<code>scoring=None</code>（用于指定评估指标），<code>cv=None</code>（交叉验证折数），<code>gcv_mode=None</code>，<code>store_cv_values=False</code>（是否存储交叉验证的详细结果） 。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">_BaseRidgeCV</span>(<span class="title class_ inherited__">LinearModel</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, alphas=(<span class="params"><span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">10.0</span></span>),</span></span><br><span class="line"><span class="params">                 fit_intercept=<span class="literal">True</span>, normalize=<span class="literal">False</span>,scoring=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 cv=<span class="literal">None</span>, gcv_mode=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 store_cv_values=<span class="literal">False</span></span>):</span><br></pre></td></tr></table></figure><h3 id="🐙（二）Lasso-回归（Lasso-Regression）"><a href="#🐙（二）Lasso-回归（Lasso-Regression）" class="headerlink" title="🐙（二）Lasso 回归（Lasso Regression）"></a>🐙（二）Lasso 回归（Lasso Regression）</h3><p>Lasso 回归是线性回归的另一种正则化版本，其正则项为权值向量的ℓ1 范数，代价函数为：</p><script type="math/tex; mode=display">J(\theta) = MSE(\theta) + \alpha \sum_{i=1}^{n} |\theta_{i}|</script><p>需要注意的是，Lasso 回归的代价函数在$\theta<em>{i} = 0$处是不可导的。解决方法是在$ \theta</em>{i} = 0$处用一个次梯度向量（subgradient vector）代替梯度。</p><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/lasso%E5%9B%9E%E5%BD%92.png" alt="Alt text"></p><p>Lasso 回归具有能够自动进行特征选择的重要性质，当 α 取值相对较大时，高阶多项式退化为二次甚至线性，高阶多项式特征的权重被置为 0，输出一个稀疏模型。在 scikit - learn 库中，可以使用<code>Lasso</code>类来实现 Lasso 回归：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line">estimator = Lasso(alpha = <span class="number">1.0</span>, fit_intercept = <span class="literal">True</span>, normalize = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h3 id="🐚（三）弹性网络（Elastic-Net）"><a href="#🐚（三）弹性网络（Elastic-Net）" class="headerlink" title="🐚（三）弹性网络（Elastic Net）"></a>🐚（三）弹性网络（Elastic Net）</h3><p>弹性网络是在岭回归和 Lasso 回归之间进行了折中，通过混合比（mix ratio）r 进行控制。</p><p>弹性网络的代价函数为：</p><script type="math/tex; mode=display">J(\theta) = MSE(\theta) + r\alpha \sum_{i=1}^{n} |\theta_{i}| + (1 - r)\alpha \frac{1}{2} \sum_{i=1}^{n} \theta_{i}^{2}</script><ul><li>其中 r 是混合比。</li><li>当 r = 0 时，弹性网络变为岭回归，主要通过 L2 正则化来约束权重。</li><li>当 r = 1 时，弹性网络变为 Lasso 回归，主要利用 L1 正则化来筛选特征。<br>弹性网络结合了岭回归和 Lasso 回归的优点，在一些情况下能够表现得更加稳定和优秀。例如在特征维度高于训练样本数，或者特征是强相关的情况下，Lasso 回归的表现可能不太稳定，此时弹性网络可能是更好的选择。</li></ul><p>在 scikit - learn 库中，可以使用<code>ElasticNet</code>类来实现弹性网络：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> ElasticNet</span><br><span class="line">estimator = ElasticNet(alpha = <span class="number">1.0</span>, l1_ratio = <span class="number">0.5</span>, fit_intercept = <span class="literal">True</span>, normalize = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure><ul><li><code>l1_ratio</code>：对应混合比 r，取值范围为 0~1。</li></ul><p>一般来说，在实际应用中，我们应避免使用朴素线性回归，而应对模型进行一定的正则化处理。通常情况下，岭回归较为常用；如果假设只有少部分特征是有用的，弹性网络和 Lasso 回归是不错的选择，不过一般弹性网络的使用更为广泛，因为在一些复杂的数据情况下（如特征维度高于训练样本数，或者特征是强相关的情况），Lasso 回归的表现不太稳定。</p><h3 id="🐠（四）Early-Stopping（了解）"><a href="#🐠（四）Early-Stopping（了解）" class="headerlink" title="🐠（四）Early Stopping（了解）"></a>🐠（四）Early Stopping（了解）</h3><p>Early Stopping 也是正则化迭代学习的方法之一。其做法是在验证错误率达到最小值的时候停止训练。在训练模型时，随着训练的进行，模型在训练集上的误差通常会不断下降，但在验证集上的误差可能会先下降后上升，这是过拟合的一个信号。Early Stopping 通过监控验证集上的误差，当误差不再下降（或开始上升）时，就停止训练，防止模型过度拟合训练数据。虽然 scikit - learn 库中没有专门的 Early Stopping 类用于线性回归的直接实现，但在一些深度学习框架（如 TensorFlow、PyTorch）中，很容易实现 Early Stopping 机制来优化模型训练过程。</p><h2 id="🧐观察正则化程度的变化，对结果的影响？"><a href="#🧐观察正则化程度的变化，对结果的影响？" class="headerlink" title="🧐观察正则化程度的变化，对结果的影响？"></a>🧐观察正则化程度的变化，对结果的影响？</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%AD%A3%E5%88%99%E5%8C%96%E5%8A%9B%E5%BA%A6.png" alt="Alt text"></p><ul><li>正则化力度越大，权重系数会越小</li><li>正则化力度越小，权重系数会越大</li></ul><h2 id="🐣五、线性回归的改进-岭回归案例"><a href="#🐣五、线性回归的改进-岭回归案例" class="headerlink" title="🐣五、线性回归的改进 - 岭回归案例"></a>🐣五、线性回归的改进 - 岭回归案例</h2><p>下面我们通过一个具体的案例来展示岭回归在波士顿房价预测中的应用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">linear_ridgeModel</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    线性回归:岭回归</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1.获取数据</span></span><br><span class="line">    data = load_boston()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.数据集划分</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, random_state = <span class="number">22</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.特征工程-标准化</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.fit_transform(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.机器学习-线性回归(岭回归)</span></span><br><span class="line">    estimator = Ridge(alpha = <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># estimator = RidgeCV(alphas=(0.1, 1, 10))</span></span><br><span class="line">    estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.模型评估</span></span><br><span class="line">    <span class="comment"># 5.1 获取系数等值</span></span><br><span class="line">    y_predict = estimator.predict(x_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;预测值为:\n&quot;</span>, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型中的系数为:\n&quot;</span>, estimator.coef_)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型中的偏置为:\n&quot;</span>, estimator.intercept_)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.2 评价</span></span><br><span class="line">    <span class="comment"># 均方误差</span></span><br><span class="line">    error = mean_squared_error(y_test, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;误差为:\n&quot;</span>, error)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    linear_ridgeModel()</span><br></pre></td></tr></table></figure><p>在这个案例中，我们首先加载了波士顿房价数据集，然后将其划分为训练集和测试集。接着对数据进行标准化处理，这有助于提高模型的训练效果和收敛速度。之后使用岭回归模型进行训练，并对模型进行评估，通过均方误差来衡量模型的预测准确性。</p><h2 id="🐤六、模型的保存和加载"><a href="#🐤六、模型的保存和加载" class="headerlink" title="🐤六、模型的保存和加载"></a>🐤六、模型的保存和加载</h2><p>在机器学习中，我们常常需要保存训练好的模型，以便在后续的应用中直接加载使用，而无需重新训练。在 scikit - learn 库中，可以使用<code>joblib</code>工具来实现模型的保存和加载。</p><h3 id="🐧（一）API"><a href="#🐧（一）API" class="headerlink" title="🐧（一）API"></a>🐧（一）API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br></pre></td></tr></table></figure><ul><li><strong>保存</strong>：<code>joblib.dump(estimator, &#39;test.pkl&#39;)</code>，其中<code>estimator</code>是训练好的模型对象，<code>&#39;test.pkl&#39;</code>是保存模型的文件名，注意保存文件的后缀名一般是<code>.pkl</code>。</li><li><strong>加载</strong>：<code>estimator = joblib.load(&#39;test.pkl&#39;)</code>，通过<code>joblib.load</code>方法将保存的模型加载到内存中，并赋值给一个变量<code>estimator</code>，后续就可以使用这个模型进行预测等操作。</li></ul><h3 id="🐳（二）线性回归的模型保存加载案例"><a href="#🐳（二）线性回归的模型保存加载案例" class="headerlink" title="🐳（二）线性回归的模型保存加载案例"></a>🐳（二）线性回归的模型保存加载案例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_dump_demo</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    模型保存和加载</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1.获取数据</span></span><br><span class="line">    data = load_boston()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.数据集划分</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.特征工程-标准化</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.fit_transform(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.机器学习-线性回归(岭回归)</span></span><br><span class="line">    <span class="comment"># # 4.1 模型训练</span></span><br><span class="line">    <span class="comment"># estimator = Ridge(alpha=1)</span></span><br><span class="line">    <span class="comment"># estimator.fit(x_train, y_train)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># # 4.2 模型保存</span></span><br><span class="line">    <span class="comment"># joblib.dump(estimator, &quot;./data/test.pkl&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.3 模型加载</span></span><br><span class="line">    estimator = joblib.load(<span class="string">&quot;./data/test.pkl&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.模型评估</span></span><br><span class="line">    <span class="comment"># 5.1 获取系数等值</span></span><br><span class="line">    y_predict = estimator.predict(x_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;预测值为:\n&quot;</span>, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型中的系数为:\n&quot;</span>, estimator.coef_)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型中的偏置为:\n&quot;</span>, estimator.intercept_)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.2 评价</span></span><br><span class="line">    <span class="comment"># 均方误差</span></span><br><span class="line">    error = mean_squared_error(y_test, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;误差为:\n&quot;</span>, error)</span><br></pre></td></tr></table></figure><p>在这个案例中，我们可以选择先训练模型并保存，也可以直接加载已经保存好的模型进行评估。模型保存和加载功能在实际应用中非常实用，比如在生产环境中，我们可以将训练好的稳定模型保存下来，随时加载用于对新数据的预测；或者在不同的项目中复用已经训练好的模型，节省训练时间和计算资源。</p><h2 id="🐾总结"><a href="#🐾总结" class="headerlink" title="🐾总结"></a>🐾总结</h2><p>在本次关于线性回归优化的学习中，我们深入探讨了多个关键要点：</p><ol><li><strong>欠拟合与过拟合</strong>：欠拟合是由于模型过于简单，对数据特征挖掘不充分，导致在训练集和测试集上都表现不佳。而过拟合则是模型过度复杂，把噪声也当作有效信息学习，在训练集上表现良好，但在测试集上效果差。针对欠拟合，可通过添加特征项（如组合、泛化、相关性等特征）或多项式特征来解决；对于过拟合，可采取清洗数据、增大训练量、运用正则化方法以及减少特征维度等措施。</li><li><strong>正则化方法</strong>：正则化是防止过拟合的核心手段，主要有 L2 正则化、L1 正则化和弹性网络等形式。L2 正则化（如岭回归）能使模型的权重系数变小，让模型更简单，减少过拟合风险；L1 正则化（如 Lasso 回归）可使部分权重直接为 0，实现自动的特征选择，输出稀疏模型；弹性网络则综合了岭回归和 Lasso 回归的优势，通过混合比进行控制，在一些复杂数据情况下表现更稳定。</li><li><strong>岭回归的应用</strong>：我们学习了岭回归在 scikit-learn 库中的 API 使用，包括<code>Ridge</code>类和<code>RidgeCV</code>类，并了解了各参数的含义和作用。同时，通过波士顿房价预测的具体案例，展示了岭回归模型的训练、评估过程，以及正则化力度的变化对权重系数和模型结果的影响。</li><li><strong>模型的保存与加载</strong>：掌握了在 scikit-learn 库中使用<code>joblib</code>工具进行模型保存和加载的方法，这在实际应用中能够节省训练时间和计算资源，方便模型在不同场景下的复用。</li></ol><p>这些知识和技能为我们在处理线性回归问题，优化模型性能，以及实际项目中的应用提供了坚实的基础，有助于我们更好地应对各种数据和业务需求，提升模型的准确性和泛化能力。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="机器学习" scheme="https://www.enju-tsubaki.icu/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="线性回归" scheme="https://www.enju-tsubaki.icu/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
    <category term="过拟合" scheme="https://www.enju-tsubaki.icu/tags/%E8%BF%87%E6%8B%9F%E5%90%88/"/>
    
    <category term="欠拟合" scheme="https://www.enju-tsubaki.icu/tags/%E6%AC%A0%E6%8B%9F%E5%90%88/"/>
    
    <category term="正则化" scheme="https://www.enju-tsubaki.icu/tags/%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>案例：波士顿房价预测</title>
    <link href="https://www.enju-tsubaki.icu/posts/8164788f.html"/>
    <id>https://www.enju-tsubaki.icu/posts/8164788f.html</id>
    <published>2025-03-02T07:23:43.516Z</published>
    <updated>2025-03-08T10:53:21.977Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="😊案例：波士顿房价预测"><a href="#😊案例：波士顿房价预测" class="headerlink" title="😊案例：波士顿房价预测"></a>😊案例：波士顿房价预测</h1><h2 id="😎学习目标"><a href="#😎学习目标" class="headerlink" title="😎学习目标"></a>😎学习目标</h2><p>通过案例掌握正规方程和梯度下降法 api 的使用</p><h2 id="🏠案例背景介绍"><a href="#🏠案例背景介绍" class="headerlink" title="🏠案例背景介绍"></a>🏠案例背景介绍</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%88%BF%E4%BB%B7%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D.png" alt="Alt text"></p><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%88%BF%E4%BB%B7%E6%95%B0%E6%8D%AE%E5%B1%9E%E6%80%A7.png" alt="Alt text"></p><h3 id="📊数据介绍"><a href="#📊数据介绍" class="headerlink" title="📊数据介绍"></a>📊数据介绍</h3><p>房价数据集案例。给定的这些特征，是专家们得出的影响房价的结果属性。我们此阶段不需要自己去探究特征是否有用，只需要使用这些特征。到后面量化很多特征需要我们自己去寻找。</p><h2 id="📈案例分析"><a href="#📈案例分析" class="headerlink" title="📈案例分析"></a>📈案例分析</h2><p>回归当中的数据大小不一致，可能会导致结果影响较大。所以需要做标准化处理，具体步骤如下：</p><ul><li>数据分割与标准化处理</li><li>回归预测</li><li>线性回归的算法效果评估</li></ul><h2 id="📏回归性能评估"><a href="#📏回归性能评估" class="headerlink" title="📏回归性能评估"></a>📏回归性能评估</h2><h3 id="🔍均方误差-Mean-Squared-Error-MSE-评价机制"><a href="#🔍均方误差-Mean-Squared-Error-MSE-评价机制" class="headerlink" title="🔍均方误差 (Mean Squared Error, MSE) 评价机制"></a>🔍均方误差 (Mean Squared Error, MSE) 评价机制</h3><p>在线性回归评估中，均方误差是一种常用的评估指标。</p><script type="math/tex; mode=display">MSE = \frac{1}{m} \sum_{i=1}^{m} (y^i - \bar{y})^2</script><script type="math/tex; mode=display">注：y_i 为预测值，\bar{y} 平均值为真实值。</script><h3 id="💭思考"><a href="#💭思考" class="headerlink" title="💭思考"></a>💭思考</h3><p>MSE 和最小二乘法的区别是？</p><h3 id="📚API-使用"><a href="#📚API-使用" class="headerlink" title="📚API 使用"></a>📚API 使用</h3><p><code>sklearn.metrics.mean_squared_error(y_true, y_pred)</code> 用于计算均方误差回归损失，其中：</p><ul><li><code>y_true</code>：真实值</li><li><code>y_pred</code>：预测值</li><li><code>return</code>：浮点数结果</li></ul><h2 id="💻代码实现"><a href="#💻代码实现" class="headerlink" title="💻代码实现"></a>💻代码实现</h2><h3 id="🧮正规方程"><a href="#🧮正规方程" class="headerlink" title="🧮正规方程"></a>🧮正规方程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">linear_model1</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    线性回归:正规方程</span></span><br><span class="line"><span class="string">    :return:None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1.获取数据</span></span><br><span class="line">    data = load_boston()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.数据集划分</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.特征工程-标准化</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.fit_transform(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.机器学习-线性回归(正规方程)</span></span><br><span class="line">    estimator = LinearRegression()</span><br><span class="line">    estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.模型评估</span></span><br><span class="line">    <span class="comment"># 5.1 获取系数等值</span></span><br><span class="line">    y_predict = estimator.predict(x_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;预测值为:\n&quot;</span>, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型中的系数为:\n&quot;</span>, estimator.coef_)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型中的偏置为:\n&quot;</span>, estimator.intercept_)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.2 评价</span></span><br><span class="line">    <span class="comment"># 均方误差</span></span><br><span class="line">    error = mean_squared_error(y_test, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;误差为:\n&quot;</span>, error)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><h3 id="📶梯度下降法"><a href="#📶梯度下降法" class="headerlink" title="📶梯度下降法"></a>📶梯度下降法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">linear_model2</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    线性回归:梯度下降法</span></span><br><span class="line"><span class="string">    :return:None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1.获取数据</span></span><br><span class="line">    data = load_boston()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.数据集划分</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.特征工程-标准化</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.fit_transform(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.机器学习-线性回归(特征方程)</span></span><br><span class="line">    estimator = SGDRegressor(max_iter=<span class="number">1000</span>)</span><br><span class="line">    estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.模型评估</span></span><br><span class="line">    <span class="comment"># 5.1 获取系数等值</span></span><br><span class="line">    y_predict = estimator.predict(x_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;预测值为:\n&quot;</span>, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型中的系数为:\n&quot;</span>, estimator.coef_)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型中的偏置为:\n&quot;</span>, estimator.intercept_)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.2 评价</span></span><br><span class="line">    <span class="comment"># 均方误差</span></span><br><span class="line">    error = mean_squared_error(y_test, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;误差为:\n&quot;</span>, error)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><h3 id="⚙️调参"><a href="#⚙️调参" class="headerlink" title="⚙️调参"></a>⚙️调参</h3><p>我们也可以尝试去修改学习率，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">estimator = SGDRegressor(max_iter=<span class="number">1000</span>,learning_rate=<span class="string">&quot;constant&quot;</span>,eta0=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><p>此时我们可以通过调参数，找到学习率效果更好的值。</p><h2 id="📝小结"><a href="#📝小结" class="headerlink" title="📝小结"></a>📝小结</h2><ul><li>了解正规方程和梯度下降法 api 在真实案例中的使用</li><li>知道线性回归性能评估方法，如均方误差</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="机器学习" scheme="https://www.enju-tsubaki.icu/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="线性回归" scheme="https://www.enju-tsubaki.icu/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
    <category term="正规方程" scheme="https://www.enju-tsubaki.icu/tags/%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B/"/>
    
    <category term="梯度下降法" scheme="https://www.enju-tsubaki.icu/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>线性回归API</title>
    <link href="https://www.enju-tsubaki.icu/posts/619f1a14.html"/>
    <id>https://www.enju-tsubaki.icu/posts/619f1a14.html</id>
    <published>2025-02-26T11:20:03.847Z</published>
    <updated>2025-02-26T11:38:04.609Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🥰2-2-线性回归-API-使用总结"><a href="#🥰2-2-线性回归-API-使用总结" class="headerlink" title="🥰2.2 线性回归 API 使用总结"></a>🥰2.2 线性回归 API 使用总结</h1><h2 id="🎯学习目标"><a href="#🎯学习目标" class="headerlink" title="🎯学习目标"></a>🎯学习目标</h2><ul><li>知道线性回归 api 的简单使用</li><li>了解正规方程的 api 及常用参数</li><li>了解梯度下降法 api 及常用参数</li></ul><h2 id="🌟线性回归-API-介绍"><a href="#🌟线性回归-API-介绍" class="headerlink" title="🌟线性回归 API 介绍"></a>🌟线性回归 API 介绍</h2><h3 id="🧐简单使用版-API"><a href="#🧐简单使用版-API" class="headerlink" title="🧐简单使用版 API"></a>🧐简单使用版 API</h3><p><code>sklearn.linear_model.LinearRegression()</code></p><ul><li><strong>属性</strong>：<ul><li><code>LinearRegression.coef_</code>：回归系数</li></ul></li></ul><h3 id="🎉示例代码"><a href="#🎉示例代码" class="headerlink" title="🎉示例代码"></a>🎉示例代码</h3><h4 id="📋步骤分析"><a href="#📋步骤分析" class="headerlink" title="📋步骤分析"></a>📋步骤分析</h4><ol><li>获取数据集</li><li>数据基本处理（该案例中省略）</li><li>特征工程（该案例中省略）</li><li>机器学习</li><li>模型评估（该案例中省略）</li></ol><h4 id="💻代码过程"><a href="#💻代码过程" class="headerlink" title="💻代码过程"></a>💻代码过程</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入模块</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造数据集</span></span><br><span class="line">x = [[<span class="number">80</span>, <span class="number">86</span>],</span><br><span class="line">     [<span class="number">82</span>, <span class="number">80</span>],</span><br><span class="line">     [<span class="number">85</span>, <span class="number">78</span>],</span><br><span class="line">     [<span class="number">90</span>, <span class="number">90</span>],</span><br><span class="line">     [<span class="number">86</span>, <span class="number">82</span>],</span><br><span class="line">     [<span class="number">82</span>, <span class="number">90</span>],</span><br><span class="line">     [<span class="number">78</span>, <span class="number">80</span>],</span><br><span class="line">     [<span class="number">92</span>, <span class="number">94</span>]]</span><br><span class="line">y = [<span class="number">84.2</span>, <span class="number">80.6</span>, <span class="number">80.1</span>, <span class="number">90</span>, <span class="number">83.2</span>, <span class="number">87.6</span>, <span class="number">79.4</span>, <span class="number">93.4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 机器学习 -- 模型训练</span></span><br><span class="line"><span class="comment"># 实例化API</span></span><br><span class="line">estimator = LinearRegression()</span><br><span class="line"><span class="comment"># 使用fit方法进行训练</span></span><br><span class="line">estimator.fit(x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看回归系数</span></span><br><span class="line"><span class="built_in">print</span>(estimator.coef_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行预测</span></span><br><span class="line"><span class="built_in">print</span>(estimator.predict([[<span class="number">100</span>, <span class="number">80</span>]]))</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="🤓详细参数版-API-介绍"><a href="#🤓详细参数版-API-介绍" class="headerlink" title="🤓详细参数版 API 介绍"></a>🤓详细参数版 API 介绍</h2><h3 id="📝正规方程实现"><a href="#📝正规方程实现" class="headerlink" title="📝正规方程实现"></a>📝正规方程实现</h3><p><code>sklearn.linear_model.LinearRegression(fit_intercept=True)</code></p><ul><li><strong>参数</strong>：<ul><li><code>fit_intercept</code>：是否计算偏置，默认为<code>True</code></li></ul></li><li><strong>属性</strong>：<ul><li><code>LinearRegression.coef_</code>：回归系数</li><li><code>LinearRegression.intercept_</code>：偏置</li></ul></li></ul><h3 id="🚀梯度下降法实现"><a href="#🚀梯度下降法实现" class="headerlink" title="🚀梯度下降法实现"></a>🚀梯度下降法实现</h3><p><code>sklearn.linear_model.SGDRegressor(loss=&quot;squared_loss&quot;, fit_intercept=True, learning_rate =&#39;invscaling&#39;, eta0=0.01)</code></p><ul><li><p><strong>参数</strong>：</p><ul><li><code>loss</code>：损失类型，<code>loss=&quot;squared_loss&quot;</code> 表示普通最小二乘法</li><li><code>fit_intercept</code>：是否计算偏置，默认为<code>True</code></li><li><p><code>learning_rate</code>：学习率填充方式，可选值有：</p><ul><li><code>&#39;constant&#39;</code>：<code>eta = eta0</code></li><li><code>&#39;optimal&#39;</code>：<code>eta = 1.0 / (alpha * (t + t0))</code>（默认）</li><li><code>&#39;invscaling&#39;</code>：<code>eta = eta0 / pow(t, power_t)</code>，其中 <code>power_t=0.25</code> 存在于父类中。对于常数值学习率，可使用 <code>learning_rate=&#39;constant&#39;</code> 并通过 <code>eta0</code> 指定学习率。</li></ul></li></ul></li><li><strong>属性</strong>：<ul><li><code>SGDRegressor.coef_</code>：回归系数</li><li><code>SGDRegressor.intercept_</code>：偏置</li></ul></li></ul><h2 id="✨小结"><a href="#✨小结" class="headerlink" title="✨小结"></a>✨小结</h2><ul><li>正规方程：<code>sklearn.linear_model.LinearRegression()</code></li><li>梯度下降法：<code>sklearn.linear_model.SGDRegressor()</code></li></ul><p>通过以上 API，我们可以根据具体需求选择合适的方法来实现线性回归模型。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="机器学习" scheme="https://www.enju-tsubaki.icu/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="API" scheme="https://www.enju-tsubaki.icu/tags/API/"/>
    
    <category term="线性回归" scheme="https://www.enju-tsubaki.icu/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>线性回归</title>
    <link href="https://www.enju-tsubaki.icu/posts/40997091.html"/>
    <id>https://www.enju-tsubaki.icu/posts/40997091.html</id>
    <published>2025-02-25T06:59:50.722Z</published>
    <updated>2025-03-08T10:38:16.234Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🎈2-1-线性回归简介"><a href="#🎈2-1-线性回归简介" class="headerlink" title="🎈2.1 线性回归简介"></a>🎈2.1 线性回归简介</h1><h2 id="🌟学习目标"><a href="#🌟学习目标" class="headerlink" title="🌟学习目标"></a>🌟学习目标</h2><ul><li>了解线性回归的应用场景</li><li>知道线性回归的定义</li></ul><h2 id="🏠1-线性回归应用场景"><a href="#🏠1-线性回归应用场景" class="headerlink" title="🏠1 线性回归应用场景"></a>🏠1 线性回归应用场景</h2><ul><li>房价预测</li><li>销售额度预测</li><li>贷款额度预测</li></ul><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.png" alt="Alt text"></p><h2 id="🔍2-什么是线性回归"><a href="#🔍2-什么是线性回归" class="headerlink" title="🔍2 什么是线性回归"></a>🔍2 什么是线性回归</h2><h3 id="📄2-1-定义与公式"><a href="#📄2-1-定义与公式" class="headerlink" title="📄2.1 定义与公式"></a>📄2.1 定义与公式</h3><p>线性回归 (Linear regression) 是利用回归方程 (函数) 对一个或多个自变量 (特征值) 和因变量 (目标值) 之间关系进行建模的一种分析方式。</p><ul><li>特点：只有一个自变量的情况称为单变量回归，多于一个自变量情况的叫做多元回归。</li></ul><p><strong>通用公式:</strong></p><script type="math/tex; mode=display">h(w) = w_1 x_1 + w_2 x_2 + w_3 x_3 \ldots + b = w^T x + b</script><script type="math/tex; mode=display">其中 w, x 可以理解为矩阵: w = \begin{pmatrix} b \\ w_1 \\ w_2 \end{pmatrix}, \quad x = \begin{pmatrix} 1 \\ x_1 \\ x_2 \end{pmatrix}</script><ul><li>线性回归用矩阵表示举例</li></ul><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9F%A9%E9%98%B5%E8%A1%A8%E7%A4%BA%E6%B3%95.png" alt="Alt text"></p><p>理解示例：</p><ul><li>期末成绩：0.7× 考试成绩 + 0.3× 平时成绩</li><li>房子价格 = 0.02× 中心区域的距离 + 0.04× 城市一氧化氮浓度 + (-0.12× 自住房平均房价) + 0.254× 城镇犯罪率</li></ul><p>上面两个例子，特征值与目标值之间建立了一个关系，这个关系可以理解为线性模型。</p><h3 id="📊2-2-线性回归的特征与目标的关系分析"><a href="#📊2-2-线性回归的特征与目标的关系分析" class="headerlink" title="📊2.2 线性回归的特征与目标的关系分析"></a>📊2.2 线性回归的特征与目标的关系分析</h3><p>线性回归当中主要有两种模型，一种是线性关系，另一种是非线性关系。为便于理解，这里都用单个特征或两个特征举例子。</p><h4 id="🔗线性关系"><a href="#🔗线性关系" class="headerlink" title="🔗线性关系"></a>🔗线性关系</h4><ul><li><strong>单变量线性关系</strong>：<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E7%BA%BF%E6%80%A7%E5%85%B3%E7%B3%BB%E5%9B%BE%EF%BC%88%E5%8D%95%E5%8F%98%E9%87%8F%EF%BC%89.png" alt="Alt text"></li><li><strong>多变量线性关系</strong>：<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%85%B3%E7%B3%BB%EF%BC%88%E5%A4%9A%E5%8F%98%E9%87%8F%EF%BC%89.png" alt="Alt text"></li></ul><ul><li>注释：单特征与目标值的关系呈直线关系，或者两个特征与目标值呈现平面的关系。更高维度的关系记住即可。</li></ul><h4 id="🌌非线性关系"><a href="#🌌非线性关系" class="headerlink" title="🌌非线性关系"></a>🌌非线性关系</h4><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%85%B3%E7%B3%BB.png" alt="Alt text"></p><ul><li>注释：若为非线性关系，回归方程可理解为：$ w_1 x_1 + w_2 x_2^2 + w_3 x_3^2$</li></ul><h2 id="🌈3-小结"><a href="#🌈3-小结" class="headerlink" title="🌈3 小结"></a>🌈3 小结</h2><ul><li><strong>线性回归的定义【了解】：</strong>利用回归方程 (函数) 对一个或多个自变量 (特征值) 和因变量 (目标值) 之间关系进行建模的一种分析方式。</li><li><strong>线性回归的分类【知道】</strong>：</li><li>线性关系</li><li>非线性关系</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="机器学习" scheme="https://www.enju-tsubaki.icu/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="线性回归" scheme="https://www.enju-tsubaki.icu/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>案例：Facebook 签到位置预测案例</title>
    <link href="https://www.enju-tsubaki.icu/posts/3b1e1cd9.html"/>
    <id>https://www.enju-tsubaki.icu/posts/3b1e1cd9.html</id>
    <published>2025-02-17T06:20:38.049Z</published>
    <updated>2025-03-08T10:42:14.944Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🎈-Facebook-签到位置预测案例"><a href="#🎈-Facebook-签到位置预测案例" class="headerlink" title="🎈 Facebook 签到位置预测案例"></a>🎈 Facebook 签到位置预测案例</h1><h2 id="🎯一、学习目标"><a href="#🎯一、学习目标" class="headerlink" title="🎯一、学习目标"></a>🎯一、学习目标</h2><p>通过 Facebook 位置预测案例，熟练掌握KNN算法学习内容。</p><h2 id="📌二、项目描述"><a href="#📌二、项目描述" class="headerlink" title="📌二、项目描述"></a>📌二、项目描述</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/Facebook%E7%AD%BE%E5%88%B0%E4%BD%8D%E7%BD%AE%E9%A2%84%E6%B5%8B.png" alt="Alt text"></p><p>本次比赛的目的是预测一个人将要签到的地方。Facebook 创建了一个虚拟世界，这个世界是一个 10 公里 ×10 公里，共 100 平方公里的区域，其中包含约 10 万个地方。对于给定的坐标集，任务是根据用户的位置、准确性和时间戳等信息，预测用户下一次的签到位置。数据被制作成类似于来自移动设备的位置数据。需要注意的是，只能使用提供的数据进行预测 。</p><h2 id="📚三、数据集介绍"><a href="#📚三、数据集介绍" class="headerlink" title="📚三、数据集介绍"></a>📚三、数据集介绍</h2><h3 id="（一）📄数据介绍"><a href="#（一）📄数据介绍" class="headerlink" title="（一）📄数据介绍"></a>（一）📄数据介绍</h3><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/facebook%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D.png" alt="Alt text"></p><p>涉及的文件有 train.csv 和 test.csv ，各字段含义如下：</p><ul><li><strong>row id</strong>：签入事件的 id。</li><li><strong>x y</strong>：坐标。</li><li><strong>accuracy</strong>：准确度，即定位精度。</li><li><strong>time</strong>：时间戳。</li><li><strong>place_id</strong>：签到的位置，这也是需要预测的内容。</li></ul><h3 id="（二）🔗官网"><a href="#（二）🔗官网" class="headerlink" title="（二）🔗官网"></a>（二）🔗官网</h3><p>数据集官网：<a href="https://www.kaggle.com/navoshta/grid-knn/data">https://www.kaggle.com/navoshta/grid-knn/data</a></p><h2 id="🛠️四、步骤分析"><a href="#🛠️四、步骤分析" class="headerlink" title="🛠️四、步骤分析"></a>🛠️四、步骤分析</h2><h3 id="（一）📊数据基本处理"><a href="#（一）📊数据基本处理" class="headerlink" title="（一）📊数据基本处理"></a>（一）📊数据基本处理</h3><p>对数据做一些基本处理（这里的处理不一定能达到最佳效果，只是简单尝试，有些特征可根据特征选择方式进一步处理）。</p><ol><li><strong>缩小数据集范围</strong>：使用 DataFrame.query () 方法。</li><li><strong>选取有用的时间特征</strong> 。</li><li><strong>将签到位置少于 n 个用户的删除</strong> 。</li></ol><h3 id="（二）✂️分割数据集"><a href="#（二）✂️分割数据集" class="headerlink" title="（二）✂️分割数据集"></a>（二）✂️分割数据集</h3><h3 id="（三）⚖️标准化处理"><a href="#（三）⚖️标准化处理" class="headerlink" title="（三）⚖️标准化处理"></a>（三）⚖️标准化处理</h3><h3 id="（四）🔍k-近邻预测"><a href="#（四）🔍k-近邻预测" class="headerlink" title="（四）🔍k - 近邻预测"></a>（四）🔍k - 近邻预测</h3><p>具体步骤如下：</p><ol><li><strong>获取数据集</strong> 。</li><li><strong>基本数据处理</strong><ul><li><strong>缩小数据范围</strong> 。</li><li><strong>选择时间特征</strong> 。</li><li><strong>去掉签到较少的地方</strong> 。</li><li><strong>确定特征值和目标值</strong> 。</li><li><strong>分割数据集</strong> 。</li></ul></li><li><strong>特征工程 — 特征预处理 (标准化)</strong> 。</li><li><strong>机器学习 — knn+cv</strong> 。</li><li><strong>模型评估</strong> 。</li></ol><h2 id="💻五、代码实现"><a href="#💻五、代码实现" class="headerlink" title="💻五、代码实现"></a>💻五、代码实现</h2><h3 id="（一）📥获取数据集"><a href="#（一）📥获取数据集" class="headerlink" title="（一）📥获取数据集"></a>（一）📥获取数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1、获取数据集</span></span><br><span class="line">facebook = pd.read_csv(<span class="string">&quot;./data/FBlocation/train.csv&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="（二）📈基本数据处理"><a href="#（二）📈基本数据处理" class="headerlink" title="（二）📈基本数据处理"></a>（二）📈基本数据处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2.基本数据处理</span></span><br><span class="line"><span class="comment"># 2.1 缩小数据范围</span></span><br><span class="line">facebook_data = facebook.query(<span class="string">&quot;x&gt;2.0 &amp; x&lt;2.5 &amp; y&gt;2.0 &amp; y&lt;2.5&quot;</span>)</span><br><span class="line"><span class="comment"># 2.2 选择时间特征</span></span><br><span class="line">time = pd.to_datetime(facebook_data[<span class="string">&quot;time&quot;</span>], unit=<span class="string">&quot;s&quot;</span>)</span><br><span class="line">time = pd.DatetimeIndex(time)</span><br><span class="line">facebook_data[<span class="string">&quot;day&quot;</span>] = time.day</span><br><span class="line">facebook_data[<span class="string">&quot;hour&quot;</span>] = time.hour</span><br><span class="line">facebook_data[<span class="string">&quot;weekday&quot;</span>] = time.weekday</span><br><span class="line"><span class="comment"># 2.3 去掉签到较少的地方</span></span><br><span class="line">place_count = facebook_data.groupby(<span class="string">&quot;place_id&quot;</span>).count()</span><br><span class="line">place_count = place_count[place_count[<span class="string">&quot;row_id&quot;</span>]&gt;<span class="number">3</span>]</span><br><span class="line">facebook_data = facebook_data[facebook_data[<span class="string">&quot;place_id&quot;</span>].isin(place_count.index)]</span><br><span class="line"><span class="comment"># 2.4 确定特征值和目标值</span></span><br><span class="line">x = facebook_data[[<span class="string">&quot;x&quot;</span>, <span class="string">&quot;y&quot;</span>, <span class="string">&quot;accuracy&quot;</span>, <span class="string">&quot;day&quot;</span>, <span class="string">&quot;hour&quot;</span>, <span class="string">&quot;weekday&quot;</span>]]</span><br><span class="line">y = facebook_data[<span class="string">&quot;place_id&quot;</span>]</span><br><span class="line"><span class="comment"># 2.5 分割数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">22</span>)</span><br></pre></td></tr></table></figure><h3 id="（三）📐特征工程-—-特征预处理-标准化"><a href="#（三）📐特征工程-—-特征预处理-标准化" class="headerlink" title="（三）📐特征工程 — 特征预处理 (标准化)"></a>（三）📐特征工程 — 特征预处理 (标准化)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3.特征工程--特征预处理(标准化)</span></span><br><span class="line"><span class="comment"># 3.1 实例化一个转换器</span></span><br><span class="line">transfer = StandardScaler()</span><br><span class="line"><span class="comment"># 3.2 调用fit_transform</span></span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.fit_transform(x_test)</span><br></pre></td></tr></table></figure><h3 id="（四）🧩机器学习-—knn-cv"><a href="#（四）🧩机器学习-—knn-cv" class="headerlink" title="（四）🧩机器学习 —knn+cv"></a>（四）🧩机器学习 —knn+cv</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4.机器学习--knn+cv</span></span><br><span class="line"><span class="comment"># 4.1 实例化一个估计器</span></span><br><span class="line">estimator = KNeighborsClassifier()</span><br><span class="line"><span class="comment"># 4.2 调用gridsearchCV</span></span><br><span class="line">param_grid = &#123;<span class="string">&quot;n_neighbors&quot;</span>: [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>]&#125;</span><br><span class="line">estimator = GridSearchCV(estimator, param_grid=param_grid, cv=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 4.3 模型训练</span></span><br><span class="line">estimator.fit(x_train, y_train)</span><br></pre></td></tr></table></figure><h3 id="（五）📊模型评估"><a href="#（五）📊模型评估" class="headerlink" title="（五）📊模型评估"></a>（五）📊模型评估</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 5.模型评估</span></span><br><span class="line"><span class="comment"># 5.1 基本评估方式</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最后预测的准确率为:\n&quot;</span>, score)</span><br><span class="line"></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最后的预测值为:\n&quot;</span>, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测值和真实值的对比情况:\n&quot;</span>, y_predict == y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.2 使用交叉验证后的评估方式</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;在交叉验证中验证的最好结果:\n&quot;</span>, estimator.best_score_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最好的参数模型:\n&quot;</span>, estimator.best_estimator_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每次交叉验证后的验证集准确率结果和训练集准确率结果:\n&quot;</span>,estimator.cv_results_)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="机器学习" scheme="https://www.enju-tsubaki.icu/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="KNN" scheme="https://www.enju-tsubaki.icu/tags/KNN/"/>
    
  </entry>
  
  <entry>
    <title>案例：鸢尾花种类预测</title>
    <link href="https://www.enju-tsubaki.icu/posts/6bddf6c7.html"/>
    <id>https://www.enju-tsubaki.icu/posts/6bddf6c7.html</id>
    <published>2025-02-15T05:21:37.654Z</published>
    <updated>2025-03-08T10:52:59.312Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🌼案例：鸢尾花种类预测-—-流程实现🥰"><a href="#🌼案例：鸢尾花种类预测-—-流程实现🥰" class="headerlink" title="🌼案例：鸢尾花种类预测 — 流程实现🥰"></a>🌼案例：鸢尾花种类预测 — 流程实现🥰</h1><h2 id="🎯学习目标"><a href="#🎯学习目标" class="headerlink" title="🎯学习目标"></a>🎯学习目标</h2><ul><li><h3 id="🎯目标"><a href="#🎯目标" class="headerlink" title="🎯目标"></a>🎯目标</h3><ul><li>熟悉：机器学习从数据获取到评估的完整流程</li><li>掌握：KNeighborsClassifier的使用及参数设置</li><li>理解：归一化和标准化原理、区别及适用场景</li><li>明晰：交叉验证和网格搜索概念及作用</li><li>运用：交叉验证和网格搜索优化模型</li></ul></li></ul><h2 id="🔍K-近邻算法-API"><a href="#🔍K-近邻算法-API" class="headerlink" title="🔍K - 近邻算法 API"></a>🔍K - 近邻算法 API</h2><p><code>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, algorithm=&#39;auto&#39;)</code></p><h4 id="📋参数说明"><a href="#📋参数说明" class="headerlink" title="📋参数说明"></a>📋参数说明</h4><ul><li><code>n_neighbors</code>：int，可选（默认 = 5），k_neighbors 查询默认使用的邻居数</li><li><code>algorithm</code>：{‘auto’，‘ball_tree’，‘kd_tree’，‘brute’}，快速 k 近邻搜索算法，默认参数为 auto，可以理解为算法自己决定合适的搜索算法。除此之外，用户也可以自己指定搜索算法：<ul><li><code>brute</code>：蛮力搜索，也就是线性扫描，当训练集很大时，计算非常耗时。</li><li><code>kd_tree</code>：构造kd树存储数据以便对其进行快速检索的树形数据结构，kd树也就是数据结构中的二叉树。以中值切分构造的树，每个结点是一个超矩形，在维数小于20时效率高。</li><li><code>ball_tree</code>：是为了克服kd树高维失效而发明的，其构造过程是以质心C和半径r分割样本空间，每个节点是一个超球体。</li></ul></li></ul><h2 id="💡预处理归一化和标准化的精髓✨"><a href="#💡预处理归一化和标准化的精髓✨" class="headerlink" title="💡预处理归一化和标准化的精髓✨"></a>💡预处理归一化和标准化的精髓✨</h2><h3 id="🔢归一化"><a href="#🔢归一化" class="headerlink" title="🔢归一化"></a>🔢归一化</h3><ul><li><strong>核心定义：</strong>将原始数据通过变换映射到指定范围，通常是[0,1]区间。</li><li><p><strong>公式本质：</strong>每一列数据，通过减去最小值，除以极差（最大值与最小值的差）</p><script type="math/tex; mode=display">X' = \frac{x - \min}{\max - \min}</script><p>再乘以指定区间长度并加上区间下限，实现数据的缩放。</p><script type="math/tex; mode=display">X'' = X' * (mx - mi) + mi</script></li><li>主要作用：消除特征之间的量纲差异，使不同特征在模型中具有相同的“地位”，便于进行比较和分析，有助于提高某些对特征范围敏感的机器学习算法的性能。</li><li>API要点：使用 <code>sklearn.preprocessing.MinMaxScaler</code>类，通过 <code>fit_transform</code>方法对 <code>numpy array</code>格式的数据进行转换，可通过 <code>feature_range</code>参数指定映射范围。</li><li>应用局限：最大值和最小值易受异常点影响，导致归一化结果不稳定，鲁棒性较差，适用于传统精确小数据场景。</li></ul><h3 id="🌟标准化"><a href="#🌟标准化" class="headerlink" title="🌟标准化"></a>🌟标准化</h3><ul><li>核心定义：对原始数据进行变换，使数据转换到均值为0、标准差为1的范围内。</li><li><p>公式本质：</p><script type="math/tex; mode=display">X' = \frac{x - \text{mean}}{\sigma}</script><p>针对每一列数据，减去该列的均值，再除以该列的标准差，从而使数据符合标准正态分布。</p></li><li>主要作用：在消除量纲影响的同时，能让数据具有稳定的均值和标准差，使模型更加稳定和高效，尤其适用于对数据分布有一定要求的算法。</li><li>API要点：利用 <code>sklearn.preprocessing.StandardScaler</code>类的 <code>fit_transform</code>方法处理 <code>numpy array</code>格式的数据，处理后每列数据都聚集在均值0附近，标准差为1。</li><li>应用优势：在样本数据足够多的情况下比较稳定，少量异常点对平均值和方差的影响较小，适合现代嘈杂大数据场景。</li></ul><h2 id="🌸案例：鸢尾花种类预测🌼"><a href="#🌸案例：鸢尾花种类预测🌼" class="headerlink" title="🌸案例：鸢尾花种类预测🌼"></a>🌸案例：鸢尾花种类预测🌼</h2><h3 id="📊数据集介绍"><a href="#📊数据集介绍" class="headerlink" title="📊数据集介绍"></a>📊数据集介绍</h3><p>Iris数据集是常用的分类实验数据集，由Fisher, 1936收集整理。Iris也称鸢尾花卉数据集，是一类多重变量分析的数据集。关于数据集的具体介绍：<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/iris%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D.png" alt="Alt text"></p><h3 id="🚀步骤分析"><a href="#🚀步骤分析" class="headerlink" title="🚀步骤分析"></a>🚀步骤分析</h3><ul><li>获取数据集</li><li>数据基本处理</li><li>特征工程</li><li>机器学习 (模型训练)</li><li>模型评估</li></ul><h3 id="💻代码过程"><a href="#💻代码过程" class="headerlink" title="💻代码过程"></a>💻代码过程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入必要的库</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 获取数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 数据基本处理</span></span><br><span class="line"><span class="comment"># x_train,x_test,y_train,y_test为训练集特征值、测试集特征值、训练集目标值、测试集目标值</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=<span class="number">0.2</span>, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 特征工程：标准化</span></span><br><span class="line">transfer = StandardScaler()</span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 机器学习(模型训练)</span></span><br><span class="line">estimator = KNeighborsClassifier(n_neighbors=<span class="number">9</span>)</span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 模型评估</span></span><br><span class="line"><span class="comment"># 方法1：比对真实值和预测值</span></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测结果为:\n&quot;</span>, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;比对真实值和预测值：\n&quot;</span>, y_predict == y_test)</span><br><span class="line"><span class="comment"># 方法2：直接计算准确率</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率为：\n&quot;</span>, score)</span><br></pre></td></tr></table></figure><h2 id="🔄什么是交叉验证-cross-validation-🌟"><a href="#🔄什么是交叉验证-cross-validation-🌟" class="headerlink" title="🔄什么是交叉验证 (cross validation)🌟"></a>🔄什么是交叉验证 (cross validation)🌟</h2><p>交叉验证是一种用于评估模型性能的重要技术。它将拿到的训练数据，进一步细分为训练集和验证集。例如，把数据分成 4 份，其中一份作为验证集。然后经过 4 次（组）的测试，每次都更换不同的验证集，即得到 4 组模型的结果，取平均值作为最终结果，这也被称为 4 折交叉验证。</p><h3 id="🧐分析"><a href="#🧐分析" class="headerlink" title="🧐分析"></a>🧐分析</h3><p>我们之前了解到数据分为训练集和测试集，但为了让从训练得到的模型结果更加准确，我们做如下处理：</p><ul><li>训练集：进一步拆分为训练集和验证集</li><li>测试集：保持不变</li></ul><h3 id="🤔为什么需要交叉验证"><a href="#🤔为什么需要交叉验证" class="headerlink" title="🤔为什么需要交叉验证"></a>🤔为什么需要交叉验证</h3><p>交叉验证的目的是为了让被评估的模型更加准确可信。不过，这只是提升了模型评估的准确性，那如何选择或者调优参数呢？这就引出了网格搜索。</p><h2 id="🔍什么是网格搜索-Grid-Search-🌈"><a href="#🔍什么是网格搜索-Grid-Search-🌈" class="headerlink" title="🔍什么是网格搜索 (Grid Search)🌈"></a>🔍什么是网格搜索 (Grid Search)🌈</h2><p>通常情况下，有很多参数是需要手动指定的（如 k - 近邻算法中的 K 值），这种参数被称为超参数。手动调整超参数的过程繁杂，所以我们需要对模型预设几种超参数组合。每组超参数都采用交叉验证来进行评估，最后选出最优参数组合建立模型。</p><h2 id="🛠交叉验证，网格搜索（模型选择与调优）API📚"><a href="#🛠交叉验证，网格搜索（模型选择与调优）API📚" class="headerlink" title="🛠交叉验证，网格搜索（模型选择与调优）API📚"></a>🛠交叉验证，网格搜索（模型选择与调优）API📚</h2><p><code>sklearn.model_selection.GridSearchCV(estimator, param_grid=None, cv=None)</code> 用于对估计器的指定参数值进行详尽搜索。</p><h4 id="📋参数说明-1"><a href="#📋参数说明-1" class="headerlink" title="📋参数说明"></a>📋参数说明</h4><ul><li><code>estimator</code>：估计器对象</li><li><code>param_grid</code>：估计器参数（字典形式），例如 <code>&#123;&quot;n_neighbors&quot;: [1, 3, 5]&#125;</code></li><li><code>cv</code>：指定几折交叉验证</li><li><code>fit</code>：输入训练数据</li><li><code>score</code>：计算准确率</li></ul><h3 id="📈结果分析"><a href="#📈结果分析" class="headerlink" title="📈结果分析"></a>📈结果分析</h3><ul><li><code>best_score_</code>：在交叉验证中验证的最好结果</li><li><code>best_estimator_</code>：最好的参数模型</li><li><code>cv_results_</code>：每次交叉验证后的验证集准确率结果和训练集准确率结果</li></ul><h2 id="🌺鸢尾花案例增加-K-值调优💐"><a href="#🌺鸢尾花案例增加-K-值调优💐" class="headerlink" title="🌺鸢尾花案例增加 K 值调优💐"></a>🌺鸢尾花案例增加 K 值调优💐</h2><p>以下是使用 <code>GridSearchCV</code> 构建估计器的完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、获取数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、数据基本处理 -- 划分数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、特征工程：标准化</span></span><br><span class="line"><span class="comment"># 实例化一个转换器类</span></span><br><span class="line">transfer = StandardScaler()</span><br><span class="line"><span class="comment"># 调用 fit_transform</span></span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、KNN 预估器流程</span></span><br><span class="line"><span class="comment">#  4.1 实例化预估器类</span></span><br><span class="line">estimator = KNeighborsClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.2 模型选择与调优——网格搜索和交叉验证</span></span><br><span class="line"><span class="comment"># 准备要调的超参数</span></span><br><span class="line">param_dict = &#123;<span class="string">&quot;n_neighbors&quot;</span>: [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>]&#125;</span><br><span class="line">estimator = GridSearchCV(estimator, param_grid=param_dict, cv=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.3 fit 数据进行训练</span></span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、评估模型效果</span></span><br><span class="line"><span class="comment"># 方法 a：比对预测结果和真实值</span></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;比对预测结果和真实值：\n&quot;</span>, y_predict == y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法 b：直接计算准确率</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;直接计算准确率：\n&quot;</span>, score)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看最终选择的结果和交叉验证的结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;在交叉验证中验证的最好结果：\n&quot;</span>, estimator.best_score_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最好的参数模型：\n&quot;</span>, estimator.best_estimator_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每次交叉验证后的准确率结果：\n&quot;</span>, estimator.cv_results_)</span><br></pre></td></tr></table></figure><h3 id="💻代码运行输出结果👇"><a href="#💻代码运行输出结果👇" class="headerlink" title="💻代码运行输出结果👇"></a>💻代码运行输出结果👇</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">比对预测结果和真实值：</span><br><span class="line"> [ True  True  True  True  True  True  True False  True  True  True  True</span><br><span class="line">  True  True  True  True  True  True False  True  True  True  True  True</span><br><span class="line">  True  True  True  True  True  True  True  True  True  True  True  True</span><br><span class="line">  True  True]</span><br><span class="line">直接计算准确率：</span><br><span class="line"> 0.947368421053</span><br><span class="line">在交叉验证中验证的最好结果：</span><br><span class="line"> 0.973214285714</span><br><span class="line">最好的参数模型：</span><br><span class="line"> KNeighborsClassifier(algorithm=&#x27;auto&#x27;, leaf_size=30, metric=&#x27;minkowski&#x27;,</span><br><span class="line">           metric_params=None, n_jobs=1, n_neighbors=5, p=2,</span><br><span class="line">           weights=&#x27;uniform&#x27;)</span><br><span class="line">每次交叉验证后的准确率结果：</span><br><span class="line"> &#123;&#x27;mean_fit_time&#x27;: array([ 0.00114751,  0.00027037,  0.00024462]), &#x27;std_fit_time&#x27;: array([  1.13901511e-03,   1.25300249e-05,   1.11011951e-05]), &#x27;mean_score_time&#x27;: array([ 0.00085751,  0.00048693,  0.00045625]), &#x27;std_score_time&#x27;: array([  3.52785082e-04,   2.87650037e-05,   5.29673344e-06]), &#x27;param_n_neighbors&#x27;: masked_array(data = [1 3 5],</span><br><span class="line">             mask = [False False False],</span><br><span class="line">       fill_value = ?), &#x27;params&#x27;: [&#123;&#x27;n_neighbors&#x27;: 1&#125;, &#123;&#x27;n_neighbors&#x27;: 3&#125;, &#123;&#x27;n_neighbors&#x27;: 5&#125;], &#x27;split0_test_score&#x27;: array([ 0.97368421,  0.97368421,  0.97368421]), &#x27;split1_test_score&#x27;: array([ 0.97297297,  0.97297297,  0.97297297]), &#x27;split2_test_score&#x27;: array([ 0.94594595,  0.89189189,  0.97297297]), &#x27;mean_test_score&#x27;: array([ 0.96428571,  0.94642857,  0.97321429]), &#x27;std_test_score&#x27;: array([ 0.01288472,  0.03830641,  0.00033675]), &#x27;rank_test_score&#x27;: array([2, 3, 1], dtype=int32), &#x27;split0_train_score&#x27;: array([ 1.        ,  0.95945946,  0.97297297]), &#x27;split1_train_score&#x27;: array([ 1.        ,  0.96      ,  0.97333333]), &#x27;split2_train_score&#x27;: array([ 1.  ,  0.96,  0.96]), &#x27;mean_train_score&#x27;: array([ 1.        ,  0.95981982,  0.96876877]), &#x27;std_train_score&#x27;: array([ 0.        ,  0.00025481,  0.0062022 ])&#125;</span><br></pre></td></tr></table></figure><h2 id="📝总结🎉"><a href="#📝总结🎉" class="headerlink" title="📝总结🎉"></a>📝总结🎉</h2><p>本文围绕鸢尾花种类预测案例，详细介绍了机器学习从数据获取到模型评估的完整流程，以及相关的数据预处理、模型调优等重要技术，具体内容总结如下：</p><h3 id="🚀机器学习流程与核心算法"><a href="#🚀机器学习流程与核心算法" class="headerlink" title="🚀机器学习流程与核心算法"></a>🚀机器学习流程与核心算法</h3><ul><li><strong>完整流程</strong>：涵盖获取数据集、数据基本处理、特征工程、模型训练和模型评估等环节，清晰展示了运用机器学习解决实际分类问题的步骤。</li><li><strong>K - 近邻算法</strong>：<code>KNeighborsClassifier</code> 是常用的分类算法，可通过设置 <code>n_neighbors</code> 和 <code>algorithm</code> 等参数进行灵活调整。不同的 <code>algorithm</code> 选项（如 <code>auto</code>、<code>ball_tree</code>、<code>kd_tree</code>、<code>brute</code>）适用于不同的数据规模和维度场景。</li></ul><h3 id="💾数据预处理"><a href="#💾数据预处理" class="headerlink" title="💾数据预处理"></a>💾数据预处理</h3><ul><li><strong>归一化</strong>：将数据映射到指定范围（通常是 [0,1]），能消除特征量纲差异，但易受异常点影响，鲁棒性较差，适用于传统精确小数据场景。使用 <code>sklearn.preprocessing.MinMaxScaler</code> 类实现。</li><li><strong>标准化</strong>：把数据变换到均值为 0、标准差为 1 的范围内，在处理大数据时更为稳定，受异常点影响较小，适合现代嘈杂大数据场景。使用 <code>sklearn.preprocessing.StandardScaler</code> 类实现。</li></ul><h3 id="📊模型评估与调优"><a href="#📊模型评估与调优" class="headerlink" title="📊模型评估与调优"></a>📊模型评估与调优</h3><ul><li><strong>交叉验证</strong>：通过将训练数据划分为多个子集进行多次验证，取结果平均值，可使模型评估结果更加准确可信，提高模型的泛化能力。</li><li><strong>网格搜索</strong>：针对超参数（如 K - 近邻算法中的 <code>n_neighbors</code>）预设多种组合，利用交叉验证评估每组参数的效果，从而选出最优参数组合，优化模型性能。使用 <code>sklearn.model_selection.GridSearchCV</code> 类实现。</li></ul><p>通过鸢尾花种类预测案例，我们不仅掌握了 <code>KNeighborsClassifier</code> 算法的使用，还学会了如何运用数据预处理、交叉验证和网格搜索等技术，提升模型的准确性和稳定性。这些方法和技术在解决各类机器学习分类问题中具有广泛的应用价值。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="机器学习" scheme="https://www.enju-tsubaki.icu/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="KNN" scheme="https://www.enju-tsubaki.icu/tags/KNN/"/>
    
    <category term="特征工程" scheme="https://www.enju-tsubaki.icu/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="交叉验证" scheme="https://www.enju-tsubaki.icu/tags/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/"/>
    
    <category term="网格搜索" scheme="https://www.enju-tsubaki.icu/tags/%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2/"/>
    
  </entry>
  
  <entry>
    <title>K-近邻算法API</title>
    <link href="https://www.enju-tsubaki.icu/posts/d5f3c9dd.html"/>
    <id>https://www.enju-tsubaki.icu/posts/d5f3c9dd.html</id>
    <published>2025-02-14T05:51:33.482Z</published>
    <updated>2025-03-08T10:43:33.543Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🌟1-2-k近邻算法api初步使用🌟"><a href="#🌟1-2-k近邻算法api初步使用🌟" class="headerlink" title="🌟1.2 k近邻算法api初步使用🌟"></a>🌟1.2 k近邻算法api初步使用🌟</h1><h2 id="🌈学习目标"><a href="#🌈学习目标" class="headerlink" title="🌈学习目标"></a>🌈学习目标</h2><h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><ul><li>了解sklearn工具的优点和包含内容</li><li>应用sklearn中的api实现KNN算法的简单使用</li></ul><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="Alt text"></p><ol><li>获取数据集</li><li>数据基本处理</li><li>特征工程</li><li>机器学习</li><li>模型评估</li></ol><h2 id="🛠️Scikit-learn-工具介绍"><a href="#🛠️Scikit-learn-工具介绍" class="headerlink" title="🛠️Scikit-learn 工具介绍"></a>🛠️Scikit-learn 工具介绍</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/scikitlearn.png" alt="Alt text"></p><p>Scikit-learn是Python语言的机器学习工具，它具有以下特点：</p><ul><li>包括许多知名的机器学习算法的实现</li><li>文档完善，容易上手，拥有丰富的AP</li></ul><h3 id="🔧安装"><a href="#🔧安装" class="headerlink" title="🔧安装"></a>🔧安装</h3><p>使用以下命令进行安装：<br><code>pip3 install scikit-learn</code></p><p>安装好之后可以通过以下命令查看是否安装成功：<br><code>import sklearn</code></p><p>注：安装scikit-learn需要Numpy, Scipy等库。</p><h3 id="📦Scikit-learn包含的内容"><a href="#📦Scikit-learn包含的内容" class="headerlink" title="📦Scikit-learn包含的内容"></a>📦Scikit-learn包含的内容</h3><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/sklearn%E5%8C%85%E5%90%AB%E5%86%85%E5%AE%B9.png" alt="Alt text"></p><ul><li>分类、聚类、回归 - 特征工程</li><li>模型选择、调优</li></ul><h2 id="📌K-近邻算法API"><a href="#📌K-近邻算法API" class="headerlink" title="📌K-近邻算法API"></a>📌K-近邻算法API</h2><p><code>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5)</code></p><ul><li><code>n_neighbors</code>：int，可选（默认 = 5），k_neighbors 查询默认使用的邻居数</li></ul><h2 id="📋案例"><a href="#📋案例" class="headerlink" title="📋案例"></a>📋案例</h2><h3 id="👣步骤分析"><a href="#👣步骤分析" class="headerlink" title="👣步骤分析"></a>👣步骤分析</h3><ol><li>获取数据集</li><li>数据基本处理（该案例中省略）</li><li>特征工程（该案例中省略）</li><li>机器学习</li><li>模型评估（该案例中省略）</li></ol><h3 id="💻代码过程"><a href="#💻代码过程" class="headerlink" title="💻代码过程"></a>💻代码过程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入模块</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造数据集</span></span><br><span class="line">x = [[<span class="number">0</span>], [<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 机器学习 -- 模型训练</span></span><br><span class="line"><span class="comment"># 实例化API</span></span><br><span class="line">estimator = KNeighborsClassifier(n_neighbors=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 使用fit方法进行训练</span></span><br><span class="line">estimator.fit(x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行预测</span></span><br><span class="line">result = estimator.predict([[<span class="number">1</span>]])</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure><h2 id="❓问题解答"><a href="#❓问题解答" class="headerlink" title="❓问题解答"></a>❓问题解答</h2><h3 id="1-选取K值的大小？"><a href="#1-选取K值的大小？" class="headerlink" title="1. 选取K值的大小？"></a>1. 选取K值的大小？</h3><p>K值的选择对KNN模型有重要影响：</p><ul><li><strong>K值过小：</strong><ul><li>容易受到异常点的影响</li><li>容易过拟合，即“学习”近似误差会减小，但“学习”的估计误差会增大，整体模型变得复杂。</li></ul></li><li><strong>K值过大：</strong><ul><li>受到样本均衡的问题</li><li>容易欠拟合，学习的近似误差会增大，模型变得简单。</li></ul></li><li><strong>K=N（N为训练样本个数）：</strong>完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的类，模型过于简单，忽略了训练实例中大量有用信息。</li></ul><p>在实际应用中，K值一般取一个比较小的数值，例如采用交叉验证法（简单来说，就是把训练数据再分成两组：训练集和验证集）来选择最优的K值。</p><p><strong>近似误差：</strong>对现有训练集的训练误差，关注训练集。如果近似误差过小可能会出现过拟合的现象，对现有的训练集能有很好的预测，但是对未知的测试样本将会出现较大偏差的预测，模型本身不是最接近最佳模型。</p><p><strong>估计误差：</strong>可以理解为对测试集的测试误差，关注测试集。估计误差小说明对未知数据的预测能力好，模型本身最接近最佳模型。</p><h3 id="2-api中其他参数的具体含义？"><a href="#2-api中其他参数的具体含义？" class="headerlink" title="2. api中其他参数的具体含义？"></a>2. api中其他参数的具体含义？</h3><p><code>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, algorithm=&#39;auto&#39;)</code></p><ul><li><code>n_neighbors</code>：int，可选（默认 = 5），k_neighbors 查询默认使用的邻居数</li><li><code>algorithm</code>：{‘auto’，‘ball_tree’，‘kd_tree’，‘brute’}，快速 k 近邻搜索算法，默认参数为 auto，可以理解为算法自己决定合适的搜索算法。除此之外，用户也可以自己指定搜索算法：<ul><li><code>brute</code>：蛮力搜索，也就是线性扫描，当训练集很大时，计算非常耗时。</li><li><code>kd_tree</code>：构造kd树存储数据以便对其进行快速检索的树形数据结构，kd树也就是数据结构中的二叉树。以中值切分构造的树，每个结点是一个超矩形，在维数小于20时效率高。</li><li><code>ball_tree</code>：是为了克服kd树高维失效而发明的，其构造过程是以质心C和半径r分割样本空间，每个节点是一个超球体。</li></ul></li></ul><h2 id="📚总结"><a href="#📚总结" class="headerlink" title="📚总结"></a>📚总结</h2><h3 id="sklearn的优势"><a href="#sklearn的优势" class="headerlink" title="sklearn的优势"></a>sklearn的优势</h3><ul><li>文档多，且规范</li><li>包含的算法多 - 实现起来容易</li></ul><h3 id="knn中的api"><a href="#knn中的api" class="headerlink" title="knn中的api"></a>knn中的api</h3><p><code>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, algorithm=&#39;auto&#39;)</code></p><h3 id="KNN中K值大小选择对模型的影响"><a href="#KNN中K值大小选择对模型的影响" class="headerlink" title="KNN中K值大小选择对模型的影响"></a>KNN中K值大小选择对模型的影响</h3><ul><li>K值过小：容易受到异常点的影响，容易过拟合</li><li>K值过大：受到样本均衡的问题，容易欠拟合</li></ul><p>通过以上内容，我们对sklearn工具和KNN算法的API有了初步的了解，并且掌握了如何使用sklearn中的KNN算法进行简单的模型训练和预测。同时，我们也了解了K值选择对模型的影响以及API中其他参数的含义。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="机器学习" scheme="https://www.enju-tsubaki.icu/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="KNN" scheme="https://www.enju-tsubaki.icu/tags/KNN/"/>
    
    <category term="API" scheme="https://www.enju-tsubaki.icu/tags/API/"/>
    
  </entry>
  
  <entry>
    <title>K-近邻算法</title>
    <link href="https://www.enju-tsubaki.icu/posts/2431c9eb.html"/>
    <id>https://www.enju-tsubaki.icu/posts/2431c9eb.html</id>
    <published>2025-02-10T05:26:18.410Z</published>
    <updated>2025-03-08T10:44:45.456Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🎈1-1-K-近邻算法简介"><a href="#🎈1-1-K-近邻算法简介" class="headerlink" title="🎈1.1 K - 近邻算法简介"></a>🎈1.1 K - 近邻算法简介</h1><h2 id="🌟学习目标"><a href="#🌟学习目标" class="headerlink" title="🌟学习目标"></a>🌟学习目标</h2><ul><li><strong>目标</strong>：了解什么是 KNN 算法</li><li><strong>知道</strong>：KNN 算法求解过程</li></ul><h2 id="🌸1-什么是-K-近邻算法"><a href="#🌸1-什么是-K-近邻算法" class="headerlink" title="🌸1 什么是 K - 近邻算法"></a>🌸1 什么是 K - 近邻算法</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/%E5%9C%B0%E5%9B%BEK%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95.png" alt="Alt text"></p><p>根据你的 “邻居” 来推断出你的类别。</p><h3 id="🐾1-1-K-近邻算法-KNN-概念"><a href="#🐾1-1-K-近邻算法-KNN-概念" class="headerlink" title="🐾1.1 K - 近邻算法 (KNN) 概念"></a>🐾1.1 K - 近邻算法 (KNN) 概念</h3><p>K Nearest Neighbor 算法又叫 KNN 算法，这个算法是机器学习里面一个比较经典的算法，总体来说 KNN 算法是相对比较容易理解的算法。</p><h4 id="💡定义"><a href="#💡定义" class="headerlink" title="💡定义"></a>💡定义</h4><p>如果一个样本在特征空间中的 k 个最相似 (即特征空间中最邻近) 的样本中的大多数属于某一个类别，则该样本也属于这个类别。例如，在一个水果分类问题中，我们有一堆已知类别的水果样本（苹果、橙子等），对于一个未知类别的水果，我们通过计算它与已知水果样本的相似度（距离），找到最相似的 k 个样本，如果这 k 个样本中大多数是苹果，那么我们就可以推断这个未知水果也可能是苹果。</p><h4 id="🌟来源"><a href="#🌟来源" class="headerlink" title="🌟来源"></a>🌟来源</h4><p>KNN 算法最早是由 Cover 和 Hart 提出的一种分类算法。</p><h4 id="📏距离公式"><a href="#📏距离公式" class="headerlink" title="📏距离公式"></a>📏距离公式</h4><p>两个样本的距离可以通过如下公式计算，又叫欧式距离 。<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/%E6%AC%A7%E6%B0%8F%E8%B7%9D%E7%A6%BB.png" alt="Alt text"></p><script type="math/tex; mode=display">对于二维平面上点a(x_{1}, y_{1})与b(x{2}, y{2}) 之间的欧氏距离：</script><script type="math/tex; mode=display">d_{12} = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}</script><script type="math/tex; mode=display">对于三维空间点 a(x{_1}, y{_1}, z{_1})与b(x{_2}, y{_2}, z{_2}) 之间的欧氏距离：</script><script type="math/tex; mode=display">d_{12} = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2 + (z_1 - z_2)^2}</script><script type="math/tex; mode=display">对于n维空间点 a(x_{11}, x_{12}, \ldots, x_{1n})与b(x_{21}, x_{22}, \ldots, x_{2n}) 之间的欧氏距离（两个n维向量）：</script><script type="math/tex; mode=display">d_{12} = \sqrt{\sum_{k=1}^{n} (x_{1k} - x_{2k})^2}</script><h3 id="🍿1-2-电影类型分析"><a href="#🍿1-2-电影类型分析" class="headerlink" title="🍿1.2 电影类型分析"></a>🍿1.2 电影类型分析</h3><p>假设我们现在有几部电影（电影数据表格，包含电影名称、特征数据、类别等信息）。其中有一部 “？号电影” 不知道类别，如何去预测？我们可以利用 K 近邻算法的思想。</p><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/%E7%94%B5%E5%BD%B1%E4%B8%BE%E4%BE%8B.png" alt="Alt text"></p><p>分别计算每个电影和被预测电影的距离，然后求解。比如，我们可以从电影的多个特征（如搞笑镜头、拥抱镜头、打斗镜头等）来计算它们之间的距离。</p><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/%E7%94%B5%E5%BD%B1%E4%B8%BE%E4%BE%8B2.png" alt="Alt text"></p><p>假设我们已经计算出了各电影与 “？号电影” 的距离，如下表所示（示例数据）：<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/%E7%94%B5%E5%BD%B1%E4%B8%BE%E4%BE%8B3.png" alt="Alt text"></p><h3 id="🐼分类过程🐠"><a href="#🐼分类过程🐠" class="headerlink" title="🐼分类过程🐠"></a>🐼分类过程🐠</h3><p>当 (K = 5) 时，从表格中可知距离《唐人街探案》最近的 5 部电影分别是《功夫熊猫》《美人鱼》《宝贝当家》《新步步惊心》《代理情人》。</p><ul><li>这 5 部电影中：</li><li>《功夫熊猫》《美人鱼》《宝贝当家》是喜剧片；</li><li>《新步步惊心》和《代理情人》是爱情片。</li></ul><p>喜剧片的数量为 3，爱情片的数量为 2。  根据 KNN 算法中多数表决的原则，在这 5 个最近邻中，喜剧片的数量占多数。</p><h3 id="🎬结论"><a href="#🎬结论" class="headerlink" title="🎬结论"></a>🎬结论</h3><p>通过 KNN 分析，预测《唐人街探案》的电影类型为喜剧片。因为在距离它最近的 5 部电影中，喜剧片的数量多于其他类型的电影数量。</p><h3 id="📈1-3-KNN-算法流程总结"><a href="#📈1-3-KNN-算法流程总结" class="headerlink" title="📈1.3 KNN 算法流程总结"></a>📈1.3 KNN 算法流程总结</h3><ol><li><strong>计算已知类别数据集中的点与当前点之间的距离</strong>：利用距离公式（如欧氏距离），计算每个已知样本点与待预测点的距离。</li><li><strong>按距离递增次序排序</strong>：将计算得到的距离从小到大进行排序。</li><li><strong>选取与当前点距离最小的 k 个点</strong>：从排序后的距离列表中，选取前 k 个最小距离对应的样本点。</li><li><strong>统计前 k 个点所在的类别出现的频率</strong>：查看这 k 个点分别属于哪些类别，并统计每个类别出现的次数。</li><li><strong>返回前 k 个点出现频率最高的类别作为当前点的预测分类</strong>：如果这 k 个点中属于动作片类别的点最多，那么就预测待预测电影为动作片。</li></ol><h2 id="🌈2-小结"><a href="#🌈2-小结" class="headerlink" title="🌈2 小结"></a>🌈2 小结</h2><ul><li><strong>K - 近邻算法简介【了解】</strong>：就是通过你的 “邻居” 来判断你属于哪个类别。</li><li><strong>如何计算你到你的 “邻居” 的距离</strong>：一般时候，都是使用欧氏距离。欧氏距离能够直观地衡量两个样本在特征空间中的距离远近，帮助我们找到最邻近的样本。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla</summary>
      
    
    
    
    <category term="机器学习" scheme="https://www.enju-tsubaki.icu/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="KNN" scheme="https://www.enju-tsubaki.icu/tags/KNN/"/>
    
  </entry>
  
</feed>
