<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Hello World</title>
      <link href="/posts/3610a686.html"/>
      <url>/posts/3610a686.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>🌟 <strong>简单的自我介绍</strong></p><p>大家好，我是 Coisini，来自古城西安，是陕西理工大学数计学院人工智能专业的学生。</p><p>🚀 <strong>编程的目标方向</strong></p><p>我对编程充满热情，尤其专注于人工智能领域的研究与应用，致力于探索机器学习和深度学习算法的潜力。通过结合Spring Boot框架，我能够快速构建稳定的应用程序，为AI算法的实际部署提供强有力的支持。利用MyBatis简化数据库操作，使我更专注于业务逻辑优化和算法实现，而Maven则帮助我高效管理项目依赖和构建过程，使开发更加流畅。每次攻克技术难题、掌握新概念，都让我感到极大的满足与成就，力求在AI技术的研究与实践中不断前进。</p><p>🌱 <strong>未来的学习方向</strong></p><p>在这个快速发展的时代，我立志于紧跟人工智能领域的前沿趋势，深入学习并掌握一系列关键技术，包括但不限于DeepSeek、Cursor、Dify、工作流、智能体以及知识库等。这些技术代表了当前AI技术发展的重要方向，它们不仅能够提升我的专业技能，也为解决复杂问题提供了新的思路和工具。</p>]]></content>
      
      
      <categories>
          
          <category> 个人简介 </category>
          
          <category> 编程学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 机器学习 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> SpringBoot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch 入门指南2：Tensor 的深度解析（概念篇）</title>
      <link href="/posts/ea1d749f.html"/>
      <url>/posts/ea1d749f.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="📚PyTorch-入门指南2：Tensor-的深度解析（概念篇）"><a href="#📚PyTorch-入门指南2：Tensor-的深度解析（概念篇）" class="headerlink" title="📚PyTorch 入门指南2：Tensor 的深度解析（概念篇）"></a>📚PyTorch 入门指南2：Tensor 的深度解析（概念篇）</h1><p><img src="https://i-blog.csdnimg.cn/direct/b1975d1d7ac047518b68eb37f995f9cf.png#pic_center" alt="PyTorch的基本概念"></p><p>在 PyTorch 框架里，<code>Tensor（张量）</code> 是核心数据结构之一，与 <code>Variable（autograd）</code>、<code>nn.Module</code> 共同构成 PyTorch 的基础概念体系。Tensor 本质是多维数组，是标量、向量、矩阵在高维空间的延伸，支持 GPU 加速计算，是深度学习模型构建的基础数据形式。</p><h2 id="一、Tensor-的维度概念"><a href="#一、Tensor-的维度概念" class="headerlink" title="一、Tensor 的维度概念"></a>一、Tensor 的维度概念</h2><p><img src="https://i-blog.csdnimg.cn/direct/5a66097f668b4693b3805a91b5c3746e.png#pic_center" alt="Tensor 的维度"></p><p>从维度视角理解，Tensor 包含以下典型形式：<img src="https://i-blog.csdnimg.cn/direct/2a7b3dde9ca54ba0920d62cd3c8c613f.jpeg#pic_center" alt="Tensor维度矩阵"></p><ul><li><strong>标量（零维张量）</strong>：最基础的张量，仅有一个数值（如 3），代表零维数据。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scalar = torch.tensor(<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(scalar.shape)  <span class="comment"># 输出: torch.Size([])</span></span><br></pre></td></tr></table></figure><ul><li><strong>向量（一维张量）</strong>：一维数组（如$ \begin{bmatrix}<br>3 \ 2 \ 1 \ 4<br>\end{bmatrix}$），用于表示线性数据，对应一维张量。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector = torch.tensor([<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line"><span class="built_in">print</span>(vector.shape)  <span class="comment"># 输出: torch.Size([4])</span></span><br></pre></td></tr></table></figure><ul><li><strong>矩阵（二维张量）</strong>：具有行列结构的二维数组，形如 $n \times m$<br>$（如<br>\begin{bmatrix}<br>3 &amp; 7 &amp; 10 &amp; 6 \<br>2 &amp; 8 &amp; 5 &amp; 2 \<br>1 &amp; 9 &amp; 11 &amp; 3 \<br>4 &amp; 6 &amp; 7 &amp; 8<br>\end{bmatrix}$），是二维张量，用于表示平面数据。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">matrix = torch.tensor([</span><br><span class="line">    [<span class="number">3</span>, <span class="number">7</span>, <span class="number">10</span>, <span class="number">6</span>],</span><br><span class="line">    [<span class="number">2</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">2</span>],</span><br><span class="line">    [<span class="number">1</span>, <span class="number">9</span>, <span class="number">11</span>, <span class="number">3</span>],</span><br><span class="line">    [<span class="number">4</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line">])</span><br><span class="line"><span class="built_in">print</span>(matrix.shape)  <span class="comment"># 输出: torch.Size([4, 4])</span></span><br></pre></td></tr></table></figure><p><img src="https://i-blog.csdnimg.cn/direct/765fe9900b2b49f2b93e6733750b363b.jpeg#pic_center" alt="多维的扩展"></p><ul><li><strong>张量（多维扩展）</strong>：维度超过二维的统称，以三维张量为例，其形式为 ($n \times m \times C$)，表示在二维矩阵 ($n \times m$) 的基础上，沿着第三个维度（如通道、时间等）延伸出 $\mathbf{C}$ 个切片，形成立体结构。<br>例如：<ul><li>三维张量可表示立体数据（如视频帧序列 $T \times H \times W$，即时间 × 高度 × 宽度），其中每个二维切片$H \times W$对应一帧图像，沿时间维度延伸 $\mathbf{T}$ 个连续帧，共同构成三维张量。</li><li>彩色图像的维度为 $H \times W \times 3$(高度 × 宽度 × 通道数），其中每个二维切片$H \times W$对应红、绿、蓝三个颜色通道，沿通道维度组合形成三维张量。</li><li>更高维张量适用于复杂场景（如图像批量处理 $B \times H \times W \times C$，即批次 × 高度 × 宽度 × 通道数），其中每个四维张量由 B 个三维图像$H \times W \times C$沿批次维度堆叠，每个三维图像内部包含空间和通道信息。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 三维张量（时间 × 高度 × 宽度）</span></span><br><span class="line">video = torch.randn(<span class="number">10</span>, <span class="number">224</span>, <span class="number">224</span>)  <span class="comment"># 10帧，224×224像素</span></span><br><span class="line"><span class="comment"># 四维张量（批次 × 高度 × 宽度 × 通道）</span></span><br><span class="line">batch_images = torch.randn(<span class="number">32</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>)  <span class="comment"># 32张彩色图像</span></span><br></pre></td></tr></table></figure><p>总结来看，<strong>标量是零维张量，向量是一维张量，矩阵是二维张量</strong>，而张量本身是这些结构在高维空间的泛化，其维度形式可抽象为：</p><script type="math/tex; mode=display">\text{Tensor} = \underbrace{\text{标量}}_{0\text{D}} \rightarrow \underbrace{\text{向量}}_{1\text{D}} \rightarrow \underbrace{\text{矩阵}}_{2\text{D}} \rightarrow \underbrace{\text{高维张量}}_{3\text{D+}}</script><p>这种结构支撑着 PyTorch 数据存储、运算及模型训练的核心功能。</p><h2 id="二、Tensor-与机器学习的关系"><a href="#二、Tensor-与机器学习的关系" class="headerlink" title="二、Tensor 与机器学习的关系"></a>二、Tensor 与机器学习的关系</h2><p><img src="https://i-blog.csdnimg.cn/direct/23561b4d39bf4ee6bf9a09e768a0c8c1.png#pic_center" alt="Tensor 与机器学习的关系"></p><p>在机器学习领域，Tensor（张量）是核心数据结构之一，承载着数据表示与运算的关键功能。从机器学习模型的运行逻辑来看，样本数据与模型参数的交互依赖Tensor实现。例如经典的线性模型公式 <strong>Y = WX + b</strong>，其中输入样本 <strong>X</strong>、权重 <strong>W</strong>、偏置 <strong>b</strong> 以及输出 <strong>Y</strong> 均可由Tensor表示，机器学习框架通过对Tensor的高效运算完成模型训练与推理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用 PyTorch 实现线性模型</span></span><br><span class="line">X = torch.tensor([[<span class="number">1.0</span>], [<span class="number">2.0</span>], [<span class="number">3.0</span>]])  <span class="comment"># 输入特征（3样本 × 1特征）</span></span><br><span class="line">W = torch.tensor([[<span class="number">2.0</span>]], requires_grad=<span class="literal">True</span>)  <span class="comment"># 权重（1特征 × 1输出）</span></span><br><span class="line">b = torch.tensor([<span class="number">0.5</span>], requires_grad=<span class="literal">True</span>)  <span class="comment"># 偏置</span></span><br><span class="line">Y_pred = W * X + b  <span class="comment"># 计算预测值</span></span><br><span class="line"><span class="built_in">print</span>(Y_pred)  <span class="comment"># 输出: tensor([[2.5000], [4.5000], [6.5000]])</span></span><br></pre></td></tr></table></figure><h3 id="Tensor在机器学习中的核心价值"><a href="#Tensor在机器学习中的核心价值" class="headerlink" title="Tensor在机器学习中的核心价值"></a>Tensor在机器学习中的核心价值</h3><ol><li><strong>数据表示</strong>：<br>多维统一：用 Tensor 表示图像（3D）、文本（序列）、视频（4D）等高维数据，支持批量处理。<br>参数存储：神经网络的权重和偏置以 Tensor 形式存储，便于优化和保存。</li><li><strong>运算与加速</strong>：<br>数学运算：支持矩阵乘法、卷积等操作，适配神经网络的复杂计算需求。<br>硬件优化：直接在 GPU/TPU 上运行，通过并行计算加速模型训练（如 ResNet 训练时间从天级缩短至小时级）。</li><li><strong>框架生态与功能</strong>：<br>自动微分：PyTorch/TensorFlow 通过 Tensor 自动推导梯度，简化反向传播实现。<br>动态计算图：允许运行时调整模型结构（如条件分支），提升灵活性。<br>广播与维度：隐式扩展维度，避免手动处理形状（如标量与矩阵相加）。</li></ol><h2 id="三、Tensor-的核心优势"><a href="#三、Tensor-的核心优势" class="headerlink" title="三、Tensor 的核心优势"></a>三、Tensor 的核心优势</h2><ol><li><strong>统一表示</strong>：用单一数据结构承载所有类型的数据，降低开发复杂度。</li><li><strong>硬件无关性</strong>：代码可在 CPU、GPU 甚至分布式集群上无缝运行。</li><li><strong>生态整合</strong>：与 PyTorch 的 <code>nn.Module</code>、<code>autograd</code> 等模块深度集成，支持端到端的模型开发。</li></ol><h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><p>Tensor 不仅是 PyTorch 的基础数据结构，更是机器学习算法的“血液”。通过维度扩展、硬件加速和框架生态整合，Tensor 实现了从原始数据到智能模型的高效转化。下一篇文章将聚焦 Tensor 的创建方式与核心属性，帮助读者掌握其编程实践技巧。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> tensor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch 入门指南1：机器学习基础</title>
      <link href="/posts/b2b2014e.html"/>
      <url>/posts/b2b2014e.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🐍-PyTorch-入门指南-1：机器学习基础"><a href="#🐍-PyTorch-入门指南-1：机器学习基础" class="headerlink" title="🐍 PyTorch 入门指南 1：机器学习基础"></a>🐍 PyTorch 入门指南 1：机器学习基础</h1><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98.png" alt="机器学习的核心问题"></p><h2 id="🔍一、机器学习的核心问题：分类与回归"><a href="#🔍一、机器学习的核心问题：分类与回归" class="headerlink" title="🔍一、机器学习的核心问题：分类与回归"></a>🔍一、机器学习的核心问题：分类与回归</h2><h3 id="🎯1-1-分类问题：离散标签的预测"><a href="#🎯1-1-分类问题：离散标签的预测" class="headerlink" title="🎯1.1 分类问题：离散标签的预测"></a>🎯1.1 分类问题：离散标签的预测</h3><p><strong>定义</strong>：分类任务旨在将输入数据划分到有限个离散的类别中。模型通过学习数据特征，输出样本属于各个类别的概率或直接判定类别。</p><ul><li><strong>数学形式</strong>：给定输入特征向量$\mathbf{x}$，模型学习映射$f: \mathbf{x} \to y$，其中 $y$  是离散类别（如$y \in {0, 1, 2, \dots, C-1}$)，$C$为类别总数）。</li><li><strong>应用场景</strong>：垃圾邮件识别（垃圾/非垃圾）、图像分类（如图二中“airplane”“automobile”等类别判断）。<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/%E5%88%86%E7%B1%BB.png" alt="分类"></li><li><strong>输出特点</strong>：以图二为例，模型输出概率向量 <code>[0.1, 0.1, 0.1, 0.1, 0, 0, 0, 0.5, 0.1, 0]</code>，表示样本属于 10 个类别的概率，最终选择概率最高的类别（第 8 类，概率 0.5）作为预测结果。</li></ul><h3 id="📈1-2-回归问题：连续值的预测"><a href="#📈1-2-回归问题：连续值的预测" class="headerlink" title="📈1.2 回归问题：连续值的预测"></a>📈1.2 回归问题：连续值的预测</h3><p><strong>定义</strong>：回归任务用于预测连续的数值型结果，关注输入与输出之间的定量关系。</p><ul><li><strong>数学形式</strong>：模型学习映射$f: \mathbf{x} \to y$，其中$y$是连续数值（如房价、股票价格涨幅）。</li><li><strong>应用场景</strong>：图三的股票数据预测，通过历史交易数据（开盘价、成交量等特征）预测股票指数（如 2991.56 点）或涨幅（+0.54%）。<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/%E5%9B%9E%E5%BD%92.png" alt="回归"></li><li><strong>输出特点</strong>：直接输出连续数值，用于描述趋势或具体量值，无类别划分。</li></ul><h3 id="🔀1-3-分类与回归的核心区别"><a href="#🔀1-3-分类与回归的核心区别" class="headerlink" title="🔀1.3 分类与回归的核心区别"></a>🔀1.3 分类与回归的核心区别</h3><div class="table-container"><table><thead><tr><th>维度</th><th>分类问题</th><th>回归问题</th></tr></thead><tbody><tr><td>目标输出</td><td>离散类别</td><td>连续数值</td></tr><tr><td>评价指标</td><td>准确率、精确率、召回率等</td><td>均方误差（MSE）、平均绝对误差（MAE）等</td></tr><tr><td>典型模型</td><td>逻辑回归、决策树、神经网络分类器</td><td>线性回归、随机森林回归、神经网络回归</td></tr></tbody></table></div><hr><h2 id="🖼️二、分类问题实战：图像分类案例分析"><a href="#🖼️二、分类问题实战：图像分类案例分析" class="headerlink" title="🖼️二、分类问题实战：图像分类案例分析"></a>🖼️二、分类问题实战：图像分类案例分析</h2><h3 id="📁2-1-图像分类任务流程"><a href="#📁2-1-图像分类任务流程" class="headerlink" title="📁2.1 图像分类任务流程"></a>📁2.1 图像分类任务流程</h3><ol><li><strong>数据准备</strong>：收集标注好的图像数据集（如图二中包含“airplane”“bird”“cat”等类别的图像）。</li><li><strong>特征提取</strong>：通过卷积神经网络（CNN）提取图像的纹理、形状等高层特征。</li><li><strong>模型训练</strong>：使用分类模型（如 ResNet、VGG）学习特征与类别的映射关系。</li><li><strong>预测推断</strong>：输入新图像，模型输出类别概率向量，选择概率最高的类别作为结果。</li></ol><h3 id="📋2-2-输出向量解读"><a href="#📋2-2-输出向量解读" class="headerlink" title="📋2.2 输出向量解读"></a>📋2.2 输出向量解读</h3><p>图二中的概率向量 <code>[0.1, 0.1, 0.1, 0.1, 0, 0, 0, 0.5, 0.1, 0]</code> 表示：</p><ul><li>向量长度对应类别总数（10 类）；</li><li>每个元素值表示属于对应类别的概率，数值越大，属于该类的可能性越高。</li></ul><hr><h2 id="📉三、回归问题实战：股票数据预测"><a href="#📉三、回归问题实战：股票数据预测" class="headerlink" title="📉三、回归问题实战：股票数据预测"></a>📉三、回归问题实战：股票数据预测</h2><h3 id="📊3-1-股票数据特征与目标"><a href="#📊3-1-股票数据特征与目标" class="headerlink" title="📊3.1 股票数据特征与目标"></a>📊3.1 股票数据特征与目标</h3><ul><li><strong>输入特征</strong>：图三中的“今开”“昨收”“成交量”“成交额”等数据，构成特征向量$\mathbf{x}$。</li><li><strong>预测目标</strong>：股票指数（如 2991.56）、涨幅（+0.54%）等连续值。</li></ul><h3 id="🚀3-2-回归模型构建思路"><a href="#🚀3-2-回归模型构建思路" class="headerlink" title="🚀3.2 回归模型构建思路"></a>🚀3.2 回归模型构建思路</h3><ol><li><strong>数据预处理</strong>：对时间序列数据进行归一化、滑动窗口处理（提取历史序列特征）。</li><li><strong>模型选择</strong>：使用线性回归、LSTM（处理时序数据）或 Transformer 模型。</li><li><strong>训练优化</strong>：以均方误差为损失函数，优化模型参数，拟合数据规律。</li></ol><hr><h2 id="🧩四、机器学习问题的构成元素"><a href="#🧩四、机器学习问题的构成元素" class="headerlink" title="🧩四、机器学习问题的构成元素"></a>🧩四、机器学习问题的构成元素</h2><p>如图四所示，机器学习问题由以下核心元素构成：<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98%E7%9A%84%E6%9E%84%E6%88%90%E5%85%83%E7%B4%A0.png" alt="机器学习问题的构成元素"></p><h3 id="📇4-1-样本（数据）"><a href="#📇4-1-样本（数据）" class="headerlink" title="📇4.1 样本（数据）"></a>📇4.1 样本（数据）</h3><ul><li><strong>定义</strong>：用于训练和测试的数据集，包含特征（输入）和标签（输出）。</li><li><strong>作用</strong>：模型通过学习样本数据，捕捉数据中的潜在规律。例如图像分类的样本是“图像特征+类别标签”，股票回归的样本是“交易特征+价格标签”。</li></ul><h3 id="🤖4-2-模型"><a href="#🤖4-2-模型" class="headerlink" title="🤖4.2 模型"></a>🤖4.2 模型</h3><ul><li><strong>定义</strong>：描述输入与输出关系的数学结构，如线性模型、神经网络、决策树等。</li><li><strong>设计原则</strong>：根据任务类型选择模型（分类用 Softmax 输出，回归用线性输出），平衡模型复杂度与泛化能力。</li></ul><h3 id="🔄4-3-训练"><a href="#🔄4-3-训练" class="headerlink" title="🔄4.3 训练"></a>🔄4.3 训练</h3><ul><li><strong>流程</strong>：<ol><li>定义损失函数（分类用交叉熵，回归用均方误差）；</li><li>选择优化器（如 SGD、Adam）；</li><li>通过反向传播调整模型参数，最小化损失。</li></ol></li><li><strong>目标</strong>：让模型在训练样本上学习到正确的映射关系。</li></ul><h3 id="🌟4-4-测试"><a href="#🌟4-4-测试" class="headerlink" title="🌟4.4 测试"></a>🌟4.4 测试</h3><ul><li><strong>作用</strong>：使用未参与训练的测试样本评估模型性能，验证模型的泛化能力。</li><li><strong>指标</strong>：分类任务关注准确率，回归任务关注 MSE 等。</li></ul><h3 id="🌌4-5-推理"><a href="#🌌4-5-推理" class="headerlink" title="🌌4.5 推理"></a>🌌4.5 推理</h3><ul><li><strong>定义</strong>：使用训练好的模型对新数据进行预测，输出分类结果或回归值。</li><li><strong>应用</strong>：部署模型到实际场景（如股票预测系统、图像分类APP），提供实时预测服务。</li></ul><hr><h2 id="🎉五、总结"><a href="#🎉五、总结" class="headerlink" title="🎉五、总结"></a>🎉五、总结</h2><p>机器学习通过解决分类与回归问题，赋能图像识别、金融预测等众多领域。理解分类与回归的本质区别，掌握样本、模型、训练等构成元素，是构建高效机器学习系统的基础。无论是处理离散类别还是连续数值，围绕核心元素设计流程，才能让模型在实际场景中发挥价值。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性回归的优化</title>
      <link href="/posts/7f94e68d.html"/>
      <url>/posts/7f94e68d.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🐰线性回归优化😜"><a href="#🐰线性回归优化😜" class="headerlink" title="🐰线性回归优化😜"></a>🐰线性回归优化😜</h1><p>在机器学习的领域中，线性回归作为一种基础且重要的算法，有着广泛的应用。然而，在实际运用过程中，我们常常会遇到欠拟合和过拟合的问题，它们如同拦路虎一般，影响着模型的性能。接下来，就让我们深入了解这两个问题以及如何对线性回归进行优化。</p><h2 id="🐱‍🏍一、欠拟合与过拟合的定义"><a href="#🐱‍🏍一、欠拟合与过拟合的定义" class="headerlink" title="🐱‍🏍一、欠拟合与过拟合的定义"></a>🐱‍🏍一、欠拟合与过拟合的定义</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%AC%A0%E6%8B%9F%E5%90%88%E8%BF%87%E6%8B%9F%E5%90%88%E5%9B%BE%E7%A4%BA.png" alt="Alt text"></p><h3 id="🐻（一）过拟合"><a href="#🐻（一）过拟合" class="headerlink" title="🐻（一）过拟合"></a>🐻（一）过拟合</h3><p>过拟合指的是一个假设在训练数据上能够获得比其他假设更好的拟合效果，但是在测试数据集上却不能很好地拟合数据。这通常是因为模型过于复杂，它努力去适应训练数据中的每一个细节，包括一些噪声，从而导致在面对新数据时缺乏泛化能力。比如，在一个预测房价的模型中，如果模型把训练数据中某几个特殊房子的独特特征（如房子旁边恰好有个独特的小雕塑）过度学习，而这些特征并非普遍影响房价的因素，那么在遇到没有这个小雕塑的房子时，模型的预测就会出现偏差。</p><h3 id="🐼（二）欠拟合"><a href="#🐼（二）欠拟合" class="headerlink" title="🐼（二）欠拟合"></a>🐼（二）欠拟合</h3><p>欠拟合则是一个假设在训练数据上不能获得良好的拟合，并且在测试数据集上同样不能很好地拟合数据。原因是模型过于简单，无法捕捉到数据中的足够特征和规律。继续以房价预测为例，如果模型仅仅考虑房子的面积这一个特征，而忽略了诸如房间数量、地段等其他重要因素，那么它对房价的预测结果必然是不准确的，这就是典型的欠拟合现象。</p><h2 id="🐥二、欠拟合与过拟合的原因及解决办法"><a href="#🐥二、欠拟合与过拟合的原因及解决办法" class="headerlink" title="🐥二、欠拟合与过拟合的原因及解决办法"></a>🐥二、欠拟合与过拟合的原因及解决办法</h2><h3 id="🐶（一）欠拟合"><a href="#🐶（一）欠拟合" class="headerlink" title="🐶（一）欠拟合"></a>🐶（一）欠拟合</h3><h4 id="🐹1-原因"><a href="#🐹1-原因" class="headerlink" title="🐹1. 原因"></a>🐹1. 原因</h4><p>学习到的数据特征过少，无法全面描述数据中的规律和关系。</p><h4 id="🐰2-解决办法"><a href="#🐰2-解决办法" class="headerlink" title="🐰2. 解决办法"></a>🐰2. 解决办法</h4><ul><li><strong>添加其他特征项</strong>：有时候模型欠拟合是因为特征项不够丰富。我们可以添加多种类型的特征，例如 “组合” 特征（如将房子的面积和房间数量组合成一个新特征，表示单位房间的平均面积）、“泛化” 特征（从一些具体特征中抽象出更宽泛的特征，如将房子所在街道名称泛化为所在区域）、“相关性” 特征（找出与房价有潜在关联的特征，如附近学校的质量）。此外，“上下文特征”（如房子所在小区的整体环境描述）、“平台特征”（如果数据来源于某个特定平台，平台相关的属性特征）等也可以作为添加的选项。</li><li><strong>添加多项式特征</strong>：在机器学习算法中，这是一种常用的手段。比如对于线性模型，我们可以通过添加二次项（如面积的平方）或者三次项（如面积的立方），让模型能够学习到更复杂的关系，从而增强模型的泛化能力。</li></ul><h3 id="🐱（二）过拟合"><a href="#🐱（二）过拟合" class="headerlink" title="🐱（二）过拟合"></a>🐱（二）过拟合</h3><h4 id="🐭1-原因"><a href="#🐭1-原因" class="headerlink" title="🐭1. 原因"></a>🐭1. 原因</h4><p>原始特征过多，其中存在一些嘈杂的特征，导致模型过于复杂，试图去兼顾各个测试数据点，包括噪声点，从而失去了对整体数据趋势的把握。</p><h4 id="🐮2-解决办法"><a href="#🐮2-解决办法" class="headerlink" title="🐮2. 解决办法"></a>🐮2. 解决办法</h4><ul><li><strong>重新清洗数据</strong>：数据不纯可能是导致过拟合的一个原因。如果数据中存在错误标注、异常值或者大量重复数据等杂质，模型在学习过程中可能会受到干扰，从而产生过拟合。此时，重新清洗数据，去除这些杂质，能够让模型学习到更准确的模式。</li><li><strong>增大数据的训练量</strong>：当用于训练的数据量太小，训练数据占总数据的比例过小时，模型可能无法充分学习到数据的全貌和规律，容易对训练数据中的噪声过度拟合。增加训练数据量，可以让模型看到更多的样本，从而更好地泛化到新的数据上。</li><li><strong>正则化</strong>：这是一种重要的防止过拟合的方法，通过对模型的参数进行约束，使得模型在拟合数据的同时，尽量保持简单。下面我们会详细介绍正则化的相关内容。</li><li><strong>减少特征维度</strong>：过多的特征维度可能会引发维灾难，导致模型复杂度增加和过拟合风险上升。我们可以通过一些特征选择的方法，去除那些对模型贡献不大或者相关性过高的特征，降低特征维度，提高模型的性能。</li></ul><h2 id="🐷三、正则化：防止过拟合的神奇魔法棒"><a href="#🐷三、正则化：防止过拟合的神奇魔法棒" class="headerlink" title="🐷三、正则化：防止过拟合的神奇魔法棒"></a>🐷三、正则化：防止过拟合的神奇魔法棒</h2><h3 id="🐸（一）什么是正则化"><a href="#🐸（一）什么是正则化" class="headerlink" title="🐸（一）什么是正则化"></a>🐸（一）什么是正则化</h3><p>在解决回归过拟合问题时，我们常常会选择正则化。实际上，对于其他机器学习算法如分类算法，同样可能出现过拟合问题，除了一些算法本身具有防止过拟合的机制（如决策树通过剪枝、神经网络通过一些结构设计和训练技巧）外，我们更多时候需要自己进行特征选择。</p><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%A8%A1%E5%9E%8B%E5%A4%8D%E6%9D%82.png" alt="Alt text"></p><p><strong>如何解决？</strong></p><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%AD%A3%E5%88%99%E5%8C%96.png" alt="Alt text"></p><p>正则化的核心思想是，在学习过程中，当数据提供的某些特征对模型复杂度有较大影响或者这些特征的数据点异常较多时，算法会尽量减少这些特征的影响，甚至删除某个特征的影响。不过需要注意的是，算法在调整时并不知道具体是哪个特征产生影响，而是通过调整参数来达到优化的结果。</p><h3 id="🐯（二）正则化类别"><a href="#🐯（二）正则化类别" class="headerlink" title="🐯（二）正则化类别"></a>🐯（二）正则化类别</h3><h4 id="🐴1-L2-正则化"><a href="#🐴1-L2-正则化" class="headerlink" title="🐴1. L2 正则化"></a>🐴1. L2 正则化</h4><ul><li><strong>作用</strong>：可以使得模型中的一些权重系数 W 都变得很小，接近于 0，从而削弱某个特征的影响。例如在房价预测中，如果某个特征（如房子旁边树木的数量）对房价的影响较小，通过 L2 正则化，该特征对应的权重系数就会被调整得很小。</li><li><strong>优点</strong>：越小的参数说明模型越简单，而越简单的模型则越不容易产生过拟合现象。这是因为简单模型不会过于复杂地去拟合训练数据中的噪声和特殊情况，能够更好地捕捉数据的整体趋势，从而在新数据上有更好的泛化能力。以岭回归（Ridge Regression）为代表的模型应用了 L2 正则化。</li></ul><h4 id="🐵2-L1-正则化"><a href="#🐵2-L1-正则化" class="headerlink" title="🐵2. L1 正则化"></a>🐵2. L1 正则化</h4><ul><li><strong>作用</strong>：可以使得其中一些权重系数 W 的值直接变为 0，相当于删除了这个特征的影响。比如在众多影响房价的特征中，如果某个特征（如房子窗户的颜色）实际上与房价并无关联，L1 正则化可能会将其对应的权重系数置为 0，从而在模型中去除这个无关特征。</li><li><strong>代表模型</strong>：LASSO 回归（Least Absolute Shrinkage and Selection Operator Regression）是应用 L1 正则化的典型模型。LASSO 回归有一个重要性质，它倾向于完全消除不重要的权重。当正则化参数 α 取值相对较大时，高阶多项式退化为二次甚至线性，即高阶多项式特征的权重被置为 0，能够自动进行特征选择，并输出一个稀疏模型（只有少数特征的权重是非零的）。</li></ul><h2 id="🐝四、正则化线性模型"><a href="#🐝四、正则化线性模型" class="headerlink" title="🐝四、正则化线性模型"></a>🐝四、正则化线性模型</h2><h3 id="🐛（一）岭回归（Ridge-Regression，又名-Tikhonov-regularization）"><a href="#🐛（一）岭回归（Ridge-Regression，又名-Tikhonov-regularization）" class="headerlink" title="🐛（一）岭回归（Ridge Regression，又名 Tikhonov regularization）"></a>🐛（一）岭回归（Ridge Regression，又名 Tikhonov regularization）</h3><p>岭回归是线性回归的正则化版本，它在原来线性回归的代价函数中添加了正则项（regularization term）。其代价函数为：</p><script type="math/tex; mode=display">J(\theta) = MSE(\theta) + \alpha \frac{1}{2} \sum_{i=1}^{n} \theta_{i}^{2}</script><p>，其中 $ MSE(\theta)$ 是均方误差，α 是正则化参数，$  \theta_{i}$是模型的权重系数。当 α = 0 时，岭回归退化为线性回归。岭回归的目的是在拟合数据的同时，使模型权重尽可能小，从而防止过拟合。在 Python 的 scikit - learn 库中，可以使用<code>Ridge</code>类来实现岭回归：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line">estimator = Ridge(alpha = <span class="number">1.0</span>, fit_intercept = <span class="literal">True</span>, solver = <span class="string">&quot;auto&quot;</span>, normalize = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure><ul><li><code>alpha</code>：正则化力度，也叫 λ，取值范围一般为 0~1 或 1~10 等，值越大，正则化力度越强，权重系数会越小；值越小，正则化力度越弱，权重系数会越大。</li><li><code>solver</code>：会根据数据自动选择优化方法，例如当数据集和特征都比较大时，可以选择<code>sag</code>随机梯度下降优化方法。</li><li><code>normalize</code>：数据是否进行标准化，<code>normalize = False</code>时，可以在<code>fit</code>之前调用<code>preprocessing.StandardScaler</code>对数据进行标准化处理。</li><li><code>Ridge.coef_</code>：可以获取回归权重。</li><li><code>Ridge.intercept_</code>：可以获取回归偏置。</li></ul><p>Ridge 方法相当于 SGDRegressor (penalty=’l2’, loss=”squared_loss”)，只不过 SGDRegressor 实现了一个普通的随机梯度下降学习，推荐使用 Ridge (实现了 SAG)。</p><p>另外，<code>sklearn.linear_model.RidgeCV(_BaseRidgeCV, RegressorMixin)</code>是具有 l2 正则化且可以进行交叉验证的线性回归。其中：</p><ul><li><code>coef_</code>可获取回归系数。</li><li><code>class _BaseRidgeCV(LinearModel)</code>的初始化参数有<code>alphas=(0.1, 1.0, 10.0)</code>（用于指定交叉验证时尝试的不同正则化参数值），<code>fit_intercept=True</code>（是否计算截距），<code>normalize=False</code>（数据是否标准化），<code>scoring=None</code>（用于指定评估指标），<code>cv=None</code>（交叉验证折数），<code>gcv_mode=None</code>，<code>store_cv_values=False</code>（是否存储交叉验证的详细结果） 。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">_BaseRidgeCV</span>(<span class="title class_ inherited__">LinearModel</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, alphas=(<span class="params"><span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">10.0</span></span>),</span></span><br><span class="line"><span class="params">                 fit_intercept=<span class="literal">True</span>, normalize=<span class="literal">False</span>,scoring=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 cv=<span class="literal">None</span>, gcv_mode=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 store_cv_values=<span class="literal">False</span></span>):</span><br></pre></td></tr></table></figure><h3 id="🐙（二）Lasso-回归（Lasso-Regression）"><a href="#🐙（二）Lasso-回归（Lasso-Regression）" class="headerlink" title="🐙（二）Lasso 回归（Lasso Regression）"></a>🐙（二）Lasso 回归（Lasso Regression）</h3><p>Lasso 回归是线性回归的另一种正则化版本，其正则项为权值向量的ℓ1 范数，代价函数为：</p><script type="math/tex; mode=display">J(\theta) = MSE(\theta) + \alpha \sum_{i=1}^{n} |\theta_{i}|</script><p>需要注意的是，Lasso 回归的代价函数在$\theta<em>{i} = 0$处是不可导的。解决方法是在$ \theta</em>{i} = 0$处用一个次梯度向量（subgradient vector）代替梯度。</p><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/lasso%E5%9B%9E%E5%BD%92.png" alt="Alt text"></p><p>Lasso 回归具有能够自动进行特征选择的重要性质，当 α 取值相对较大时，高阶多项式退化为二次甚至线性，高阶多项式特征的权重被置为 0，输出一个稀疏模型。在 scikit - learn 库中，可以使用<code>Lasso</code>类来实现 Lasso 回归：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line">estimator = Lasso(alpha = <span class="number">1.0</span>, fit_intercept = <span class="literal">True</span>, normalize = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h3 id="🐚（三）弹性网络（Elastic-Net）"><a href="#🐚（三）弹性网络（Elastic-Net）" class="headerlink" title="🐚（三）弹性网络（Elastic Net）"></a>🐚（三）弹性网络（Elastic Net）</h3><p>弹性网络是在岭回归和 Lasso 回归之间进行了折中，通过混合比（mix ratio）r 进行控制。</p><p>弹性网络的代价函数为：</p><script type="math/tex; mode=display">J(\theta) = MSE(\theta) + r\alpha \sum_{i=1}^{n} |\theta_{i}| + (1 - r)\alpha \frac{1}{2} \sum_{i=1}^{n} \theta_{i}^{2}</script><ul><li>其中 r 是混合比。</li><li>当 r = 0 时，弹性网络变为岭回归，主要通过 L2 正则化来约束权重。</li><li>当 r = 1 时，弹性网络变为 Lasso 回归，主要利用 L1 正则化来筛选特征。<br>弹性网络结合了岭回归和 Lasso 回归的优点，在一些情况下能够表现得更加稳定和优秀。例如在特征维度高于训练样本数，或者特征是强相关的情况下，Lasso 回归的表现可能不太稳定，此时弹性网络可能是更好的选择。</li></ul><p>在 scikit - learn 库中，可以使用<code>ElasticNet</code>类来实现弹性网络：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> ElasticNet</span><br><span class="line">estimator = ElasticNet(alpha = <span class="number">1.0</span>, l1_ratio = <span class="number">0.5</span>, fit_intercept = <span class="literal">True</span>, normalize = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure><ul><li><code>l1_ratio</code>：对应混合比 r，取值范围为 0~1。</li></ul><p>一般来说，在实际应用中，我们应避免使用朴素线性回归，而应对模型进行一定的正则化处理。通常情况下，岭回归较为常用；如果假设只有少部分特征是有用的，弹性网络和 Lasso 回归是不错的选择，不过一般弹性网络的使用更为广泛，因为在一些复杂的数据情况下（如特征维度高于训练样本数，或者特征是强相关的情况），Lasso 回归的表现不太稳定。</p><h3 id="🐠（四）Early-Stopping（了解）"><a href="#🐠（四）Early-Stopping（了解）" class="headerlink" title="🐠（四）Early Stopping（了解）"></a>🐠（四）Early Stopping（了解）</h3><p>Early Stopping 也是正则化迭代学习的方法之一。其做法是在验证错误率达到最小值的时候停止训练。在训练模型时，随着训练的进行，模型在训练集上的误差通常会不断下降，但在验证集上的误差可能会先下降后上升，这是过拟合的一个信号。Early Stopping 通过监控验证集上的误差，当误差不再下降（或开始上升）时，就停止训练，防止模型过度拟合训练数据。虽然 scikit - learn 库中没有专门的 Early Stopping 类用于线性回归的直接实现，但在一些深度学习框架（如 TensorFlow、PyTorch）中，很容易实现 Early Stopping 机制来优化模型训练过程。</p><h2 id="🧐观察正则化程度的变化，对结果的影响？"><a href="#🧐观察正则化程度的变化，对结果的影响？" class="headerlink" title="🧐观察正则化程度的变化，对结果的影响？"></a>🧐观察正则化程度的变化，对结果的影响？</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%AD%A3%E5%88%99%E5%8C%96%E5%8A%9B%E5%BA%A6.png" alt="Alt text"></p><ul><li>正则化力度越大，权重系数会越小</li><li>正则化力度越小，权重系数会越大</li></ul><h2 id="🐣五、线性回归的改进-岭回归案例"><a href="#🐣五、线性回归的改进-岭回归案例" class="headerlink" title="🐣五、线性回归的改进 - 岭回归案例"></a>🐣五、线性回归的改进 - 岭回归案例</h2><p>下面我们通过一个具体的案例来展示岭回归在波士顿房价预测中的应用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">linear_ridgeModel</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    线性回归:岭回归</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1.获取数据</span></span><br><span class="line">    data = load_boston()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.数据集划分</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, random_state = <span class="number">22</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.特征工程-标准化</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.fit_transform(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.机器学习-线性回归(岭回归)</span></span><br><span class="line">    estimator = Ridge(alpha = <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># estimator = RidgeCV(alphas=(0.1, 1, 10))</span></span><br><span class="line">    estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.模型评估</span></span><br><span class="line">    <span class="comment"># 5.1 获取系数等值</span></span><br><span class="line">    y_predict = estimator.predict(x_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;预测值为:\n&quot;</span>, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型中的系数为:\n&quot;</span>, estimator.coef_)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型中的偏置为:\n&quot;</span>, estimator.intercept_)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.2 评价</span></span><br><span class="line">    <span class="comment"># 均方误差</span></span><br><span class="line">    error = mean_squared_error(y_test, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;误差为:\n&quot;</span>, error)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    linear_ridgeModel()</span><br></pre></td></tr></table></figure><p>在这个案例中，我们首先加载了波士顿房价数据集，然后将其划分为训练集和测试集。接着对数据进行标准化处理，这有助于提高模型的训练效果和收敛速度。之后使用岭回归模型进行训练，并对模型进行评估，通过均方误差来衡量模型的预测准确性。</p><h2 id="🐤六、模型的保存和加载"><a href="#🐤六、模型的保存和加载" class="headerlink" title="🐤六、模型的保存和加载"></a>🐤六、模型的保存和加载</h2><p>在机器学习中，我们常常需要保存训练好的模型，以便在后续的应用中直接加载使用，而无需重新训练。在 scikit - learn 库中，可以使用<code>joblib</code>工具来实现模型的保存和加载。</p><h3 id="🐧（一）API"><a href="#🐧（一）API" class="headerlink" title="🐧（一）API"></a>🐧（一）API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br></pre></td></tr></table></figure><ul><li><strong>保存</strong>：<code>joblib.dump(estimator, &#39;test.pkl&#39;)</code>，其中<code>estimator</code>是训练好的模型对象，<code>&#39;test.pkl&#39;</code>是保存模型的文件名，注意保存文件的后缀名一般是<code>.pkl</code>。</li><li><strong>加载</strong>：<code>estimator = joblib.load(&#39;test.pkl&#39;)</code>，通过<code>joblib.load</code>方法将保存的模型加载到内存中，并赋值给一个变量<code>estimator</code>，后续就可以使用这个模型进行预测等操作。</li></ul><h3 id="🐳（二）线性回归的模型保存加载案例"><a href="#🐳（二）线性回归的模型保存加载案例" class="headerlink" title="🐳（二）线性回归的模型保存加载案例"></a>🐳（二）线性回归的模型保存加载案例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_dump_demo</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    模型保存和加载</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1.获取数据</span></span><br><span class="line">    data = load_boston()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.数据集划分</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.特征工程-标准化</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.fit_transform(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.机器学习-线性回归(岭回归)</span></span><br><span class="line">    <span class="comment"># # 4.1 模型训练</span></span><br><span class="line">    <span class="comment"># estimator = Ridge(alpha=1)</span></span><br><span class="line">    <span class="comment"># estimator.fit(x_train, y_train)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># # 4.2 模型保存</span></span><br><span class="line">    <span class="comment"># joblib.dump(estimator, &quot;./data/test.pkl&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.3 模型加载</span></span><br><span class="line">    estimator = joblib.load(<span class="string">&quot;./data/test.pkl&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.模型评估</span></span><br><span class="line">    <span class="comment"># 5.1 获取系数等值</span></span><br><span class="line">    y_predict = estimator.predict(x_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;预测值为:\n&quot;</span>, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型中的系数为:\n&quot;</span>, estimator.coef_)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型中的偏置为:\n&quot;</span>, estimator.intercept_)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.2 评价</span></span><br><span class="line">    <span class="comment"># 均方误差</span></span><br><span class="line">    error = mean_squared_error(y_test, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;误差为:\n&quot;</span>, error)</span><br></pre></td></tr></table></figure><p>在这个案例中，我们可以选择先训练模型并保存，也可以直接加载已经保存好的模型进行评估。模型保存和加载功能在实际应用中非常实用，比如在生产环境中，我们可以将训练好的稳定模型保存下来，随时加载用于对新数据的预测；或者在不同的项目中复用已经训练好的模型，节省训练时间和计算资源。</p><h2 id="🐾总结"><a href="#🐾总结" class="headerlink" title="🐾总结"></a>🐾总结</h2><p>在本次关于线性回归优化的学习中，我们深入探讨了多个关键要点：</p><ol><li><strong>欠拟合与过拟合</strong>：欠拟合是由于模型过于简单，对数据特征挖掘不充分，导致在训练集和测试集上都表现不佳。而过拟合则是模型过度复杂，把噪声也当作有效信息学习，在训练集上表现良好，但在测试集上效果差。针对欠拟合，可通过添加特征项（如组合、泛化、相关性等特征）或多项式特征来解决；对于过拟合，可采取清洗数据、增大训练量、运用正则化方法以及减少特征维度等措施。</li><li><strong>正则化方法</strong>：正则化是防止过拟合的核心手段，主要有 L2 正则化、L1 正则化和弹性网络等形式。L2 正则化（如岭回归）能使模型的权重系数变小，让模型更简单，减少过拟合风险；L1 正则化（如 Lasso 回归）可使部分权重直接为 0，实现自动的特征选择，输出稀疏模型；弹性网络则综合了岭回归和 Lasso 回归的优势，通过混合比进行控制，在一些复杂数据情况下表现更稳定。</li><li><strong>岭回归的应用</strong>：我们学习了岭回归在 scikit-learn 库中的 API 使用，包括<code>Ridge</code>类和<code>RidgeCV</code>类，并了解了各参数的含义和作用。同时，通过波士顿房价预测的具体案例，展示了岭回归模型的训练、评估过程，以及正则化力度的变化对权重系数和模型结果的影响。</li><li><strong>模型的保存与加载</strong>：掌握了在 scikit-learn 库中使用<code>joblib</code>工具进行模型保存和加载的方法，这在实际应用中能够节省训练时间和计算资源，方便模型在不同场景下的复用。</li></ol><p>这些知识和技能为我们在处理线性回归问题，优化模型性能，以及实际项目中的应用提供了坚实的基础，有助于我们更好地应对各种数据和业务需求，提升模型的准确性和泛化能力。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线性回归 </tag>
            
            <tag> 过拟合 </tag>
            
            <tag> 欠拟合 </tag>
            
            <tag> 正则化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>案例：波士顿房价预测</title>
      <link href="/posts/8164788f.html"/>
      <url>/posts/8164788f.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="😊案例：波士顿房价预测"><a href="#😊案例：波士顿房价预测" class="headerlink" title="😊案例：波士顿房价预测"></a>😊案例：波士顿房价预测</h1><h2 id="😎学习目标"><a href="#😎学习目标" class="headerlink" title="😎学习目标"></a>😎学习目标</h2><p>通过案例掌握正规方程和梯度下降法 api 的使用</p><h2 id="🏠案例背景介绍"><a href="#🏠案例背景介绍" class="headerlink" title="🏠案例背景介绍"></a>🏠案例背景介绍</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%88%BF%E4%BB%B7%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D.png" alt="Alt text"></p><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%88%BF%E4%BB%B7%E6%95%B0%E6%8D%AE%E5%B1%9E%E6%80%A7.png" alt="Alt text"></p><h3 id="📊数据介绍"><a href="#📊数据介绍" class="headerlink" title="📊数据介绍"></a>📊数据介绍</h3><p>房价数据集案例。给定的这些特征，是专家们得出的影响房价的结果属性。我们此阶段不需要自己去探究特征是否有用，只需要使用这些特征。到后面量化很多特征需要我们自己去寻找。</p><h2 id="📈案例分析"><a href="#📈案例分析" class="headerlink" title="📈案例分析"></a>📈案例分析</h2><p>回归当中的数据大小不一致，可能会导致结果影响较大。所以需要做标准化处理，具体步骤如下：</p><ul><li>数据分割与标准化处理</li><li>回归预测</li><li>线性回归的算法效果评估</li></ul><h2 id="📏回归性能评估"><a href="#📏回归性能评估" class="headerlink" title="📏回归性能评估"></a>📏回归性能评估</h2><h3 id="🔍均方误差-Mean-Squared-Error-MSE-评价机制"><a href="#🔍均方误差-Mean-Squared-Error-MSE-评价机制" class="headerlink" title="🔍均方误差 (Mean Squared Error, MSE) 评价机制"></a>🔍均方误差 (Mean Squared Error, MSE) 评价机制</h3><p>在线性回归评估中，均方误差是一种常用的评估指标。</p><script type="math/tex; mode=display">MSE = \frac{1}{m} \sum_{i=1}^{m} (y^i - \bar{y})^2</script><script type="math/tex; mode=display">注：y_i 为预测值，\bar{y} 平均值为真实值。</script><h3 id="💭思考"><a href="#💭思考" class="headerlink" title="💭思考"></a>💭思考</h3><p>MSE 和最小二乘法的区别是？</p><h3 id="📚API-使用"><a href="#📚API-使用" class="headerlink" title="📚API 使用"></a>📚API 使用</h3><p><code>sklearn.metrics.mean_squared_error(y_true, y_pred)</code> 用于计算均方误差回归损失，其中：</p><ul><li><code>y_true</code>：真实值</li><li><code>y_pred</code>：预测值</li><li><code>return</code>：浮点数结果</li></ul><h2 id="💻代码实现"><a href="#💻代码实现" class="headerlink" title="💻代码实现"></a>💻代码实现</h2><h3 id="🧮正规方程"><a href="#🧮正规方程" class="headerlink" title="🧮正规方程"></a>🧮正规方程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">linear_model1</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    线性回归:正规方程</span></span><br><span class="line"><span class="string">    :return:None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1.获取数据</span></span><br><span class="line">    data = load_boston()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.数据集划分</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.特征工程-标准化</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.fit_transform(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.机器学习-线性回归(正规方程)</span></span><br><span class="line">    estimator = LinearRegression()</span><br><span class="line">    estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.模型评估</span></span><br><span class="line">    <span class="comment"># 5.1 获取系数等值</span></span><br><span class="line">    y_predict = estimator.predict(x_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;预测值为:\n&quot;</span>, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型中的系数为:\n&quot;</span>, estimator.coef_)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型中的偏置为:\n&quot;</span>, estimator.intercept_)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.2 评价</span></span><br><span class="line">    <span class="comment"># 均方误差</span></span><br><span class="line">    error = mean_squared_error(y_test, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;误差为:\n&quot;</span>, error)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><h3 id="📶梯度下降法"><a href="#📶梯度下降法" class="headerlink" title="📶梯度下降法"></a>📶梯度下降法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">linear_model2</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    线性回归:梯度下降法</span></span><br><span class="line"><span class="string">    :return:None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1.获取数据</span></span><br><span class="line">    data = load_boston()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.数据集划分</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.特征工程-标准化</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.fit_transform(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.机器学习-线性回归(特征方程)</span></span><br><span class="line">    estimator = SGDRegressor(max_iter=<span class="number">1000</span>)</span><br><span class="line">    estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.模型评估</span></span><br><span class="line">    <span class="comment"># 5.1 获取系数等值</span></span><br><span class="line">    y_predict = estimator.predict(x_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;预测值为:\n&quot;</span>, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型中的系数为:\n&quot;</span>, estimator.coef_)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型中的偏置为:\n&quot;</span>, estimator.intercept_)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.2 评价</span></span><br><span class="line">    <span class="comment"># 均方误差</span></span><br><span class="line">    error = mean_squared_error(y_test, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;误差为:\n&quot;</span>, error)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><h3 id="⚙️调参"><a href="#⚙️调参" class="headerlink" title="⚙️调参"></a>⚙️调参</h3><p>我们也可以尝试去修改学习率，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">estimator = SGDRegressor(max_iter=<span class="number">1000</span>,learning_rate=<span class="string">&quot;constant&quot;</span>,eta0=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><p>此时我们可以通过调参数，找到学习率效果更好的值。</p><h2 id="📝小结"><a href="#📝小结" class="headerlink" title="📝小结"></a>📝小结</h2><ul><li>了解正规方程和梯度下降法 api 在真实案例中的使用</li><li>知道线性回归性能评估方法，如均方误差</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线性回归 </tag>
            
            <tag> 正规方程 </tag>
            
            <tag> 梯度下降法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性回归API</title>
      <link href="/posts/619f1a14.html"/>
      <url>/posts/619f1a14.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🥰2-2-线性回归-API-使用总结"><a href="#🥰2-2-线性回归-API-使用总结" class="headerlink" title="🥰2.2 线性回归 API 使用总结"></a>🥰2.2 线性回归 API 使用总结</h1><h2 id="🎯学习目标"><a href="#🎯学习目标" class="headerlink" title="🎯学习目标"></a>🎯学习目标</h2><ul><li>知道线性回归 api 的简单使用</li><li>了解正规方程的 api 及常用参数</li><li>了解梯度下降法 api 及常用参数</li></ul><h2 id="🌟线性回归-API-介绍"><a href="#🌟线性回归-API-介绍" class="headerlink" title="🌟线性回归 API 介绍"></a>🌟线性回归 API 介绍</h2><h3 id="🧐简单使用版-API"><a href="#🧐简单使用版-API" class="headerlink" title="🧐简单使用版 API"></a>🧐简单使用版 API</h3><p><code>sklearn.linear_model.LinearRegression()</code></p><ul><li><strong>属性</strong>：<ul><li><code>LinearRegression.coef_</code>：回归系数</li></ul></li></ul><h3 id="🎉示例代码"><a href="#🎉示例代码" class="headerlink" title="🎉示例代码"></a>🎉示例代码</h3><h4 id="📋步骤分析"><a href="#📋步骤分析" class="headerlink" title="📋步骤分析"></a>📋步骤分析</h4><ol><li>获取数据集</li><li>数据基本处理（该案例中省略）</li><li>特征工程（该案例中省略）</li><li>机器学习</li><li>模型评估（该案例中省略）</li></ol><h4 id="💻代码过程"><a href="#💻代码过程" class="headerlink" title="💻代码过程"></a>💻代码过程</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入模块</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造数据集</span></span><br><span class="line">x = [[<span class="number">80</span>, <span class="number">86</span>],</span><br><span class="line">     [<span class="number">82</span>, <span class="number">80</span>],</span><br><span class="line">     [<span class="number">85</span>, <span class="number">78</span>],</span><br><span class="line">     [<span class="number">90</span>, <span class="number">90</span>],</span><br><span class="line">     [<span class="number">86</span>, <span class="number">82</span>],</span><br><span class="line">     [<span class="number">82</span>, <span class="number">90</span>],</span><br><span class="line">     [<span class="number">78</span>, <span class="number">80</span>],</span><br><span class="line">     [<span class="number">92</span>, <span class="number">94</span>]]</span><br><span class="line">y = [<span class="number">84.2</span>, <span class="number">80.6</span>, <span class="number">80.1</span>, <span class="number">90</span>, <span class="number">83.2</span>, <span class="number">87.6</span>, <span class="number">79.4</span>, <span class="number">93.4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 机器学习 -- 模型训练</span></span><br><span class="line"><span class="comment"># 实例化API</span></span><br><span class="line">estimator = LinearRegression()</span><br><span class="line"><span class="comment"># 使用fit方法进行训练</span></span><br><span class="line">estimator.fit(x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看回归系数</span></span><br><span class="line"><span class="built_in">print</span>(estimator.coef_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行预测</span></span><br><span class="line"><span class="built_in">print</span>(estimator.predict([[<span class="number">100</span>, <span class="number">80</span>]]))</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="🤓详细参数版-API-介绍"><a href="#🤓详细参数版-API-介绍" class="headerlink" title="🤓详细参数版 API 介绍"></a>🤓详细参数版 API 介绍</h2><h3 id="📝正规方程实现"><a href="#📝正规方程实现" class="headerlink" title="📝正规方程实现"></a>📝正规方程实现</h3><p><code>sklearn.linear_model.LinearRegression(fit_intercept=True)</code></p><ul><li><strong>参数</strong>：<ul><li><code>fit_intercept</code>：是否计算偏置，默认为<code>True</code></li></ul></li><li><strong>属性</strong>：<ul><li><code>LinearRegression.coef_</code>：回归系数</li><li><code>LinearRegression.intercept_</code>：偏置</li></ul></li></ul><h3 id="🚀梯度下降法实现"><a href="#🚀梯度下降法实现" class="headerlink" title="🚀梯度下降法实现"></a>🚀梯度下降法实现</h3><p><code>sklearn.linear_model.SGDRegressor(loss=&quot;squared_loss&quot;, fit_intercept=True, learning_rate =&#39;invscaling&#39;, eta0=0.01)</code></p><ul><li><p><strong>参数</strong>：</p><ul><li><code>loss</code>：损失类型，<code>loss=&quot;squared_loss&quot;</code> 表示普通最小二乘法</li><li><code>fit_intercept</code>：是否计算偏置，默认为<code>True</code></li><li><p><code>learning_rate</code>：学习率填充方式，可选值有：</p><ul><li><code>&#39;constant&#39;</code>：<code>eta = eta0</code></li><li><code>&#39;optimal&#39;</code>：<code>eta = 1.0 / (alpha * (t + t0))</code>（默认）</li><li><code>&#39;invscaling&#39;</code>：<code>eta = eta0 / pow(t, power_t)</code>，其中 <code>power_t=0.25</code> 存在于父类中。对于常数值学习率，可使用 <code>learning_rate=&#39;constant&#39;</code> 并通过 <code>eta0</code> 指定学习率。</li></ul></li></ul></li><li><strong>属性</strong>：<ul><li><code>SGDRegressor.coef_</code>：回归系数</li><li><code>SGDRegressor.intercept_</code>：偏置</li></ul></li></ul><h2 id="✨小结"><a href="#✨小结" class="headerlink" title="✨小结"></a>✨小结</h2><ul><li>正规方程：<code>sklearn.linear_model.LinearRegression()</code></li><li>梯度下降法：<code>sklearn.linear_model.SGDRegressor()</code></li></ul><p>通过以上 API，我们可以根据具体需求选择合适的方法来实现线性回归模型。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> API </tag>
            
            <tag> 线性回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性回归</title>
      <link href="/posts/40997091.html"/>
      <url>/posts/40997091.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🎈2-1-线性回归简介"><a href="#🎈2-1-线性回归简介" class="headerlink" title="🎈2.1 线性回归简介"></a>🎈2.1 线性回归简介</h1><h2 id="🌟学习目标"><a href="#🌟学习目标" class="headerlink" title="🌟学习目标"></a>🌟学习目标</h2><ul><li>了解线性回归的应用场景</li><li>知道线性回归的定义</li></ul><h2 id="🏠1-线性回归应用场景"><a href="#🏠1-线性回归应用场景" class="headerlink" title="🏠1 线性回归应用场景"></a>🏠1 线性回归应用场景</h2><ul><li>房价预测</li><li>销售额度预测</li><li>贷款额度预测</li></ul><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.png" alt="Alt text"></p><h2 id="🔍2-什么是线性回归"><a href="#🔍2-什么是线性回归" class="headerlink" title="🔍2 什么是线性回归"></a>🔍2 什么是线性回归</h2><h3 id="📄2-1-定义与公式"><a href="#📄2-1-定义与公式" class="headerlink" title="📄2.1 定义与公式"></a>📄2.1 定义与公式</h3><p>线性回归 (Linear regression) 是利用回归方程 (函数) 对一个或多个自变量 (特征值) 和因变量 (目标值) 之间关系进行建模的一种分析方式。</p><ul><li>特点：只有一个自变量的情况称为单变量回归，多于一个自变量情况的叫做多元回归。</li></ul><p><strong>通用公式:</strong></p><script type="math/tex; mode=display">h(w) = w_1 x_1 + w_2 x_2 + w_3 x_3 \ldots + b = w^T x + b</script><script type="math/tex; mode=display">其中 w, x 可以理解为矩阵: w = \begin{pmatrix} b \\ w_1 \\ w_2 \end{pmatrix}, \quad x = \begin{pmatrix} 1 \\ x_1 \\ x_2 \end{pmatrix}</script><ul><li>线性回归用矩阵表示举例</li></ul><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9F%A9%E9%98%B5%E8%A1%A8%E7%A4%BA%E6%B3%95.png" alt="Alt text"></p><p>理解示例：</p><ul><li>期末成绩：0.7× 考试成绩 + 0.3× 平时成绩</li><li>房子价格 = 0.02× 中心区域的距离 + 0.04× 城市一氧化氮浓度 + (-0.12× 自住房平均房价) + 0.254× 城镇犯罪率</li></ul><p>上面两个例子，特征值与目标值之间建立了一个关系，这个关系可以理解为线性模型。</p><h3 id="📊2-2-线性回归的特征与目标的关系分析"><a href="#📊2-2-线性回归的特征与目标的关系分析" class="headerlink" title="📊2.2 线性回归的特征与目标的关系分析"></a>📊2.2 线性回归的特征与目标的关系分析</h3><p>线性回归当中主要有两种模型，一种是线性关系，另一种是非线性关系。为便于理解，这里都用单个特征或两个特征举例子。</p><h4 id="🔗线性关系"><a href="#🔗线性关系" class="headerlink" title="🔗线性关系"></a>🔗线性关系</h4><ul><li><strong>单变量线性关系</strong>：<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E7%BA%BF%E6%80%A7%E5%85%B3%E7%B3%BB%E5%9B%BE%EF%BC%88%E5%8D%95%E5%8F%98%E9%87%8F%EF%BC%89.png" alt="Alt text"></li><li><strong>多变量线性关系</strong>：<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%85%B3%E7%B3%BB%EF%BC%88%E5%A4%9A%E5%8F%98%E9%87%8F%EF%BC%89.png" alt="Alt text"></li></ul><ul><li>注释：单特征与目标值的关系呈直线关系，或者两个特征与目标值呈现平面的关系。更高维度的关系记住即可。</li></ul><h4 id="🌌非线性关系"><a href="#🌌非线性关系" class="headerlink" title="🌌非线性关系"></a>🌌非线性关系</h4><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%85%B3%E7%B3%BB.png" alt="Alt text"></p><ul><li>注释：若为非线性关系，回归方程可理解为：$ w_1 x_1 + w_2 x_2^2 + w_3 x_3^2$</li></ul><h2 id="🌈3-小结"><a href="#🌈3-小结" class="headerlink" title="🌈3 小结"></a>🌈3 小结</h2><ul><li><strong>线性回归的定义【了解】：</strong>利用回归方程 (函数) 对一个或多个自变量 (特征值) 和因变量 (目标值) 之间关系进行建模的一种分析方式。</li><li><strong>线性回归的分类【知道】</strong>：</li><li>线性关系</li><li>非线性关系</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线性回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>案例：Facebook 签到位置预测案例</title>
      <link href="/posts/3b1e1cd9.html"/>
      <url>/posts/3b1e1cd9.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🎈-Facebook-签到位置预测案例"><a href="#🎈-Facebook-签到位置预测案例" class="headerlink" title="🎈 Facebook 签到位置预测案例"></a>🎈 Facebook 签到位置预测案例</h1><h2 id="🎯一、学习目标"><a href="#🎯一、学习目标" class="headerlink" title="🎯一、学习目标"></a>🎯一、学习目标</h2><p>通过 Facebook 位置预测案例，熟练掌握KNN算法学习内容。</p><h2 id="📌二、项目描述"><a href="#📌二、项目描述" class="headerlink" title="📌二、项目描述"></a>📌二、项目描述</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/Facebook%E7%AD%BE%E5%88%B0%E4%BD%8D%E7%BD%AE%E9%A2%84%E6%B5%8B.png" alt="Alt text"></p><p>本次比赛的目的是预测一个人将要签到的地方。Facebook 创建了一个虚拟世界，这个世界是一个 10 公里 ×10 公里，共 100 平方公里的区域，其中包含约 10 万个地方。对于给定的坐标集，任务是根据用户的位置、准确性和时间戳等信息，预测用户下一次的签到位置。数据被制作成类似于来自移动设备的位置数据。需要注意的是，只能使用提供的数据进行预测 。</p><h2 id="📚三、数据集介绍"><a href="#📚三、数据集介绍" class="headerlink" title="📚三、数据集介绍"></a>📚三、数据集介绍</h2><h3 id="（一）📄数据介绍"><a href="#（一）📄数据介绍" class="headerlink" title="（一）📄数据介绍"></a>（一）📄数据介绍</h3><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/facebook%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D.png" alt="Alt text"></p><p>涉及的文件有 train.csv 和 test.csv ，各字段含义如下：</p><ul><li><strong>row id</strong>：签入事件的 id。</li><li><strong>x y</strong>：坐标。</li><li><strong>accuracy</strong>：准确度，即定位精度。</li><li><strong>time</strong>：时间戳。</li><li><strong>place_id</strong>：签到的位置，这也是需要预测的内容。</li></ul><h3 id="（二）🔗官网"><a href="#（二）🔗官网" class="headerlink" title="（二）🔗官网"></a>（二）🔗官网</h3><p>数据集官网：<a href="https://www.kaggle.com/navoshta/grid-knn/data">https://www.kaggle.com/navoshta/grid-knn/data</a></p><h2 id="🛠️四、步骤分析"><a href="#🛠️四、步骤分析" class="headerlink" title="🛠️四、步骤分析"></a>🛠️四、步骤分析</h2><h3 id="（一）📊数据基本处理"><a href="#（一）📊数据基本处理" class="headerlink" title="（一）📊数据基本处理"></a>（一）📊数据基本处理</h3><p>对数据做一些基本处理（这里的处理不一定能达到最佳效果，只是简单尝试，有些特征可根据特征选择方式进一步处理）。</p><ol><li><strong>缩小数据集范围</strong>：使用 DataFrame.query () 方法。</li><li><strong>选取有用的时间特征</strong> 。</li><li><strong>将签到位置少于 n 个用户的删除</strong> 。</li></ol><h3 id="（二）✂️分割数据集"><a href="#（二）✂️分割数据集" class="headerlink" title="（二）✂️分割数据集"></a>（二）✂️分割数据集</h3><h3 id="（三）⚖️标准化处理"><a href="#（三）⚖️标准化处理" class="headerlink" title="（三）⚖️标准化处理"></a>（三）⚖️标准化处理</h3><h3 id="（四）🔍k-近邻预测"><a href="#（四）🔍k-近邻预测" class="headerlink" title="（四）🔍k - 近邻预测"></a>（四）🔍k - 近邻预测</h3><p>具体步骤如下：</p><ol><li><strong>获取数据集</strong> 。</li><li><strong>基本数据处理</strong><ul><li><strong>缩小数据范围</strong> 。</li><li><strong>选择时间特征</strong> 。</li><li><strong>去掉签到较少的地方</strong> 。</li><li><strong>确定特征值和目标值</strong> 。</li><li><strong>分割数据集</strong> 。</li></ul></li><li><strong>特征工程 — 特征预处理 (标准化)</strong> 。</li><li><strong>机器学习 — knn+cv</strong> 。</li><li><strong>模型评估</strong> 。</li></ol><h2 id="💻五、代码实现"><a href="#💻五、代码实现" class="headerlink" title="💻五、代码实现"></a>💻五、代码实现</h2><h3 id="（一）📥获取数据集"><a href="#（一）📥获取数据集" class="headerlink" title="（一）📥获取数据集"></a>（一）📥获取数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1、获取数据集</span></span><br><span class="line">facebook = pd.read_csv(<span class="string">&quot;./data/FBlocation/train.csv&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="（二）📈基本数据处理"><a href="#（二）📈基本数据处理" class="headerlink" title="（二）📈基本数据处理"></a>（二）📈基本数据处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2.基本数据处理</span></span><br><span class="line"><span class="comment"># 2.1 缩小数据范围</span></span><br><span class="line">facebook_data = facebook.query(<span class="string">&quot;x&gt;2.0 &amp; x&lt;2.5 &amp; y&gt;2.0 &amp; y&lt;2.5&quot;</span>)</span><br><span class="line"><span class="comment"># 2.2 选择时间特征</span></span><br><span class="line">time = pd.to_datetime(facebook_data[<span class="string">&quot;time&quot;</span>], unit=<span class="string">&quot;s&quot;</span>)</span><br><span class="line">time = pd.DatetimeIndex(time)</span><br><span class="line">facebook_data[<span class="string">&quot;day&quot;</span>] = time.day</span><br><span class="line">facebook_data[<span class="string">&quot;hour&quot;</span>] = time.hour</span><br><span class="line">facebook_data[<span class="string">&quot;weekday&quot;</span>] = time.weekday</span><br><span class="line"><span class="comment"># 2.3 去掉签到较少的地方</span></span><br><span class="line">place_count = facebook_data.groupby(<span class="string">&quot;place_id&quot;</span>).count()</span><br><span class="line">place_count = place_count[place_count[<span class="string">&quot;row_id&quot;</span>]&gt;<span class="number">3</span>]</span><br><span class="line">facebook_data = facebook_data[facebook_data[<span class="string">&quot;place_id&quot;</span>].isin(place_count.index)]</span><br><span class="line"><span class="comment"># 2.4 确定特征值和目标值</span></span><br><span class="line">x = facebook_data[[<span class="string">&quot;x&quot;</span>, <span class="string">&quot;y&quot;</span>, <span class="string">&quot;accuracy&quot;</span>, <span class="string">&quot;day&quot;</span>, <span class="string">&quot;hour&quot;</span>, <span class="string">&quot;weekday&quot;</span>]]</span><br><span class="line">y = facebook_data[<span class="string">&quot;place_id&quot;</span>]</span><br><span class="line"><span class="comment"># 2.5 分割数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">22</span>)</span><br></pre></td></tr></table></figure><h3 id="（三）📐特征工程-—-特征预处理-标准化"><a href="#（三）📐特征工程-—-特征预处理-标准化" class="headerlink" title="（三）📐特征工程 — 特征预处理 (标准化)"></a>（三）📐特征工程 — 特征预处理 (标准化)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3.特征工程--特征预处理(标准化)</span></span><br><span class="line"><span class="comment"># 3.1 实例化一个转换器</span></span><br><span class="line">transfer = StandardScaler()</span><br><span class="line"><span class="comment"># 3.2 调用fit_transform</span></span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.fit_transform(x_test)</span><br></pre></td></tr></table></figure><h3 id="（四）🧩机器学习-—knn-cv"><a href="#（四）🧩机器学习-—knn-cv" class="headerlink" title="（四）🧩机器学习 —knn+cv"></a>（四）🧩机器学习 —knn+cv</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4.机器学习--knn+cv</span></span><br><span class="line"><span class="comment"># 4.1 实例化一个估计器</span></span><br><span class="line">estimator = KNeighborsClassifier()</span><br><span class="line"><span class="comment"># 4.2 调用gridsearchCV</span></span><br><span class="line">param_grid = &#123;<span class="string">&quot;n_neighbors&quot;</span>: [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>]&#125;</span><br><span class="line">estimator = GridSearchCV(estimator, param_grid=param_grid, cv=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 4.3 模型训练</span></span><br><span class="line">estimator.fit(x_train, y_train)</span><br></pre></td></tr></table></figure><h3 id="（五）📊模型评估"><a href="#（五）📊模型评估" class="headerlink" title="（五）📊模型评估"></a>（五）📊模型评估</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 5.模型评估</span></span><br><span class="line"><span class="comment"># 5.1 基本评估方式</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最后预测的准确率为:\n&quot;</span>, score)</span><br><span class="line"></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最后的预测值为:\n&quot;</span>, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测值和真实值的对比情况:\n&quot;</span>, y_predict == y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.2 使用交叉验证后的评估方式</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;在交叉验证中验证的最好结果:\n&quot;</span>, estimator.best_score_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最好的参数模型:\n&quot;</span>, estimator.best_estimator_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每次交叉验证后的验证集准确率结果和训练集准确率结果:\n&quot;</span>,estimator.cv_results_)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>案例：鸢尾花种类预测</title>
      <link href="/posts/6bddf6c7.html"/>
      <url>/posts/6bddf6c7.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🌼案例：鸢尾花种类预测-—-流程实现🥰"><a href="#🌼案例：鸢尾花种类预测-—-流程实现🥰" class="headerlink" title="🌼案例：鸢尾花种类预测 — 流程实现🥰"></a>🌼案例：鸢尾花种类预测 — 流程实现🥰</h1><h2 id="🎯学习目标"><a href="#🎯学习目标" class="headerlink" title="🎯学习目标"></a>🎯学习目标</h2><ul><li><h3 id="🎯目标"><a href="#🎯目标" class="headerlink" title="🎯目标"></a>🎯目标</h3><ul><li>熟悉：机器学习从数据获取到评估的完整流程</li><li>掌握：KNeighborsClassifier的使用及参数设置</li><li>理解：归一化和标准化原理、区别及适用场景</li><li>明晰：交叉验证和网格搜索概念及作用</li><li>运用：交叉验证和网格搜索优化模型</li></ul></li></ul><h2 id="🔍K-近邻算法-API"><a href="#🔍K-近邻算法-API" class="headerlink" title="🔍K - 近邻算法 API"></a>🔍K - 近邻算法 API</h2><p><code>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, algorithm=&#39;auto&#39;)</code></p><h4 id="📋参数说明"><a href="#📋参数说明" class="headerlink" title="📋参数说明"></a>📋参数说明</h4><ul><li><code>n_neighbors</code>：int，可选（默认 = 5），k_neighbors 查询默认使用的邻居数</li><li><code>algorithm</code>：{‘auto’，‘ball_tree’，‘kd_tree’，‘brute’}，快速 k 近邻搜索算法，默认参数为 auto，可以理解为算法自己决定合适的搜索算法。除此之外，用户也可以自己指定搜索算法：<ul><li><code>brute</code>：蛮力搜索，也就是线性扫描，当训练集很大时，计算非常耗时。</li><li><code>kd_tree</code>：构造kd树存储数据以便对其进行快速检索的树形数据结构，kd树也就是数据结构中的二叉树。以中值切分构造的树，每个结点是一个超矩形，在维数小于20时效率高。</li><li><code>ball_tree</code>：是为了克服kd树高维失效而发明的，其构造过程是以质心C和半径r分割样本空间，每个节点是一个超球体。</li></ul></li></ul><h2 id="💡预处理归一化和标准化的精髓✨"><a href="#💡预处理归一化和标准化的精髓✨" class="headerlink" title="💡预处理归一化和标准化的精髓✨"></a>💡预处理归一化和标准化的精髓✨</h2><h3 id="🔢归一化"><a href="#🔢归一化" class="headerlink" title="🔢归一化"></a>🔢归一化</h3><ul><li><strong>核心定义：</strong>将原始数据通过变换映射到指定范围，通常是[0,1]区间。</li><li><p><strong>公式本质：</strong>每一列数据，通过减去最小值，除以极差（最大值与最小值的差）</p><script type="math/tex; mode=display">X' = \frac{x - \min}{\max - \min}</script><p>再乘以指定区间长度并加上区间下限，实现数据的缩放。</p><script type="math/tex; mode=display">X'' = X' * (mx - mi) + mi</script></li><li>主要作用：消除特征之间的量纲差异，使不同特征在模型中具有相同的“地位”，便于进行比较和分析，有助于提高某些对特征范围敏感的机器学习算法的性能。</li><li>API要点：使用 <code>sklearn.preprocessing.MinMaxScaler</code>类，通过 <code>fit_transform</code>方法对 <code>numpy array</code>格式的数据进行转换，可通过 <code>feature_range</code>参数指定映射范围。</li><li>应用局限：最大值和最小值易受异常点影响，导致归一化结果不稳定，鲁棒性较差，适用于传统精确小数据场景。</li></ul><h3 id="🌟标准化"><a href="#🌟标准化" class="headerlink" title="🌟标准化"></a>🌟标准化</h3><ul><li>核心定义：对原始数据进行变换，使数据转换到均值为0、标准差为1的范围内。</li><li><p>公式本质：</p><script type="math/tex; mode=display">X' = \frac{x - \text{mean}}{\sigma}</script><p>针对每一列数据，减去该列的均值，再除以该列的标准差，从而使数据符合标准正态分布。</p></li><li>主要作用：在消除量纲影响的同时，能让数据具有稳定的均值和标准差，使模型更加稳定和高效，尤其适用于对数据分布有一定要求的算法。</li><li>API要点：利用 <code>sklearn.preprocessing.StandardScaler</code>类的 <code>fit_transform</code>方法处理 <code>numpy array</code>格式的数据，处理后每列数据都聚集在均值0附近，标准差为1。</li><li>应用优势：在样本数据足够多的情况下比较稳定，少量异常点对平均值和方差的影响较小，适合现代嘈杂大数据场景。</li></ul><h2 id="🌸案例：鸢尾花种类预测🌼"><a href="#🌸案例：鸢尾花种类预测🌼" class="headerlink" title="🌸案例：鸢尾花种类预测🌼"></a>🌸案例：鸢尾花种类预测🌼</h2><h3 id="📊数据集介绍"><a href="#📊数据集介绍" class="headerlink" title="📊数据集介绍"></a>📊数据集介绍</h3><p>Iris数据集是常用的分类实验数据集，由Fisher, 1936收集整理。Iris也称鸢尾花卉数据集，是一类多重变量分析的数据集。关于数据集的具体介绍：<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/iris%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D.png" alt="Alt text"></p><h3 id="🚀步骤分析"><a href="#🚀步骤分析" class="headerlink" title="🚀步骤分析"></a>🚀步骤分析</h3><ul><li>获取数据集</li><li>数据基本处理</li><li>特征工程</li><li>机器学习 (模型训练)</li><li>模型评估</li></ul><h3 id="💻代码过程"><a href="#💻代码过程" class="headerlink" title="💻代码过程"></a>💻代码过程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入必要的库</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 获取数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 数据基本处理</span></span><br><span class="line"><span class="comment"># x_train,x_test,y_train,y_test为训练集特征值、测试集特征值、训练集目标值、测试集目标值</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=<span class="number">0.2</span>, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 特征工程：标准化</span></span><br><span class="line">transfer = StandardScaler()</span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 机器学习(模型训练)</span></span><br><span class="line">estimator = KNeighborsClassifier(n_neighbors=<span class="number">9</span>)</span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 模型评估</span></span><br><span class="line"><span class="comment"># 方法1：比对真实值和预测值</span></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测结果为:\n&quot;</span>, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;比对真实值和预测值：\n&quot;</span>, y_predict == y_test)</span><br><span class="line"><span class="comment"># 方法2：直接计算准确率</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率为：\n&quot;</span>, score)</span><br></pre></td></tr></table></figure><h2 id="🔄什么是交叉验证-cross-validation-🌟"><a href="#🔄什么是交叉验证-cross-validation-🌟" class="headerlink" title="🔄什么是交叉验证 (cross validation)🌟"></a>🔄什么是交叉验证 (cross validation)🌟</h2><p>交叉验证是一种用于评估模型性能的重要技术。它将拿到的训练数据，进一步细分为训练集和验证集。例如，把数据分成 4 份，其中一份作为验证集。然后经过 4 次（组）的测试，每次都更换不同的验证集，即得到 4 组模型的结果，取平均值作为最终结果，这也被称为 4 折交叉验证。</p><h3 id="🧐分析"><a href="#🧐分析" class="headerlink" title="🧐分析"></a>🧐分析</h3><p>我们之前了解到数据分为训练集和测试集，但为了让从训练得到的模型结果更加准确，我们做如下处理：</p><ul><li>训练集：进一步拆分为训练集和验证集</li><li>测试集：保持不变</li></ul><h3 id="🤔为什么需要交叉验证"><a href="#🤔为什么需要交叉验证" class="headerlink" title="🤔为什么需要交叉验证"></a>🤔为什么需要交叉验证</h3><p>交叉验证的目的是为了让被评估的模型更加准确可信。不过，这只是提升了模型评估的准确性，那如何选择或者调优参数呢？这就引出了网格搜索。</p><h2 id="🔍什么是网格搜索-Grid-Search-🌈"><a href="#🔍什么是网格搜索-Grid-Search-🌈" class="headerlink" title="🔍什么是网格搜索 (Grid Search)🌈"></a>🔍什么是网格搜索 (Grid Search)🌈</h2><p>通常情况下，有很多参数是需要手动指定的（如 k - 近邻算法中的 K 值），这种参数被称为超参数。手动调整超参数的过程繁杂，所以我们需要对模型预设几种超参数组合。每组超参数都采用交叉验证来进行评估，最后选出最优参数组合建立模型。</p><h2 id="🛠交叉验证，网格搜索（模型选择与调优）API📚"><a href="#🛠交叉验证，网格搜索（模型选择与调优）API📚" class="headerlink" title="🛠交叉验证，网格搜索（模型选择与调优）API📚"></a>🛠交叉验证，网格搜索（模型选择与调优）API📚</h2><p><code>sklearn.model_selection.GridSearchCV(estimator, param_grid=None, cv=None)</code> 用于对估计器的指定参数值进行详尽搜索。</p><h4 id="📋参数说明-1"><a href="#📋参数说明-1" class="headerlink" title="📋参数说明"></a>📋参数说明</h4><ul><li><code>estimator</code>：估计器对象</li><li><code>param_grid</code>：估计器参数（字典形式），例如 <code>&#123;&quot;n_neighbors&quot;: [1, 3, 5]&#125;</code></li><li><code>cv</code>：指定几折交叉验证</li><li><code>fit</code>：输入训练数据</li><li><code>score</code>：计算准确率</li></ul><h3 id="📈结果分析"><a href="#📈结果分析" class="headerlink" title="📈结果分析"></a>📈结果分析</h3><ul><li><code>best_score_</code>：在交叉验证中验证的最好结果</li><li><code>best_estimator_</code>：最好的参数模型</li><li><code>cv_results_</code>：每次交叉验证后的验证集准确率结果和训练集准确率结果</li></ul><h2 id="🌺鸢尾花案例增加-K-值调优💐"><a href="#🌺鸢尾花案例增加-K-值调优💐" class="headerlink" title="🌺鸢尾花案例增加 K 值调优💐"></a>🌺鸢尾花案例增加 K 值调优💐</h2><p>以下是使用 <code>GridSearchCV</code> 构建估计器的完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、获取数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、数据基本处理 -- 划分数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、特征工程：标准化</span></span><br><span class="line"><span class="comment"># 实例化一个转换器类</span></span><br><span class="line">transfer = StandardScaler()</span><br><span class="line"><span class="comment"># 调用 fit_transform</span></span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、KNN 预估器流程</span></span><br><span class="line"><span class="comment">#  4.1 实例化预估器类</span></span><br><span class="line">estimator = KNeighborsClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.2 模型选择与调优——网格搜索和交叉验证</span></span><br><span class="line"><span class="comment"># 准备要调的超参数</span></span><br><span class="line">param_dict = &#123;<span class="string">&quot;n_neighbors&quot;</span>: [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>]&#125;</span><br><span class="line">estimator = GridSearchCV(estimator, param_grid=param_dict, cv=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.3 fit 数据进行训练</span></span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、评估模型效果</span></span><br><span class="line"><span class="comment"># 方法 a：比对预测结果和真实值</span></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;比对预测结果和真实值：\n&quot;</span>, y_predict == y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法 b：直接计算准确率</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;直接计算准确率：\n&quot;</span>, score)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看最终选择的结果和交叉验证的结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;在交叉验证中验证的最好结果：\n&quot;</span>, estimator.best_score_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最好的参数模型：\n&quot;</span>, estimator.best_estimator_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每次交叉验证后的准确率结果：\n&quot;</span>, estimator.cv_results_)</span><br></pre></td></tr></table></figure><h3 id="💻代码运行输出结果👇"><a href="#💻代码运行输出结果👇" class="headerlink" title="💻代码运行输出结果👇"></a>💻代码运行输出结果👇</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">比对预测结果和真实值：</span><br><span class="line"> [ True  True  True  True  True  True  True False  True  True  True  True</span><br><span class="line">  True  True  True  True  True  True False  True  True  True  True  True</span><br><span class="line">  True  True  True  True  True  True  True  True  True  True  True  True</span><br><span class="line">  True  True]</span><br><span class="line">直接计算准确率：</span><br><span class="line"> 0.947368421053</span><br><span class="line">在交叉验证中验证的最好结果：</span><br><span class="line"> 0.973214285714</span><br><span class="line">最好的参数模型：</span><br><span class="line"> KNeighborsClassifier(algorithm=&#x27;auto&#x27;, leaf_size=30, metric=&#x27;minkowski&#x27;,</span><br><span class="line">           metric_params=None, n_jobs=1, n_neighbors=5, p=2,</span><br><span class="line">           weights=&#x27;uniform&#x27;)</span><br><span class="line">每次交叉验证后的准确率结果：</span><br><span class="line"> &#123;&#x27;mean_fit_time&#x27;: array([ 0.00114751,  0.00027037,  0.00024462]), &#x27;std_fit_time&#x27;: array([  1.13901511e-03,   1.25300249e-05,   1.11011951e-05]), &#x27;mean_score_time&#x27;: array([ 0.00085751,  0.00048693,  0.00045625]), &#x27;std_score_time&#x27;: array([  3.52785082e-04,   2.87650037e-05,   5.29673344e-06]), &#x27;param_n_neighbors&#x27;: masked_array(data = [1 3 5],</span><br><span class="line">             mask = [False False False],</span><br><span class="line">       fill_value = ?), &#x27;params&#x27;: [&#123;&#x27;n_neighbors&#x27;: 1&#125;, &#123;&#x27;n_neighbors&#x27;: 3&#125;, &#123;&#x27;n_neighbors&#x27;: 5&#125;], &#x27;split0_test_score&#x27;: array([ 0.97368421,  0.97368421,  0.97368421]), &#x27;split1_test_score&#x27;: array([ 0.97297297,  0.97297297,  0.97297297]), &#x27;split2_test_score&#x27;: array([ 0.94594595,  0.89189189,  0.97297297]), &#x27;mean_test_score&#x27;: array([ 0.96428571,  0.94642857,  0.97321429]), &#x27;std_test_score&#x27;: array([ 0.01288472,  0.03830641,  0.00033675]), &#x27;rank_test_score&#x27;: array([2, 3, 1], dtype=int32), &#x27;split0_train_score&#x27;: array([ 1.        ,  0.95945946,  0.97297297]), &#x27;split1_train_score&#x27;: array([ 1.        ,  0.96      ,  0.97333333]), &#x27;split2_train_score&#x27;: array([ 1.  ,  0.96,  0.96]), &#x27;mean_train_score&#x27;: array([ 1.        ,  0.95981982,  0.96876877]), &#x27;std_train_score&#x27;: array([ 0.        ,  0.00025481,  0.0062022 ])&#125;</span><br></pre></td></tr></table></figure><h2 id="📝总结🎉"><a href="#📝总结🎉" class="headerlink" title="📝总结🎉"></a>📝总结🎉</h2><p>本文围绕鸢尾花种类预测案例，详细介绍了机器学习从数据获取到模型评估的完整流程，以及相关的数据预处理、模型调优等重要技术，具体内容总结如下：</p><h3 id="🚀机器学习流程与核心算法"><a href="#🚀机器学习流程与核心算法" class="headerlink" title="🚀机器学习流程与核心算法"></a>🚀机器学习流程与核心算法</h3><ul><li><strong>完整流程</strong>：涵盖获取数据集、数据基本处理、特征工程、模型训练和模型评估等环节，清晰展示了运用机器学习解决实际分类问题的步骤。</li><li><strong>K - 近邻算法</strong>：<code>KNeighborsClassifier</code> 是常用的分类算法，可通过设置 <code>n_neighbors</code> 和 <code>algorithm</code> 等参数进行灵活调整。不同的 <code>algorithm</code> 选项（如 <code>auto</code>、<code>ball_tree</code>、<code>kd_tree</code>、<code>brute</code>）适用于不同的数据规模和维度场景。</li></ul><h3 id="💾数据预处理"><a href="#💾数据预处理" class="headerlink" title="💾数据预处理"></a>💾数据预处理</h3><ul><li><strong>归一化</strong>：将数据映射到指定范围（通常是 [0,1]），能消除特征量纲差异，但易受异常点影响，鲁棒性较差，适用于传统精确小数据场景。使用 <code>sklearn.preprocessing.MinMaxScaler</code> 类实现。</li><li><strong>标准化</strong>：把数据变换到均值为 0、标准差为 1 的范围内，在处理大数据时更为稳定，受异常点影响较小，适合现代嘈杂大数据场景。使用 <code>sklearn.preprocessing.StandardScaler</code> 类实现。</li></ul><h3 id="📊模型评估与调优"><a href="#📊模型评估与调优" class="headerlink" title="📊模型评估与调优"></a>📊模型评估与调优</h3><ul><li><strong>交叉验证</strong>：通过将训练数据划分为多个子集进行多次验证，取结果平均值，可使模型评估结果更加准确可信，提高模型的泛化能力。</li><li><strong>网格搜索</strong>：针对超参数（如 K - 近邻算法中的 <code>n_neighbors</code>）预设多种组合，利用交叉验证评估每组参数的效果，从而选出最优参数组合，优化模型性能。使用 <code>sklearn.model_selection.GridSearchCV</code> 类实现。</li></ul><p>通过鸢尾花种类预测案例，我们不仅掌握了 <code>KNeighborsClassifier</code> 算法的使用，还学会了如何运用数据预处理、交叉验证和网格搜索等技术，提升模型的准确性和稳定性。这些方法和技术在解决各类机器学习分类问题中具有广泛的应用价值。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KNN </tag>
            
            <tag> 特征工程 </tag>
            
            <tag> 交叉验证 </tag>
            
            <tag> 网格搜索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>K-近邻算法API</title>
      <link href="/posts/d5f3c9dd.html"/>
      <url>/posts/d5f3c9dd.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🌟1-2-k近邻算法api初步使用🌟"><a href="#🌟1-2-k近邻算法api初步使用🌟" class="headerlink" title="🌟1.2 k近邻算法api初步使用🌟"></a>🌟1.2 k近邻算法api初步使用🌟</h1><h2 id="🌈学习目标"><a href="#🌈学习目标" class="headerlink" title="🌈学习目标"></a>🌈学习目标</h2><h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><ul><li>了解sklearn工具的优点和包含内容</li><li>应用sklearn中的api实现KNN算法的简单使用</li></ul><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="Alt text"></p><ol><li>获取数据集</li><li>数据基本处理</li><li>特征工程</li><li>机器学习</li><li>模型评估</li></ol><h2 id="🛠️Scikit-learn-工具介绍"><a href="#🛠️Scikit-learn-工具介绍" class="headerlink" title="🛠️Scikit-learn 工具介绍"></a>🛠️Scikit-learn 工具介绍</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/scikitlearn.png" alt="Alt text"></p><p>Scikit-learn是Python语言的机器学习工具，它具有以下特点：</p><ul><li>包括许多知名的机器学习算法的实现</li><li>文档完善，容易上手，拥有丰富的AP</li></ul><h3 id="🔧安装"><a href="#🔧安装" class="headerlink" title="🔧安装"></a>🔧安装</h3><p>使用以下命令进行安装：<br><code>pip3 install scikit-learn</code></p><p>安装好之后可以通过以下命令查看是否安装成功：<br><code>import sklearn</code></p><p>注：安装scikit-learn需要Numpy, Scipy等库。</p><h3 id="📦Scikit-learn包含的内容"><a href="#📦Scikit-learn包含的内容" class="headerlink" title="📦Scikit-learn包含的内容"></a>📦Scikit-learn包含的内容</h3><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/sklearn%E5%8C%85%E5%90%AB%E5%86%85%E5%AE%B9.png" alt="Alt text"></p><ul><li>分类、聚类、回归 - 特征工程</li><li>模型选择、调优</li></ul><h2 id="📌K-近邻算法API"><a href="#📌K-近邻算法API" class="headerlink" title="📌K-近邻算法API"></a>📌K-近邻算法API</h2><p><code>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5)</code></p><ul><li><code>n_neighbors</code>：int，可选（默认 = 5），k_neighbors 查询默认使用的邻居数</li></ul><h2 id="📋案例"><a href="#📋案例" class="headerlink" title="📋案例"></a>📋案例</h2><h3 id="👣步骤分析"><a href="#👣步骤分析" class="headerlink" title="👣步骤分析"></a>👣步骤分析</h3><ol><li>获取数据集</li><li>数据基本处理（该案例中省略）</li><li>特征工程（该案例中省略）</li><li>机器学习</li><li>模型评估（该案例中省略）</li></ol><h3 id="💻代码过程"><a href="#💻代码过程" class="headerlink" title="💻代码过程"></a>💻代码过程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入模块</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造数据集</span></span><br><span class="line">x = [[<span class="number">0</span>], [<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 机器学习 -- 模型训练</span></span><br><span class="line"><span class="comment"># 实例化API</span></span><br><span class="line">estimator = KNeighborsClassifier(n_neighbors=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 使用fit方法进行训练</span></span><br><span class="line">estimator.fit(x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行预测</span></span><br><span class="line">result = estimator.predict([[<span class="number">1</span>]])</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure><h2 id="❓问题解答"><a href="#❓问题解答" class="headerlink" title="❓问题解答"></a>❓问题解答</h2><h3 id="1-选取K值的大小？"><a href="#1-选取K值的大小？" class="headerlink" title="1. 选取K值的大小？"></a>1. 选取K值的大小？</h3><p>K值的选择对KNN模型有重要影响：</p><ul><li><strong>K值过小：</strong><ul><li>容易受到异常点的影响</li><li>容易过拟合，即“学习”近似误差会减小，但“学习”的估计误差会增大，整体模型变得复杂。</li></ul></li><li><strong>K值过大：</strong><ul><li>受到样本均衡的问题</li><li>容易欠拟合，学习的近似误差会增大，模型变得简单。</li></ul></li><li><strong>K=N（N为训练样本个数）：</strong>完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的类，模型过于简单，忽略了训练实例中大量有用信息。</li></ul><p>在实际应用中，K值一般取一个比较小的数值，例如采用交叉验证法（简单来说，就是把训练数据再分成两组：训练集和验证集）来选择最优的K值。</p><p><strong>近似误差：</strong>对现有训练集的训练误差，关注训练集。如果近似误差过小可能会出现过拟合的现象，对现有的训练集能有很好的预测，但是对未知的测试样本将会出现较大偏差的预测，模型本身不是最接近最佳模型。</p><p><strong>估计误差：</strong>可以理解为对测试集的测试误差，关注测试集。估计误差小说明对未知数据的预测能力好，模型本身最接近最佳模型。</p><h3 id="2-api中其他参数的具体含义？"><a href="#2-api中其他参数的具体含义？" class="headerlink" title="2. api中其他参数的具体含义？"></a>2. api中其他参数的具体含义？</h3><p><code>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, algorithm=&#39;auto&#39;)</code></p><ul><li><code>n_neighbors</code>：int，可选（默认 = 5），k_neighbors 查询默认使用的邻居数</li><li><code>algorithm</code>：{‘auto’，‘ball_tree’，‘kd_tree’，‘brute’}，快速 k 近邻搜索算法，默认参数为 auto，可以理解为算法自己决定合适的搜索算法。除此之外，用户也可以自己指定搜索算法：<ul><li><code>brute</code>：蛮力搜索，也就是线性扫描，当训练集很大时，计算非常耗时。</li><li><code>kd_tree</code>：构造kd树存储数据以便对其进行快速检索的树形数据结构，kd树也就是数据结构中的二叉树。以中值切分构造的树，每个结点是一个超矩形，在维数小于20时效率高。</li><li><code>ball_tree</code>：是为了克服kd树高维失效而发明的，其构造过程是以质心C和半径r分割样本空间，每个节点是一个超球体。</li></ul></li></ul><h2 id="📚总结"><a href="#📚总结" class="headerlink" title="📚总结"></a>📚总结</h2><h3 id="sklearn的优势"><a href="#sklearn的优势" class="headerlink" title="sklearn的优势"></a>sklearn的优势</h3><ul><li>文档多，且规范</li><li>包含的算法多 - 实现起来容易</li></ul><h3 id="knn中的api"><a href="#knn中的api" class="headerlink" title="knn中的api"></a>knn中的api</h3><p><code>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, algorithm=&#39;auto&#39;)</code></p><h3 id="KNN中K值大小选择对模型的影响"><a href="#KNN中K值大小选择对模型的影响" class="headerlink" title="KNN中K值大小选择对模型的影响"></a>KNN中K值大小选择对模型的影响</h3><ul><li>K值过小：容易受到异常点的影响，容易过拟合</li><li>K值过大：受到样本均衡的问题，容易欠拟合</li></ul><p>通过以上内容，我们对sklearn工具和KNN算法的API有了初步的了解，并且掌握了如何使用sklearn中的KNN算法进行简单的模型训练和预测。同时，我们也了解了K值选择对模型的影响以及API中其他参数的含义。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KNN </tag>
            
            <tag> API </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>K-近邻算法</title>
      <link href="/posts/2431c9eb.html"/>
      <url>/posts/2431c9eb.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="🎈1-1-K-近邻算法简介"><a href="#🎈1-1-K-近邻算法简介" class="headerlink" title="🎈1.1 K - 近邻算法简介"></a>🎈1.1 K - 近邻算法简介</h1><h2 id="🌟学习目标"><a href="#🌟学习目标" class="headerlink" title="🌟学习目标"></a>🌟学习目标</h2><ul><li><strong>目标</strong>：了解什么是 KNN 算法</li><li><strong>知道</strong>：KNN 算法求解过程</li></ul><h2 id="🌸1-什么是-K-近邻算法"><a href="#🌸1-什么是-K-近邻算法" class="headerlink" title="🌸1 什么是 K - 近邻算法"></a>🌸1 什么是 K - 近邻算法</h2><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/%E5%9C%B0%E5%9B%BEK%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95.png" alt="Alt text"></p><p>根据你的 “邻居” 来推断出你的类别。</p><h3 id="🐾1-1-K-近邻算法-KNN-概念"><a href="#🐾1-1-K-近邻算法-KNN-概念" class="headerlink" title="🐾1.1 K - 近邻算法 (KNN) 概念"></a>🐾1.1 K - 近邻算法 (KNN) 概念</h3><p>K Nearest Neighbor 算法又叫 KNN 算法，这个算法是机器学习里面一个比较经典的算法，总体来说 KNN 算法是相对比较容易理解的算法。</p><h4 id="💡定义"><a href="#💡定义" class="headerlink" title="💡定义"></a>💡定义</h4><p>如果一个样本在特征空间中的 k 个最相似 (即特征空间中最邻近) 的样本中的大多数属于某一个类别，则该样本也属于这个类别。例如，在一个水果分类问题中，我们有一堆已知类别的水果样本（苹果、橙子等），对于一个未知类别的水果，我们通过计算它与已知水果样本的相似度（距离），找到最相似的 k 个样本，如果这 k 个样本中大多数是苹果，那么我们就可以推断这个未知水果也可能是苹果。</p><h4 id="🌟来源"><a href="#🌟来源" class="headerlink" title="🌟来源"></a>🌟来源</h4><p>KNN 算法最早是由 Cover 和 Hart 提出的一种分类算法。</p><h4 id="📏距离公式"><a href="#📏距离公式" class="headerlink" title="📏距离公式"></a>📏距离公式</h4><p>两个样本的距离可以通过如下公式计算，又叫欧式距离 。<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/%E6%AC%A7%E6%B0%8F%E8%B7%9D%E7%A6%BB.png" alt="Alt text"></p><script type="math/tex; mode=display">对于二维平面上点a(x_{1}, y_{1})与b(x{2}, y{2}) 之间的欧氏距离：</script><script type="math/tex; mode=display">d_{12} = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}</script><script type="math/tex; mode=display">对于三维空间点 a(x{_1}, y{_1}, z{_1})与b(x{_2}, y{_2}, z{_2}) 之间的欧氏距离：</script><script type="math/tex; mode=display">d_{12} = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2 + (z_1 - z_2)^2}</script><script type="math/tex; mode=display">对于n维空间点 a(x_{11}, x_{12}, \ldots, x_{1n})与b(x_{21}, x_{22}, \ldots, x_{2n}) 之间的欧氏距离（两个n维向量）：</script><script type="math/tex; mode=display">d_{12} = \sqrt{\sum_{k=1}^{n} (x_{1k} - x_{2k})^2}</script><h3 id="🍿1-2-电影类型分析"><a href="#🍿1-2-电影类型分析" class="headerlink" title="🍿1.2 电影类型分析"></a>🍿1.2 电影类型分析</h3><p>假设我们现在有几部电影（电影数据表格，包含电影名称、特征数据、类别等信息）。其中有一部 “？号电影” 不知道类别，如何去预测？我们可以利用 K 近邻算法的思想。</p><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/%E7%94%B5%E5%BD%B1%E4%B8%BE%E4%BE%8B.png" alt="Alt text"></p><p>分别计算每个电影和被预测电影的距离，然后求解。比如，我们可以从电影的多个特征（如搞笑镜头、拥抱镜头、打斗镜头等）来计算它们之间的距离。</p><p><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/%E7%94%B5%E5%BD%B1%E4%B8%BE%E4%BE%8B2.png" alt="Alt text"></p><p>假设我们已经计算出了各电影与 “？号电影” 的距离，如下表所示（示例数据）：<br><img src="https://cdn.jsdelivr.net/gh/enju-tsubaki/image/机器学习/knn/%E7%94%B5%E5%BD%B1%E4%B8%BE%E4%BE%8B3.png" alt="Alt text"></p><h3 id="🐼分类过程🐠"><a href="#🐼分类过程🐠" class="headerlink" title="🐼分类过程🐠"></a>🐼分类过程🐠</h3><p>当 (K = 5) 时，从表格中可知距离《唐人街探案》最近的 5 部电影分别是《功夫熊猫》《美人鱼》《宝贝当家》《新步步惊心》《代理情人》。</p><ul><li>这 5 部电影中：</li><li>《功夫熊猫》《美人鱼》《宝贝当家》是喜剧片；</li><li>《新步步惊心》和《代理情人》是爱情片。</li></ul><p>喜剧片的数量为 3，爱情片的数量为 2。  根据 KNN 算法中多数表决的原则，在这 5 个最近邻中，喜剧片的数量占多数。</p><h3 id="🎬结论"><a href="#🎬结论" class="headerlink" title="🎬结论"></a>🎬结论</h3><p>通过 KNN 分析，预测《唐人街探案》的电影类型为喜剧片。因为在距离它最近的 5 部电影中，喜剧片的数量多于其他类型的电影数量。</p><h3 id="📈1-3-KNN-算法流程总结"><a href="#📈1-3-KNN-算法流程总结" class="headerlink" title="📈1.3 KNN 算法流程总结"></a>📈1.3 KNN 算法流程总结</h3><ol><li><strong>计算已知类别数据集中的点与当前点之间的距离</strong>：利用距离公式（如欧氏距离），计算每个已知样本点与待预测点的距离。</li><li><strong>按距离递增次序排序</strong>：将计算得到的距离从小到大进行排序。</li><li><strong>选取与当前点距离最小的 k 个点</strong>：从排序后的距离列表中，选取前 k 个最小距离对应的样本点。</li><li><strong>统计前 k 个点所在的类别出现的频率</strong>：查看这 k 个点分别属于哪些类别，并统计每个类别出现的次数。</li><li><strong>返回前 k 个点出现频率最高的类别作为当前点的预测分类</strong>：如果这 k 个点中属于动作片类别的点最多，那么就预测待预测电影为动作片。</li></ol><h2 id="🌈2-小结"><a href="#🌈2-小结" class="headerlink" title="🌈2 小结"></a>🌈2 小结</h2><ul><li><strong>K - 近邻算法简介【了解】</strong>：就是通过你的 “邻居” 来判断你属于哪个类别。</li><li><strong>如何计算你到你的 “邻居” 的距离</strong>：一般时候，都是使用欧氏距离。欧氏距离能够直观地衡量两个样本在特征空间中的距离远近，帮助我们找到最邻近的样本。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KNN </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title></title>
      <link href="/manifest.json"/>
      <url>/manifest.json</url>
      
        <content type="html"><![CDATA[{"name":"Coisini","short_name":"Coisini","theme_color":"#3b70fc","background_color":"#3b70fc","display":"standalone","scope":"/","start_url":"/","icons":[{"src":"/img/siteicon/16.png","sizes":"16x16","type":"image/png"},{"src":"/img/siteicon/32.png","sizes":"32x32","type":"image/png"},{"src":"/img/siteicon/48.png","sizes":"48x48","type":"image/png"},{"src":"/img/siteicon/64.png","sizes":"64x64","type":"image/png"},{"src":"/img/siteicon/128.png","sizes":"128x128","type":"image/png"},{"src":"/img/siteicon/144.png","sizes":"144x144","type":"image/png"},{"src":"/img/siteicon/512.png","sizes":"512x512","type":"image/png"}],"splash_pages":null}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>分类</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/css/custom.css"/>
      <url>/css/custom.css</url>
      
        <content type="html"><![CDATA[@font-face {  font-family: iconfont;  src: url('/fonts/iconfont.woff2') format('woff2');  font-display: swap;  font-weight: lighter;}div#menus {  font-family: "iconfont";}h1#site-title {  font-family: iconfont;  font-size: 3em !important;}a.article-title,a.blog-slider__title,a.categoryBar-list-link,h1.post-title {  font-family: iconfont;}.iconfont {  font-family: "iconfont" !important;  font-size: 3em;  /* 可以定义图标大小 */  font-style: normal;  -webkit-font-smoothing: antialiased;  -moz-osx-font-smoothing: grayscale;}.icon-fenleiorguangchangorqitatianchong:before {  content: "\e67d";}.icon-pengyouquan:before {  content: "\e669";}.icon-yinle:before {  content: "\e60a";}.icon-zhuye-copy:before {  content: "\e608";}.icon-liuyanban:before {  content: "\e703";}.icon-rss:before {  content: "\e600";}.icon-icon-checked:before {  content: "\e601";}.icon-zhifeiji:before {  content: "\e6f3";}.icon-bilibili:before {  content: "\e602";}.icon-liaotian:before {  content: "\e759";}.icon-lianjie:before {  content: "\e612";}.icon-QQ:before {  content: "\e641";}.icon-github:before {  content: "\e722";}.icon-bilibili1:before {  content: "\eb78";}.icon-youxiangyoujian:before {  content: "\e607";}.icon-shichen-shen:before {  content: "\e64a";}.icon-shichen-wei:before {  content: "\e64b";}.icon-shichen-si:before {  content: "\e64c";}.icon-shichen-wu:before {  content: "\e64d";}.icon-shichen-yin:before {  content: "\e64e";}.icon-shichen-zi:before {  content: "\e64f";}.icon-shichen-you:before {  content: "\e650";}.icon-shichen-xu:before {  content: "\e651";}.icon-shichen-chen:before {  content: "\e652";}.icon-shichen-hai:before {  content: "\e653";}.icon-shichen-chou:before {  content: "\e654";}.icon-shichen-mao:before {  content: "\e655";}.icon-shengxiaoniu:before {  content: "\e603";}.icon-shengxiaohou:before {  content: "\e685";}.icon-shengxiaohu:before {  content: "\e686";}.icon-shengxiaoshe:before {  content: "\e687";}.icon-shengxiaotu:before {  content: "\e688";}.icon-shengxiaolong:before {  content: "\e689";}.icon-shengxiaoshu:before {  content: "\e68a";}.icon-shengxiaoma:before {  content: "\e70e";}.icon-shengxiaogou:before {  content: "\e70f";}.icon-shengxiaozhu:before {  content: "\e710";}.icon-shengxiaoyang:before {  content: "\e711";}.icon-shengxiaoji:before {  content: "\e712";}/* 时间轴生肖icon */svg.icon {  /* 这里定义svg.icon，避免和Butterfly自带的note标签冲突 */  width: 1em;  height: 1em;  /* width和height定义图标的默认宽度和高度*/  vertical-align: -0.15em;  fill: currentColor;  overflow: hidden;}.icon-zhongbiao::before {  color: #f7c768;}/* bilibli番剧插件 */#article-container .bangumi-tab.bangumi-active {  background: var(--anzhiyu-theme);  color: var(--anzhiyu-ahoverbg);  border-radius: 10px;}a.bangumi-tab:hover {  text-decoration: none !important;}.bangumi-button:hover {  background: var(--anzhiyu-theme) !important;  border-radius: 10px !important;  color: var(--anzhiyu-ahoverbg) !important;}a.bangumi-button.bangumi-nextpage:hover {  text-decoration: none !important;}.bangumi-button {  padding: 5px 10px !important;}a.bangumi-tab {  padding: 5px 10px !important;}svg.icon.faa-tada {  font-size: 1.1em;}.bangumi-info-item {  border-right: 1px solid #f2b94b;}.bangumi-info-item span {  color: #f2b94b;}.bangumi-info-item em {  color: #f2b94b;}/* 解决artitalk的图标问题 */#uploadSource>svg {  width: 1.19em;  height: 1.5em;}/*top-img黑色透明玻璃效果移除，不建议加，除非你执着于完全一图流或者背景图对比色明显 */#page-header:not(.not-top-img):before {  background-color: transparent !important;}/* 首页文章卡片 */#recent-posts>.recent-post-item {  background: rgba(255, 255, 255, 0.9);}/* 首页侧栏卡片 */#aside-content .card-widget {  background: rgba(255, 255, 255, 0.9);}/* 文章页面正文背景 */div#post {  background: rgba(255, 255, 255, 0.9);}/* 分页页面 */div#page {  background: rgba(255, 255, 255, 0.9);}/* 归档页面 */div#archive {  background: rgba(255, 255, 255, 0.9);}/* 标签页面 */div#tag {  background: rgba(255, 255, 255, 0.9);}/* 分类页面 */div#category {  background: rgba(255, 255, 255, 0.9);}/*夜间模式伪类遮罩层透明*/[data-theme="dark"] #recent-posts>.recent-post-item {  background: #121212;}[data-theme="dark"] .card-widget {  background: #121212 !important;}[data-theme="dark"] div#post {  background: #121212 !important;}[data-theme="dark"] div#tag {  background: #121212 !important;}[data-theme="dark"] div#archive {  background: #121212 !important;}[data-theme="dark"] div#page {  background: #121212 !important;}[data-theme="dark"] div#category {  background: #121212 !important;}[data-theme="dark"] div#category {  background: transparent !important;}/* 页脚透明 */#footer {  background: transparent !important;}/* 头图透明 */#page-header {  background: transparent !important;}#rightside>div>button {  border-radius: 5px;}/* 滚动条 */::-webkit-scrollbar {  width: 10px;  height: 10px;}::-webkit-scrollbar-thumb {  background-color: #3b70fc;  border-radius: 2em;}::-webkit-scrollbar-corner {  background-color: transparent;}::-moz-selection {  color: #fff;  background-color: #3b70fc;}/* 音乐播放器 *//* .aplayer .aplayer-lrc {  display: none !important;} */.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {  left: -66px !important;  transition: all 0.3s;  /* 默认情况下缩进左侧66px，只留一点箭头部分 */}.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {  left: 0 !important;  transition: all 0.3s;  /* 鼠标悬停是左侧缩进归零，完全显示按钮 */}.aplayer.aplayer-fixed {  z-index: 999999 !important;}/* 评论框  */.vwrap {  box-shadow: 2px 2px 5px #bbb;  background: rgba(255, 255, 255, 0.3);  border-radius: 8px;  padding: 30px;  margin: 30px 0px 30px 0px;}/* 设置评论框 */.vcard {  box-shadow: 2px 2px 5px #bbb;  background: rgba(255, 255, 255, 0.3);  border-radius: 8px;  padding: 30px;  margin: 30px 0px 0px 0px;}/* md网站下划线 */#article-container a:hover {  text-decoration: none !important;}#article-container #hpp_talk p img {  display: inline;}/* 404页面 */#error-wrap {  position: absolute;  top: 40%;  right: 0;  left: 0;  margin: 0 auto;  padding: 0 1rem;  max-width: 1000px;  transform: translate(0, -50%);}#error-wrap .error-content {  display: flex;  flex-direction: row;  justify-content: center;  align-items: center;  margin: 0 1rem;  height: 18rem;  border-radius: 8px;  background: var(--card-bg);  box-shadow: var(--card-box-shadow);  transition: all 0.3s;}#error-wrap .error-content .error-img {  box-flex: 1;  flex: 1;  height: 100%;  border-top-left-radius: 8px;  border-bottom-left-radius: 8px;  background-color: #3b70fc;  background-position: center;  background-size: cover;}#error-wrap .error-content .error-info {  box-flex: 1;  flex: 1;  padding: 0.5rem;  text-align: center;  font-size: 14px;  font-family: Titillium Web, "PingFang SC", "Hiragino Sans GB", "Microsoft JhengHei", "Microsoft YaHei", sans-serif;}#error-wrap .error-content .error-info .error_title {  margin-top: -4rem;  font-size: 9em;}#error-wrap .error-content .error-info .error_subtitle {  margin-top: -3.5rem;  word-break: break-word;  font-size: 1.6em;}#error-wrap .error-content .error-info a {  display: inline-block;  margin-top: 0.5rem;  padding: 0.3rem 1.5rem;  background: var(--btn-bg);  color: var(--btn-color);}#body-wrap.error .aside-list {  display: flex;  flex-direction: row;  flex-wrap: nowrap;  bottom: 0px;  position: absolute;  padding: 1rem;  width: 100%;  overflow: scroll;}#body-wrap.error .aside-list .aside-list-group {  display: flex;  flex-direction: row;  flex-wrap: nowrap;  max-width: 1200px;  margin: 0 auto;}#body-wrap.error .aside-list .aside-list-item {  padding: 0.5rem;}#body-wrap.error .aside-list .aside-list-item img {  width: 100%;  object-fit: cover;  border-radius: 12px;}#body-wrap.error .aside-list .aside-list-item .thumbnail {  overflow: hidden;  width: 230px;  height: 143px;  background: var(--anzhiyu-card-bg);  display: flex;}#body-wrap.error .aside-list .aside-list-item .content .title {  -webkit-line-clamp: 2;  overflow: hidden;  display: -webkit-box;  -webkit-box-orient: vertical;  line-height: 1.5;  justify-content: center;  align-items: flex-end;  align-content: center;  padding-top: 0.5rem;  color: white;}#body-wrap.error .aside-list .aside-list-item .content time {  display: none;}/* 代码框主题 */#article-container figure.highlight {  border-radius: 10px;}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/js/ali_font.js"/>
      <url>/js/ali_font.js</url>
      
        <content type="html"><![CDATA[window._iconfont_svg_string_4604429='<svg><symbol id="icon-fenleiorguangchangorqitatianchong" viewBox="0 0 1024 1024"><path d="M886.951936 438.203392c-63.514624 63.514624-166.499328 63.514624-230.013952 0l-63.895552-63.900672c-63.519744-63.514624-63.519744-166.494208 0-230.013952l63.895552-63.895552c63.515648-63.514624 166.499328-63.514624 230.013952 0l63.895552 63.895552c63.519744 63.519744 63.519744 166.499328 0 230.013952L886.951936 438.203392z" fill="#FF9000" ></path><path d="M444.669952 304.477184c0 89.827328-72.81664 162.644992-162.644992 162.644992l-90.361856 0c-89.827328 0-162.644992-72.81664-162.644992-162.644992l0-90.361856c0-89.827328 72.81664-162.644992 162.644992-162.644992l90.361856 0c89.827328 0 162.644992 72.81664 162.644992 162.644992L444.669952 304.477184z" fill="#FF9000" ></path><path d="M979.771392 828.194816c0 89.822208-72.81664 162.644992-162.644992 162.644992l-90.361856 0c-89.827328 0-162.644992-72.82176-162.644992-162.644992l0-90.366976c0-89.822208 72.81664-162.644992 162.644992-162.644992l90.361856 0c89.827328 0 162.644992 72.82176 162.644992 162.644992L979.771392 828.194816z" fill="#FF9000" ></path><path d="M444.669952 828.194816c0 89.822208-72.81664 162.644992-162.644992 162.644992l-90.361856 0c-89.827328 0-162.644992-72.82176-162.644992-162.644992l0-90.366976c0-89.822208 72.81664-162.644992 162.644992-162.644992l90.361856 0c89.827328 0 162.644992 72.82176 162.644992 162.644992L444.669952 828.194816z" fill="#FF9000" ></path></symbol><symbol id="icon-pengyouquan" viewBox="0 0 1024 1024"><path d="M689.995294 69.993412A479.051294 479.051294 0 0 0 498.447059 30.117647a484.894118 484.894118 0 0 0-133.722353 18.974118l316.958118 389.24047 8.31247-368.338823z m-368.820706-6.02353a478.027294 478.027294 0 0 0-163.478588 107.218824A484.713412 484.713412 0 0 0 76.498824 279.250824l499.410823 51.2L321.174588 63.849412zM56.380235 320.451765a480.798118 480.798118 0 0 0-20.901647 325.270588L424.658824 328.704 56.380235 320.451765z m-6.023529 368.64a478.870588 478.870588 0 0 0 215.280941 244.736l51.2-499.410824L50.236235 689.091765z m256.421647 264.854588a479.171765 479.171765 0 0 0 325.391059 20.841412L315.151059 585.487059l-8.432941 368.459294z m368.760471 5.963294a479.472941 479.472941 0 0 0 244.736-215.341176l-499.471059-51.019295 254.795294 266.360471z m285.635764-581.752471l-389.24047 317.018353 368.459294 8.252236a479.171765 479.171765 0 0 0 20.781176-325.270589z m-14.757647-43.369411a480.496941 480.496941 0 0 0-215.280941-244.736l-51.2 499.410823 266.480941-254.674823z" fill="#FF4E5F" ></path></symbol><symbol id="icon-yinle" viewBox="0 0 1024 1024"><path d="M512.34 511.24m-443.09 0a443.09 443.09 0 1 0 886.18 0 443.09 443.09 0 1 0-886.18 0Z" fill="#F7B52C" ></path><path d="M424.39 626.87m-147.53 0a147.53 147.53 0 1 0 295.06 0 147.53 147.53 0 1 0-295.06 0Z" fill="#FFFFFF" ></path><path d="M675.94 429.77l-120.18 263.8-137.89-62.82 167.07-366.72z" fill="#FFFFFF" ></path><path d="M762.71 511.52L522.62 402.14l62.82-137.88z" fill="#FFFFFF" ></path></symbol><symbol id="icon-zhuye-copy" viewBox="0 0 1024 1024"><path d="M847.9 416.1c-1.6-1.7-3-3.4-4.7-4.9l-4.1-3.3v1l8.8 7.2zM269.7 729.7c1.3-0.6 2.4-1.4 3.7-2-1.1 0.5-2.1 1.2-3.2 1.7V601.7l-90.8-33.1c-2-1.7-3.7-3.7-5.4-5.6v86.2c1.1-0.5 2.1-1.2 3.2-1.7-1.3 0.6-2.4 1.4-3.7 2v84.6c0 57.1 38.9 92.8 96.9 93-0.5-4.2-0.8-8.5-0.8-12.9v-84.5zM179.4 483.9l180.2-145.2 149.8-120.9c27-24.5 68.2-24.5 95.2 0l132.2 107.8v-39.2c0.6-7.4 2.8-14.2 6.2-20.3v-59.9c-2.1-26.7-24.4-47.2-51.2-47.2-26.7 0-49 20.5-51.1 47.2v39.2L508.4 137.7c-27-24.5-68.2-24.5-95.2 0L263.5 258.6 83.3 403.7c-12.6 10.5-19.9 26-19.9 42.4s7.3 32 19.9 42.4l77.3 28.2c2.2-12.8 8.7-24.5 18.8-32.8z" fill="#44D9E6" ></path><path d="M607.9 657c-16.4-0.2-32.7 2.4-48.3 7.5-14.1 4.7-27.4 11.6-39.3 20.4-12.9 9.9-24.9 20.9-35.7 33.1-1.8 1.8-2.8 4.3-2.9 6.8 0.1 5.3 4.4 9.6 9.7 9.7 2.6-0.1 5-1.1 6.8-2.9 2.7-2.4 6.4-6.1 11-11l10.1-10c11.9-11.2 25.7-20.3 40.8-26.7 15.2-5.6 31.4-8.3 47.6-7.9 5.3-0.1 9.6-4.4 9.7-9.7-0.1-2.4-1-4.7-2.8-6.4-1.7-1.9-4.1-2.9-6.7-2.9z" fill="#5271FF" ></path><path d="M939.3 491.3l-91.4-75.2-8.8-7.3v-1c0.2-2.3 0.2-4.6 0-6.8V286.5c-2.1-26.7-24.4-47.2-51.2-47.2-19.4 0-36.3 10.9-45 26.9-3.3 6.1-5.6 12.9-6.2 20.3v39.2L604.6 217.8c-27-24.5-68.2-24.5-95.2 0L359.7 338.7c36.3 45.3 56.1 101.6 56 159.7 0 59.4-20.6 115.5-56.4 160.2-0.1 0.1-0.2 0.2-0.2 0.3-5.8 7.2-12 14.1-18.5 20.7l-1.3 1.3c-6 5.9-12.4 11.6-19 16.9l-2.1 1.8c-6.4 5.1-13.2 9.8-20.1 14.3l-6.3 3.9c-5.9 3.6-12 6.9-18.2 10-1.3 0.6-2.4 1.4-3.7 2v84.6c0 4.5 0.3 8.7 0.8 12.9 5.5 49.7 42.9 80.2 96.7 80.2h378.5c52.7 0 96-27.4 97.5-93.1V610.6l96.1-34.4c12.7-10.5 20-26 20-42.5-0.2-16.3-7.5-31.9-20.2-42.4zM695.2 636.7c0 9.8-1.1 19.7-3.1 29.3-4.1 21.5-13.7 41.5-28 58.1-15.2 17-33.7 30.8-54.3 40.6-20.4 10.6-43.1 16.2-66.1 16.4-15 0.1-29.9-2.3-44.1-7.2-1.5-0.5-6-2.6-13.3-6.4-4.5-2.7-9.4-4.6-14.6-5.6-1.6 0-3.6 1.6-5.9 4.8-2.5 3.5-4.8 7.2-6.8 11-2.1 4-4.8 7.7-7.9 11-2.3 2.8-5.6 4.5-9.2 4.9-2.7 0.1-5.3-0.5-7.7-1.7-1.8-0.9-3.4-2.1-4.7-3.6-1.5-2-2.8-4.2-4.1-6.4l-0.9-1.7-0.4-2.4v-1.4c-0.1-0.7-0.1-1.4 0-2.1 0.3-4.1 2-8 4.7-11 3-3.7 6.5-7.1 10.4-9.9 3.6-2.6 7.1-5.5 10.3-8.5 3.2-2.9 4.7-5.4 4.7-7.3-0.5-2-1.3-3.9-2.1-5.7-1-2.2-1.8-4.4-2.4-6.7-0.9-5.2-1.3-10.5-1.3-15.8 0-11.3 2.3-22.6 6.6-33 4.2-10.4 10.4-19.8 18.1-28 7.7-8.1 16.4-15.1 25.9-21 9.4-6.1 19.4-11 30-14.8 7.2-2.1 14.6-3.4 22-3.9 9.1-0.7 18.2-1.2 27.2-1.3 9-0.1 18.1-0.4 27.1-0.9 8.4-0.4 16.7-1.6 24.8-3.6 6.4-1.4 12.3-4.3 17.2-8.6l4.5-4.5 4.5-4.3c3-2.9 4.4-3.9 4.1-3.1-0.3 0.8 1.5 0 5.5-2.4s6.2-2.6 6.6-0.7c4.6 0.2 8.8 2.9 11 6.9 3.4 5.2 5.8 10.9 7.2 17 1.6 6.7 2.8 13 3.6 18.8 0.7 4.8 1.1 9.7 1.2 14.5h-0.3z" fill="#5271FF" ></path><path d="M270.2 601.7v127.7c1.1-0.5 2.1-1.2 3.2-1.7 6.2-3.1 12.3-6.5 18.2-10l6.3-3.9c7-4.5 13.7-9.2 20.1-14.3l2.1-1.8c6.6-5.3 13-11 19-16.9l1.3-1.3c6.6-6.6 12.7-13.5 18.5-20.7 0.1-0.1 0.2-0.2 0.2-0.3 35.8-44.6 56.4-100.8 56.4-160.2 0-58.1-19.7-114.4-56-159.7L179.4 483.9c-10.1 8.4-16.6 20.1-18.9 32.8-0.6 3.1-1.1 6.3-1.1 9.6 0 13.8 5.4 26.8 14.5 36.8 1.7 1.9 3.4 3.9 5.4 5.6l90.9 33z" fill="#5271FF" ></path></symbol><symbol id="icon-liuyanban" viewBox="0 0 1024 1024"><path d="M853.333333 307.2h-170.666666l-126.293334-126.293333c3.413333-6.826667 6.826667-17.066667 6.826667-27.306667 0-27.306667-23.893333-51.2-51.2-51.2s-51.2 23.893333-51.2 51.2c0 10.24 3.413333 17.066667 6.826667 27.306667L341.333333 307.2H170.666667c-37.546667 0-68.266667 30.72-68.266667 68.266667v477.866666c0 37.546667 30.72 68.266667 68.266667 68.266667h682.666666c37.546667 0 68.266667-30.72 68.266667-68.266667V375.466667c0-37.546667-30.72-68.266667-68.266667-68.266667zM494.933333 201.386667c6.826667 3.413333 10.24 3.413333 17.066667 3.413333s10.24 0 17.066667-3.413333L634.88 307.2h-245.76l105.813333-105.813333zM204.8 477.866667h375.466667v34.133333H204.8v-34.133333z m491.52 17.066666l51.2 51.2-150.186667 150.186667H546.133333v-51.2l150.186667-150.186667zM204.8 624.64h238.933333v34.133333H204.8v-34.133333z m590.506667 184.32H204.8v-34.133333h590.506667v34.133333z m-3.413334-303.786667l-27.306666 27.306667-54.613334-54.613333 27.306667-27.306667c6.826667-6.826667 13.653333-6.826667 20.48 0l34.133333 34.133333c6.826667 3.413333 6.826667 13.653333 0 20.48z" fill="#FF6B00" ></path></symbol><symbol id="icon-rss" viewBox="0 0 1024 1024"><path d="M544.059897 959.266898h-64.949141c-228.633593 0-415.697442-187.063849-415.697442-415.697442v-64.949141c0-228.633593 187.063849-415.697442 415.697442-415.697442h64.949141c228.633593 0 415.697442 187.063849 415.697442 415.697442v64.949141C959.756315 772.203049 772.692466 959.266898 544.059897 959.266898z" fill="#FD9B00" ></path><path d="M638.254276 718.937463c0-186.152591-151.296463-337.64564-337.178748-337.64564v-80.094453c230.17966 0 417.439071 187.459069 417.43907 417.739069H638.254276zM576.586686 718.937463h-80.368854c0-52.377878-20.342554-101.550994-57.208569-138.422129-36.882397-36.960212-85.890668-57.311981-138.048411-57.311981v-80.070904C452.934103 443.132449 576.586686 566.766602 576.586686 718.937463zM356.501512 607.516214c30.775945 0 55.629737 25.013518 55.629737 55.528373 0 30.607004-24.853792 55.351241-55.629737 55.351241-30.667413 0-55.583663-24.743213-55.583663-55.351241C300.917849 632.529733 325.834099 607.516214 356.501512 607.516214z" fill="#FFFFFF" ></path></symbol><symbol id="icon-icon-checked" viewBox="0 0 1024 1024"><path d="M512 512m-229.517241 0a229.517241 229.517241 0 1 0 459.034482 0 229.517241 229.517241 0 1 0-459.034482 0Z" fill="#1296db" ></path><path d="M512 1024A512 512 0 1 1 1024 512 512 512 0 0 1 512 1024z m0-141.241379A370.758621 370.758621 0 1 0 141.241379 512 370.758621 370.758621 0 0 0 512 882.758621z" fill="#1296db" ></path></symbol><symbol id="icon-zhifeiji" viewBox="0 0 1024 1024"><path d="M512 1024C230.4 1024 0 793.6 0 512S230.4 0 512 0s512 230.4 512 512-230.4 512-512 512z" fill="#5BC1ED" ></path><path d="M865.456 219.048L400.832 455.56l-41.184 20.232 131.784 89.032 16.536 121.408L760.52 959.096C917.336 871.32 1024 703.552 1024 512c0-39.712-4.728-78.344-13.392-115.512l-145.152-177.44z" fill="#2399BC" ></path><path d="M862.672 219.584L355.864 477.232l131.032 84.536 16.304 119.864 106.072-53.296 81.512 39.704z" fill="#5BC1ED" ></path><path d="M503.2 688.48a6.92 6.92 0 0 1-3.192-0.784 6.856 6.856 0 0 1-3.592-5.128l-15.88-116.744-128.376-82.832a6.858 6.858 0 0 1-3.128-6.104 6.84 6.84 0 0 1 3.736-5.752l506.8-257.656a6.856 6.856 0 1 1 9.504 8.56l-171.896 448.448a6.832 6.832 0 0 1-3.88 3.92 6.788 6.788 0 0 1-5.512-0.208l-78.464-38.232-103.04 51.784a6.86 6.86 0 0 1-3.08 0.728m-133.608-210.544l121.016 78.072a6.86 6.86 0 0 1 3.072 4.832l15.008 110.368 97.504-49a6.838 6.838 0 0 1 6.072-0.04l74.8 36.44 162.848-424.864-480.32 244.192z" fill="#474341" ></path><path d="M552.416 595.024l-33.008 70.848 84.536-37.04v-6.44l-48.312-28.176z" fill="#0C8BAE" ></path><path d="M488.008 556.376L828.56 256.88 553.224 587.776 505.72 681.16z" fill="#0C8BAE" ></path><path d="M505.72 686a4.84 4.84 0 0 1-4.784-4.152l-17.712-124.784a4.814 4.814 0 0 1 1.6-4.304l340.552-299.496a4.84 4.84 0 0 1 6.56 0.16c1.8 1.76 1.952 4.616 0.344 6.552l-275 330.472-47.256 92.904A4.812 4.812 0 0 1 505.72 686m-12.56-127.712l15.192 107.048 40.56-79.744c0.16-0.32 0.36-0.616 0.592-0.904l235.672-283.216L493.16 558.288z" fill="#474341" ></path><path d="M864.128 219.808c-2.056-0.448-4.264-0.056-5.968 1.432L482.376 551.344a6.83 6.83 0 0 0-0.616 9.656 6.84 6.84 0 0 0 9.656 0.624l304.92-267.864-250.04 293.832c-0.36 0.432-0.672 0.896-0.92 1.392l-41.056 82.808a6.85 6.85 0 0 0 6.128 9.896c2.52 0 4.944-1.4 6.136-3.808l40.688-82.04L862.96 236.624c-1.376-5.56-0.992-11.56 1.168-16.816" fill="#474341" ></path><path d="M609.264 635.184c-1.24 0-2.504-0.344-3.64-1.056l-57.768-36.296a6.846 6.846 0 0 1-2.152-9.44c2.016-3.2 6.24-4.184 9.44-2.152l57.768 36.296a6.846 6.846 0 0 1 2.152 9.44 6.824 6.824 0 0 1-5.8 3.208M176.344 616.504a6.848 6.848 0 0 1-6.784-7.832c0.68-4.68 1.544-9.336 2.576-13.928a6.856 6.856 0 0 1 8.176-5.184 6.848 6.848 0 0 1 5.184 8.176 179.746 179.746 0 0 0-2.392 12.912 6.844 6.844 0 0 1-6.76 5.856M389.968 826.016c-4.608 0-9.368-0.336-14.136-1.008a6.846 6.846 0 0 1-5.816-7.736c0.52-3.752 4-6.376 7.736-5.824 8.688 1.232 17.136 1.184 25.04-0.184 3.712-0.616 7.272 1.864 7.904 5.592a6.844 6.844 0 0 1-5.592 7.904 90.72 90.72 0 0 1-15.136 1.256m-36.664-7.736c-0.976 0-1.968-0.208-2.904-0.648a77.264 77.264 0 0 1-24-17.52 6.842 6.842 0 0 1 0.376-9.672 6.828 6.828 0 0 1 9.672 0.376 63.726 63.726 0 0 0 19.776 14.424 6.856 6.856 0 0 1 3.288 9.112 6.88 6.88 0 0 1-6.208 3.928m73.776-1.28a6.834 6.834 0 0 1-6.056-3.656 6.84 6.84 0 0 1 2.856-9.248c7.12-3.76 13.824-8.856 19.904-15.12a6.848 6.848 0 0 1 9.832 9.528c-7.088 7.304-14.936 13.256-23.336 17.696a6.8 6.8 0 0 1-3.2 0.8m-108.984-35.168c-2.64 0-5.16-1.536-6.28-4.112a81.546 81.546 0 0 1-1.24-3 90.602 90.602 0 0 1-16.376 4.424c-3.672 0.672-7.264-1.848-7.904-5.584a6.828 6.828 0 0 1 5.584-7.904 77.808 77.808 0 0 0 14.712-4.064 91.232 91.232 0 0 1-1.864-12.392 6.842 6.842 0 0 1 6.256-7.392c3.704-0.4 7.072 2.488 7.384 6.256 0.248 2.944 0.648 5.84 1.208 8.68a6.848 6.848 0 0 1 3.432 12.128c0.432 1.144 0.888 2.256 1.368 3.368a6.852 6.852 0 0 1-6.28 9.592m145.544-0.656a6.84 6.84 0 0 1-5.824-10.432c4.344-7.056 8.176-14.896 11.392-23.32a6.836 6.836 0 0 1 8.84-3.96 6.844 6.844 0 0 1 3.96 8.832c-3.52 9.232-7.736 17.848-12.528 25.624a6.862 6.862 0 0 1-5.84 3.256m-195.04-1.392c-0.288 0-0.584-0.008-0.872-0.048-9.68-1.232-19.152-4.032-28.136-8.304-3.416-1.632-4.864-5.72-3.232-9.128s5.72-4.856 9.128-3.232a78.752 78.752 0 0 0 23.976 7.08 6.86 6.86 0 0 1 5.928 7.656 6.868 6.868 0 0 1-6.792 5.976m-46.576-21.072a6.768 6.768 0 0 1-4.432-1.64 110.916 110.916 0 0 1-11.904-11.848 141.414 141.414 0 0 1-7.504-9.456 6.844 6.844 0 1 1 11.072-8.048 125.394 125.394 0 0 0 6.784 8.536 97.766 97.766 0 0 0 10.44 10.4 6.844 6.844 0 0 1 0.768 9.648c-1.36 1.6-3.28 2.408-5.224 2.408m116.52-2.656a6.842 6.842 0 0 1-4.688-11.832c4.576-4.304 8.832-9.224 12.656-14.616a101.734 101.734 0 0 0 3.368-5.12c2-3.216 6.232-4.2 9.424-2.208a6.836 6.836 0 0 1 2.208 9.424 117.08 117.08 0 0 1-3.824 5.816c-4.36 6.136-9.216 11.744-14.448 16.672a6.808 6.808 0 0 1-4.696 1.864m-25.736-25.016c-0.416 0-0.84-0.04-1.256-0.12a6.844 6.844 0 0 1-5.48-7.984c0.84-4.488 1.976-8.968 3.392-13.304 1.312-4.032 3.448-9.208 5.856-14.2a6.84 6.84 0 0 1 9.144-3.192 6.848 6.848 0 0 1 3.184 9.144c-2.152 4.472-4.048 9.016-5.168 12.488a89.992 89.992 0 0 0-2.944 11.584 6.848 6.848 0 0 1-6.728 5.584m-121.736-13.448c-2.528 0-4.96-1.4-6.152-3.816a163.798 163.798 0 0 1-10.264-26.512 6.838 6.838 0 0 1 4.656-8.488 6.864 6.864 0 0 1 8.488 4.656 150.086 150.086 0 0 0 9.408 24.288 6.846 6.846 0 0 1-6.136 9.872m175.808-4.504a6.844 6.844 0 0 1-6.344-9.416c3.304-8.176 5.056-15.408 5.056-20.92 0-0.792-0.04-1.568-0.112-2.32a6.838 6.838 0 0 1 6.12-7.496c3.672-0.376 7.12 2.36 7.496 6.12 0.128 1.2 0.176 2.44 0.176 3.696 0.008 7.352-2.024 16.128-6.048 26.056a6.84 6.84 0 0 1-6.344 4.28m-32.584-28.76c-1.496 0-3-0.488-4.264-1.496a6.834 6.834 0 0 1-1.08-9.616c8.704-10.912 17.728-16.44 26.832-16.44 0.112 0 1.08 0.024 1.192 0.024 3.776 0.192 6.688 3.4 6.496 7.176s-3.384 6.808-7.176 6.504l0.336-6.84-0.856 6.816c-4.592 0-10.328 4.016-16.136 11.288a6.784 6.784 0 0 1-5.344 2.584M176.088 668.2a6.844 6.844 0 0 1-6.768-5.904 187.042 187.042 0 0 1-1.784-25.88l0.008-2.352c0.048-3.776 3.216-6.504 6.936-6.768a6.846 6.846 0 0 1 6.76 6.936l-0.016 2.184c0 8.048 0.56 16.112 1.656 23.984a6.84 6.84 0 0 1-5.832 7.728c-0.32 0.056-0.64 0.072-0.96 0.072M482.816 732.68a6.844 6.844 0 0 1-6.68-8.352c0.968-4.304 1.768-8.64 2.408-12.968 0.552-3.736 4.096-6.272 7.776-5.768a6.84 6.84 0 0 1 5.768 7.776 192.612 192.612 0 0 1-2.592 13.96 6.874 6.874 0 0 1-6.68 5.352M521.016 527.52a3336.128 3336.128 0 0 0 6.952 96.648c0.536 6.144 10.2 6.2 9.664 0a3336.128 3336.128 0 0 1-6.952-96.648c-0.36-6.176-10.016-6.224-9.664 0M551.28 498.544l7.208 74.88c0.584 6.136 10.256 6.192 9.656 0l-7.2-74.88c-0.592-6.136-10.264-6.2-9.664 0M579.816 476.992c3.152 20.48 6.296 40.96 9.448 61.432 0.936 6.128 10.248 3.52 9.32-2.568-3.152-20.48-6.296-40.96-9.448-61.432-0.944-6.128-10.256-3.528-9.32 2.568M609.424 450.216l5.688 56.792c0.616 6.128 10.28 6.192 9.656 0a136410.24 136410.24 0 0 1-5.68-56.792c-0.616-6.128-10.28-6.184-9.664 0M642.8 423.704c1.832 14.864 3.656 29.736 5.488 44.6 0.752 6.088 10.416 6.168 9.656 0-1.832-14.864-3.656-29.736-5.48-44.6-0.76-6.088-10.424-6.168-9.664 0M677.04 391.048l4.816 41.056c0.72 6.104 10.384 6.176 9.664 0l-4.816-41.056c-0.72-6.104-10.384-6.176-9.664 0M708.784 364.44c1.168 9.664 2.336 19.336 3.496 29 0.736 6.096 10.408 6.176 9.664 0-1.168-9.664-2.336-19.336-3.496-29-0.736-6.096-10.4-6.168-9.664 0M745.944 330.656c-0.648 8.472 0.952 16.392 4.32 24.16 2.464 5.688 10.792 0.768 8.336-4.872-2.672-6.16-3.504-12.624-2.992-19.288 0.464-6.2-9.2-6.168-9.664 0M692.928 572.744c-5.176 12.416-10.368 24.84-15.544 37.256-2.392 5.736 6.952 8.232 9.32 2.568l15.544-37.256c2.384-5.736-6.96-8.232-9.32-2.568M734.376 473.4l-31.088 74.512c-2.392 5.736 6.952 8.232 9.32 2.568 10.36-24.84 20.72-49.672 31.088-74.512 2.384-5.736-6.96-8.232-9.32-2.568" fill="#474341" ></path></symbol><symbol id="icon-bilibili" viewBox="0 0 1129 1024"><path d="M234.909 9.656a80.468 80.468 0 0 1 68.398 0 167.374 167.374 0 0 1 41.843 30.578l160.937 140.82h115.07l160.936-140.82a168.983 168.983 0 0 1 41.843-30.578A80.468 80.468 0 0 1 930.96 76.445a80.468 80.468 0 0 1-17.703 53.914 449.818 449.818 0 0 1-35.406 32.187 232.553 232.553 0 0 1-22.531 18.508h100.585a170.593 170.593 0 0 1 118.289 53.109 171.397 171.397 0 0 1 53.914 118.288v462.693a325.897 325.897 0 0 1-4.024 70.007 178.64 178.64 0 0 1-80.468 112.656 173.007 173.007 0 0 1-92.539 25.75H212.377a341.186 341.186 0 0 1-72.421-4.024A177.835 177.835 0 0 1 28.91 939.065a172.202 172.202 0 0 1-27.36-92.539V388.662a360.498 360.498 0 0 1 0-66.789A177.03 177.03 0 0 1 162.487 178.64h105.414c-16.899-12.07-31.383-26.555-46.672-39.43a80.468 80.468 0 0 1-25.75-65.984 80.468 80.468 0 0 1 39.43-63.57M216.4 321.873a80.468 80.468 0 0 0-63.57 57.937 108.632 108.632 0 0 0 0 30.578v380.615a80.468 80.468 0 0 0 55.523 80.469 106.218 106.218 0 0 0 34.601 5.632h654.208a80.468 80.468 0 0 0 76.444-47.476 112.656 112.656 0 0 0 8.047-53.109v-354.06a135.187 135.187 0 0 0 0-38.625 80.468 80.468 0 0 0-52.304-54.719 129.554 129.554 0 0 0-49.89-7.242H254.22a268.764 268.764 0 0 0-37.82 0z m0 0" fill="#20B0E3" ></path><path d="M348.369 447.404a80.468 80.468 0 0 1 55.523 18.507 80.468 80.468 0 0 1 28.164 59.547v80.468a80.468 80.468 0 0 1-16.094 51.5 80.468 80.468 0 0 1-131.968-9.656 104.609 104.609 0 0 1-10.46-54.719v-80.468a80.468 80.468 0 0 1 70.007-67.593z m416.02 0a80.468 80.468 0 0 1 86.102 75.64v80.468a94.148 94.148 0 0 1-12.07 53.11 80.468 80.468 0 0 1-132.773 0 95.757 95.757 0 0 1-12.875-57.133V519.02a80.468 80.468 0 0 1 70.007-70.812z m0 0" fill="#20B0E3" ></path></symbol><symbol id="icon-liaotian" viewBox="0 0 1318 1024"><path d="M1318.502489 432.779052c0-231.790522-209.29842-419.704826-467.458992-419.704826s-467.56979 188.357498-467.56979 419.704826 209.409219 419.704826 467.56979 419.704826a512.110799 512.110799 0 0 0 183.482363-33.239559l93.292361 93.292361a25.816057 25.816057 0 0 0 44.319412-19.168145L1165.822116 742.350141C1259.336074 665.56676 1318.502489 555.433023 1318.502489 432.779052z" fill="#612273" ></path><path d="M1034.304263 745.784895a509.673231 509.673231 0 0 1-183.482363 33.239559c-244.532352 0-445.077689-168.524562-465.353819-383.25211-1.107985 12.07704-1.883575 24.264878-1.883575 36.563514 0 231.790522 209.409219 419.704826 467.56979 419.704826a512.110799 512.110799 0 0 0 183.482363-33.239559l93.292361 93.292361a25.816057 25.816057 0 0 0 44.319411-19.168145 25.262064 25.262064 0 0 0-7.5343-17.284571zM1165.822116 669.223112l2.769964 70.689461C1260.44406 663.239991 1318.502489 553.992642 1318.502489 432.779052a366.632331 366.632331 0 0 0-1.883575-36.785111 403.971435 403.971435 0 0 1-150.796798 273.229171z" fill="#612273" opacity=".2" ></path><path d="M383.25211 432.779052a383.141311 383.141311 0 0 1 41.881844-172.956503c-12.298637-0.997187-24.81887-1.661978-37.449903-1.661978C173.510496 258.160571 0 413.943302 0 606.178749c0 101.713049 48.97295 193.011037 126.421121 256.609392l-5.761524 148.470028a12.187838 12.187838 0 0 0 20.830124 9.08548l94.06795-93.957153A425.577148 425.577148 0 0 0 387.79485 954.196927a404.636226 404.636226 0 0 0 300.37481-128.304696c-177.831638-59.388011-304.91755-212.733175-304.91755-393.113179z" fill="#EB3D72" ></path><path d="M342.256654 391.672798c0 117.557239 53.958883 223.59143 140.714132 299.71002a391.008007 391.008007 0 0 1-99.718676-258.603766 383.141311 383.141311 0 0 1 41.881844-172.956503c-12.298637-0.997187-24.81887-1.661978-37.449903-1.661978-7.091106 0-14.071413 0-21.05172 0.553993a375.939407 375.939407 0 0 0-24.375677 132.958234zM630.111231 802.181346a407.627786 407.627786 0 0 1-283.533434 110.798528 424.136767 424.136767 0 0 1-152.12638-27.699632l-71.686647 71.686648-2.105173 54.291279a12.187838 12.187838 0 0 0 20.830124 9.08548l94.06795-93.957153A425.577148 425.577148 0 0 0 387.79485 954.196927a404.636226 404.636226 0 0 0 300.37481-128.304696 486.294741 486.294741 0 0 1-58.058429-23.710885zM85.425665 821.792686l-5.761523-4.985934c1.883575 2.215971 3.656351 4.431941 5.650725 6.647911z" fill="#EB3D72" opacity=".5" ></path><path d="M833.426531 332.395585c64.263147-10.193465 64.041549-66.479117 62.601169-75.342999s-15.400995-54.291279-59.942004-47.200173S799.078987 254.836615 799.078987 254.836615a28.475222 28.475222 0 1 0 56.174854-8.97468s6.315516 3.323956 8.30989 20.27613-11.966241 29.029214-35.455529 33.239559-88.638823-19.943735-104.039819-115.452067C709.110582 96.39472 781.57282 28.253625 838.966457 13.185025a55.399264 55.399264 0 0 0-64.041549-5.318329c-56.064055 35.123134-97.170309 109.579745-85.536464 182.817571 14.957801 93.846354 79.664142 151.904783 144.038087 141.711318zM203.980091 573.825579a53.072495 53.072495 0 0 0 33.90435-67.919498c-2.659165-6.537113-21.162519-38.225492-53.51569-25.040467a30.026401 30.026401 0 0 0-19.832936 40.773858 22.159706 22.159706 0 1 0 40.773858-16.619779s5.318329 1.329582 9.861069 13.739017-3.988747 24.043281-21.05172 31.023588-70.02467 0.553993-98.832288-68.695087C68.916685 417.599654 110.798528 353.558104 151.904783 332.395585a42.879031 42.879031 0 0 0-48.97295 7.423502 146.918849 146.918849 0 0 0-32.574767 152.458775c27.810431 68.141095 86.866046 100.605064 133.623025 81.547717z" fill="#FED150" ></path></symbol><symbol id="icon-lianjie" viewBox="0 0 1024 1024"><path d="M935.754805 89.966493a47.62257 47.62257 0 0 0-3.672102-4.590127A252.170113 252.170113 0 0 0 753.698885 8.893371c-66.384715 1.147532-131.794027 24.72931-180.621505 72.35188l-175.055976 175.572365A248.096375 248.096375 0 0 0 325.956407 437.209615a258.538914 258.538914 0 0 0 76.540371 179.875609c1.204908 1.204908 2.52457 2.295064 3.901608 3.270466a68.163389 68.163389 0 0 0 94.72875-4.475374 68.278142 68.278142 0 0 0-2.409817-95.991035 123.187539 123.187539 0 0 1-36.548887-85.720625 112.22861 112.22861 0 0 1 32.30302-81.302628l174.654339-175.342859c22.72113-21.745728 52.384827-34.425954 83.884575-32.589903a116.93349 116.93349 0 0 1 82.851796 36.835771c22.950636 22.72113 35.917745 53.130722 36.548887 85.778002a110.908948 110.908948 0 0 1-31.384994 80.212472L728.625315 456.717656a67.704376 67.704376 0 0 0-20.885079 47.852076c-0.401636 18.245756 6.368801 35.516109 19.049028 48.655348a68.278142 68.278142 0 0 0 96.507425 1.836051l113.376141-109.417157a248.899647 248.899647 0 0 0 72.064997-180.334622c-1.147532-67.933882-28.401412-131.73665-72.983022-175.342859z" fill="#4DA1FF" ></path><path d="M520.864683 400.259091a68.565025 68.565025 0 0 0-1.893427 97.023814c22.950636 22.778506 35.975122 53.245475 36.606264 85.720625a111.88435 111.88435 0 0 1-32.30302 81.302628l-174.424833 175.055976a121.179358 121.179358 0 0 1-170.752732-171.728134l113.605648-119.974449a68.335519 68.335519 0 0 0-2.52457-96.450048 67.589623 67.589623 0 0 0-48.770101-18.647392c-18.188379 0.459013-35.114473 8.032723-47.737323 21.229339l-112.458116 118.769541c-96.679554 100.638539-94.269737 261.924133 5.106516 359.292206a260.661848 260.661848 0 0 0 183.605088 76.827253h1.204908a244.998039 244.998039 0 0 0 174.31008-72.294503l175.342859-175.629741a249.18653 249.18653 0 0 0 72.122374-180.334623 259.227433 259.227433 0 0 0-77.22889-180.449375 68.507648 68.507648 0 0 0-93.810725 0.286883z" fill="#4DA1FF" ></path></symbol><symbol id="icon-QQ" viewBox="0 0 1024 1024"><path d="M773.9392 301.8752m-200.0384 0a200.0384 200.0384 0 1 0 400.0768 0 200.0384 200.0384 0 1 0-400.0768 0Z" fill="#40ECCB" ></path><path d="M924.4672 706.2528a24.32 24.32 0 0 1-24.2688 24.2688h-145.7664a24.3712 24.3712 0 0 0-24.2688 24.32 24.2688 24.2688 0 0 0 24.2688 24.2688h48.5888a24.32 24.32 0 0 1 24.2688 24.32 24.32 24.32 0 0 1-24.2688 24.2688h-64.512A388.7616 388.7616 0 0 1 122.88 390.4512h-48.5888a24.32 24.32 0 0 1 0-48.5888h97.28a24.2688 24.2688 0 0 0 6.8096-47.5648l0.768-0.9728H122.88a24.32 24.32 0 1 1 0-48.5888h101.632a388.7616 388.7616 0 0 1 619.52 437.248h56.32a24.32 24.32 0 0 1 24.1152 24.2688z" fill="#43CEED" ></path><path d="M294.5024 575.744c-15.36 38.0928-18.2784 74.0864-5.9392 80.5376 8.6016 4.8128 22.5792-5.888 35.4816-25.2416a106.1888 106.1888 0 0 0 35.4304 55.8592c-18.7904 6.9632-31.1808 18.7904-31.1808 31.6416 0 21.504 33.3312 39.2192 74.1376 39.2192 37.0176 0 67.6352-13.9776 73.5232-32.768h8.6016c5.9392 18.7904 36.5056 32.768 73.5744 32.768 41.3184 0 74.0864-17.2032 74.0864-39.2192 0-12.8512-12.3392-24.6784-31.1296-31.6416a106.1888 106.1888 0 0 0 35.4304-55.8592c12.9024 19.3536 26.3168 30.0544 35.4304 25.2416 12.9024-6.4512 10.24-42.9568-5.888-80.5376-12.3392-29.5424-28.9792-51.5584-41.8816-56.32 0-1.6384 0.512-3.7888 0.512-5.9392a58.368 58.368 0 0 0-8.5504-30.72v-2.1504a32.1024 32.1024 0 0 0-3.2256-14.5408C609.6896 389.12 560.2816 327.68 480.256 327.68S350.8736 389.12 347.648 466.176a32.1024 32.1024 0 0 0-3.2256 14.5408v2.1504a57.9584 57.9584 0 0 0-8.6016 30.72v5.9392c-11.776 4.6592-28.9792 26.1632-41.3184 56.2176z" fill="#FFFFFF" ></path></symbol><symbol id="icon-github" viewBox="0 0 1024 1024"><path d="M512 512m-512 0a512 512 0 1 0 1024 0 512 512 0 1 0-1024 0Z" fill="#4186F5" ></path><path d="M611.944 302.056c0-15.701 2.75-30.802 7.816-44.917a384.238 384.238 0 0 0-186.11 2.956c-74.501-50.063-93.407-71.902-107.975-39.618a136.243 136.243 0 0 0-3.961 102.287 149.515 149.515 0 0 0-39.949 104.806c0 148.743 92.139 181.875 179.961 191.61a83.898 83.898 0 0 0-25.192 51.863c-40.708 22.518-91.94 8.261-115.181-32.058a83.117 83.117 0 0 0-60.466-39.98s-38.871-0.361-2.879 23.408a102.97 102.97 0 0 1 43.912 56.906s23.398 75.279 133.531 51.863v65.913c0 10.443 13.548 42.63 102.328 42.63 71.275 0 94.913-30.385 94.913-42.987V690.485a90.052 90.052 0 0 0-26.996-72.03c83.996-9.381 173.328-40.204 179.6-176.098a164.706 164.706 0 0 1-21.129 1.365c-84.07 0-152.223-63.426-152.223-141.666z" fill="#FFFFFF" ></path><path d="M743.554 322.765a136.267 136.267 0 0 0-3.961-102.289s-32.396-10.445-107.979 39.618a385.536 385.536 0 0 0-11.853-2.956 132.623 132.623 0 0 0-7.816 44.917c0 78.24 68.152 141.667 152.222 141.667 7.171 0 14.222-0.472 21.129-1.365 0.231-5.03 0.363-10.187 0.363-15.509a149.534 149.534 0 0 0-42.105-104.083z" fill="#FFFFFF" opacity=".4" ></path></symbol><symbol id="icon-bilibili1" viewBox="0 0 1024 1024"><path d="M729.32864 373.94944c-9.79456-5.94432-19.06176-6.784-19.14368-6.784l-1.06496-0.0512c-57.20064-3.8656-121.1648-5.83168-190.12608-5.83168l-13.98784 0.00512c-68.95616 0-132.92544 1.96096-190.12096 5.83168l-1.06496 0.0512c-0.08192 0-9.34912 0.83968-19.14368 6.784-15.04768 9.12896-24.27392 25.94816-27.4176 49.9712-10.07104 76.91264-4.38272 173.64992 0.18944 251.392 2.93888 49.96608 33.408 62.45888 85.04832 67.1488 10.78272 0.98816 69.08928 5.86752 159.50848 5.89312v-0.00512c90.4192-0.02048 148.72576-4.90496 159.5136-5.888 51.64032-4.68992 82.10944-17.18272 85.0432-67.1488 4.57728-77.74208 10.26048-174.47936 0.18944-251.392-3.1488-24.02816-12.37504-40.84736-27.42272-49.97632z m-390.9888 172.71808a23.64928 23.64928 0 0 1-31.68768-10.84416 23.68 23.68 0 0 1 10.84416-31.68768c2.03776-1.00352 50.69312-24.72448 110.5408-43.06432a23.68 23.68 0 1 1 13.88032 45.29152c-56.2944 17.24928-103.11168 40.07424-103.5776 40.30464z m268.89728 35.88608c-0.44032 2.23232-11.26912 54.64064-50.93888 54.64064-21.44256 0-36.10112-14.04928-44.98432-26.77248-8.69376 12.70784-22.80448 26.77248-42.65472 26.77248-35.5328 0-50.13504-48.26624-51.68128-53.77024a11.3664 11.3664 0 0 1 21.87776-6.1696c2.74944 9.6512 14.1312 37.20192 29.7984 37.20192 16.37376 0 28.89216-23.64416 31.98464-31.92832a11.37152 11.37152 0 0 1 10.6496-7.38816h0.06144c4.76672 0.03072 9.0112 3.02592 10.62912 7.50592 0.10752 0.28672 11.96544 31.81568 34.31424 31.81568 20.864 0 28.56448-35.95264 28.64128-36.32128a11.34592 11.34592 0 0 1 13.35808-8.93952 11.36128 11.36128 0 0 1 8.94464 13.35296z m110.11584-46.73536a23.68 23.68 0 0 1-31.68256 10.84416c-0.47104-0.2304-47.47264-23.1168-103.57248-40.30976a23.69024 23.69024 0 0 1-15.70816-29.58336 23.66976 23.66976 0 0 1 29.57824-15.70304c59.84768 18.33984 108.49792 42.0608 110.55104 43.06432a23.68 23.68 0 0 1 10.83392 31.68768z" fill="#F16C8D" ></path><path d="M849.92 51.2H174.08c-67.8656 0-122.88 55.0144-122.88 122.88v675.84c0 67.87072 55.0144 122.88 122.88 122.88h675.84c67.87072 0 122.88-55.00928 122.88-122.88V174.08c0-67.86048-55.00928-122.88-122.88-122.88z m-36.60288 627.45088c-2.62656 44.57984-21.82144 78.63296-55.51616 98.48832-25.68192 15.13472-54.17472 19.48672-81.13664 21.9392-32.45568 2.94912-92.71808 6.09792-164.66432 6.1184-71.94112-0.02048-132.20864-3.16416-164.66432-6.1184-26.96192-2.45248-55.45472-6.80448-81.13152-21.9392-33.69472-19.85536-52.8896-53.90336-55.51104-98.4832-4.70528-80.13312-10.5728-179.85536 0.19456-262.10816C221.5424 335.16544 280.99072 311.57248 311.5008 310.37952a2482.64192 2482.64192 0 0 1 81.42336-4.08576c-7.53664-8.53504-19.88096-23.3216-28.81536-38.11328-13.73696-22.73792 8.52992-41.68704 8.52992-41.68704s23.68-20.36736 44.52864 5.21216c15.69792 19.26656 38.37952 55.99744 48.61952 72.95488l53.20704-0.21504c13.2608 0 26.33216 0.07168 39.2192 0.21504 10.24-16.95744 32.9216-53.6832 48.61952-72.95488 20.84352-25.57952 44.52864-5.21216 44.52864-5.21216s22.26176 18.94912 8.5248 41.68704c-8.9344 14.79168-21.27872 29.57824-28.81536 38.11328 28.35968 0.97792 55.56224 2.33984 81.42336 4.08064 30.5152 1.19808 89.9584 24.79104 100.61312 106.17344 10.7776 82.24768 4.9152 181.96992 0.20992 262.10304z" fill="#F16C8D" ></path></symbol><symbol id="icon-youxiangyoujian" viewBox="0 0 1024 1024"><path d="M752 176H272C148.288 176 48 276.288 48 400v352h928V400c0-123.712-100.288-224-224-224z" fill="#CED8ED" ></path><path d="M278.08 176C398.432 176 496 273.568 496 393.92V752H48V406.08C48 279.008 151.008 176 278.08 176z" fill="#B5C4E0" ></path><path d="M496 752H176a32 32 0 0 1-32-32V400a32 32 0 0 1 32-32h314.4" fill="#FAEFDE" ></path><path d="M496 521.6l-77.28 56a32 32 0 0 1-37.6 0L144 405.76l16-35.2L496 368v153.6z" fill="#FFF7F0" ></path><path d="M160 752h336v-80H208a64 64 0 0 0-64 64v3.68c0 8.8 7.2 12.32 16 12.32z" fill="#EFD8BE" ></path><path d="M157.28 370.56H496c17.6 0 0 14.4 0 32h16c0 17.6 1.6 32-16 32H157.28c-17.6 0-17.6-64 0-64z" fill="#FFFFFF" ></path><path d="M464 848h128v176h-128z" fill="#C4939C" ></path><path d="M560 672h352a64 64 0 0 1 64 64v16H496v-16a64 64 0 0 1 64-64z" fill="#B5C4E0" ></path><path d="M976 752H48a32 32 0 1 0 0 64h928a32 32 0 1 0 0-64z" fill="#F9DD8F" ></path><path d="M752 32a16 16 0 0 0-16-16h-128a16 16 0 0 0-16 16v400a32 32 0 1 0 64 0V112a16 16 0 0 1 12.8-16l70.24-14.08a16 16 0 0 0 12.8-16L752 32z" fill="#ED7899" ></path><path d="M590.043467 466.021718a48 48 0 1 0 67.881066-67.883436 48 48 0 1 0-67.881066 67.883436Z" fill="#F9DD8F" ></path><path d="M636.16 880H419.84c-12.144 0-23.232-6.88-28.64-17.76L368 816h320l-23.2 46.24A31.984 31.984 0 0 1 636.16 880z" fill="#CDA1A7" ></path><path d="M992 738.88V400c0-132.544-107.456-240-240-240h-80V112l70.24-14.08a32 32 0 0 0 25.76-32V32a32 32 0 0 0-32-32h-128a32 32 0 0 0-32 32v128H272C139.456 160 32 267.456 32 400v338.88A48 48 0 0 0 48 832h310.08l18.72 37.44A48.016 48.016 0 0 0 419.84 896H448v112a16 16 0 0 0 32 0v-112h96v112a16 16 0 0 0 32 0v-112h28.16a48.016 48.016 0 0 0 42.88-26.56L697.92 832H976a48 48 0 0 0 16-93.12zM608 192V32h128v34.88l-70.24 14.08A32 32 0 0 0 640 112v258.56a67.632 67.632 0 0 0-32 0V192z m-6.56 217.44a28.32 28.32 0 0 1 6.56-4.96 30.912 30.912 0 0 1 32 0c2.416 1.328 4.624 2.992 6.56 4.96a32 32 0 1 1-45.248 0.128l0.128-0.128zM576 192v197.76A63.04 63.04 0 0 0 560 432a64 64 0 0 0 128 0 63.04 63.04 0 0 0-16-42.24V192h80c114.88 0 208 93.12 208 208v16h-96a16 16 0 0 0 0 32h96v288H512V400a240 240 0 0 0-120.8-208H576z m-112 544H176a16 16 0 0 1-16-16V437.12l211.84 153.28c16.8 12.176 39.52 12.176 56.32 0L480 552.96V736h-16z m16-336v113.44l-70.56 51.2a16 16 0 0 1-18.72 0L160 397.92a16 16 0 0 1 16-13.92h303.2c0.8 5.28 0.8 10.56 0.8 16zM64 400c0.336-114.88 93.728-207.728 208.608-207.392A208 208 0 0 1 474.24 352H176a48 48 0 0 0-48 48v320c0.048 5.456 1.024 10.864 2.88 16H64V400z m586.56 455.2a16 16 0 0 1-14.24 8.8H419.84a16 16 0 0 1-14.24-8.8L393.92 832h268.16l-11.52 23.2zM976 800H48a16 16 0 0 1 0-32h928a16 16 0 0 1 0 32z" fill="#8D6C9F" ></path><path d="M736 448h64a16 16 0 0 0 0-32h-64a16 16 0 0 0 0 32zM800 656v32a16 16 0 0 0 32 0v-32a16 16 0 0 0-32 0zM736 704a16 16 0 0 0 16-16v-32a16 16 0 0 0-32 0v32a16 16 0 0 0 16 16zM896 704a16 16 0 0 0 16-16v-32a16 16 0 0 0-32 0v32a16 16 0 0 0 16 16zM656 704a16 16 0 0 0 16-16v-32a16 16 0 0 0-32 0v32a16 16 0 0 0 16 16zM576 704a16 16 0 0 0 16-16v-32a16 16 0 0 0-32 0v32a16 16 0 0 0 16 16z" fill="#8D6C9F" ></path></symbol><symbol id="icon-shichen-shen" viewBox="0 0 1024 1024"><path d="M506.88 84.493c22.055 0 40.12 16.857 42.063 38.387l0.184 3.833v760.334a42.247 42.247 0 0 1-84.31 3.833l-0.184-3.833V126.713c0-23.315 18.905-42.22 42.247-42.22z m-142.572 168.96a42.247 42.247 0 1 1 0 84.467c-94.26 0-171.717 57.554-190.806 132.779h190.832a42.247 42.247 0 0 1 3.833 84.283l-3.86 0.184H177.1c23.973 69.211 98.068 120.674 187.209 120.674a42.247 42.247 0 1 1 0 84.493c-153.495 0-279.815-112.299-279.815-253.453s126.293-253.427 279.815-253.427z m285.144 0c153.495 0 279.841 112.273 279.841 253.427l-0.052 4.595 0.052 1.444c0 1.47-0.079 2.94-0.262 4.385-6.04 136.218-129.865 243.03-279.579 243.03a42.247 42.247 0 1 1 0-84.494c89.14 0 163.236-51.463 187.209-120.674H696.976l-3.86-0.184a42.247 42.247 0 0 1 3.834-84.283l143.308-0.027c-19.115-75.198-96.545-132.752-190.806-132.752a42.247 42.247 0 1 1 0-84.467z" fill="#409EFF" ></path></symbol><symbol id="icon-shichen-wei" viewBox="0 0 1024 1024"><path d="M844.8 84.493c23.342 0 42.247 18.905 42.247 42.22 0 195.69-147.824 356.825-337.92 377.83v48.81a211.285 211.285 0 0 1 168.96 206.98 42.247 42.247 0 1 1-84.494 0 126.766 126.766 0 0 0-84.466-119.52v246.234a42.247 42.247 0 0 1-84.31 3.833l-0.184-3.833V640.814a126.766 126.766 0 0 0-84.466 119.52 42.247 42.247 0 1 1-84.494 0 211.285 211.285 0 0 1 168.987-206.98v-48.785c-190.097-21.005-337.92-182.167-337.92-377.83a42.247 42.247 0 1 1 84.467 0c0 148.953 110.145 272.175 253.453 292.68v-42.77c-119.913-20.087-211.207-124.325-211.207-249.936a42.247 42.247 0 0 1 84.467 0A169.039 169.039 0 0 0 464.66 290.37V126.713a42.247 42.247 0 0 1 84.283-3.833l0.184 3.833v163.63a169.039 169.039 0 0 0 126.713-163.63 42.247 42.247 0 1 1 84.493 0c0 125.585-91.372 229.85-211.233 249.961l0.027 42.72c143.28-20.48 253.426-143.728 253.426-292.68 0-23.316 18.905-42.22 42.247-42.22z" fill="#409EFF" ></path></symbol><symbol id="icon-shichen-si" viewBox="0 0 1024 1024"><path d="M337.92 84.493a253.453 253.453 0 0 1 59.077 499.922 42.247 42.247 0 0 1-19.64-82.156 168.96 168.96 0 1 0-85.517-1.733 42.35 42.35 0 0 1 15.202 7.877 42.273 42.273 0 0 1 30.878 40.356l1.365 242.242a52.828 52.828 0 0 0 101.98 18.8l1.418-4.07a42.247 42.247 0 1 1 80.922 24.26 137.321 137.321 0 0 1-268.787-38.255l-1.207-214.751A253.453 253.453 0 0 1 337.92 84.467zM723.574 506.88a214.856 214.856 0 0 1 203.934 153.127 42.247 42.247 0 1 1-80.923 24.261 130.363 130.363 0 0 0-255.212 36.34 42.247 42.247 0 0 1-84.493-0.736A214.856 214.856 0 0 1 723.574 506.88z" fill="#409EFF" ></path></symbol><symbol id="icon-shichen-wu" viewBox="0 0 1024 1024"><path d="M506.88 84.493c22.055 0 40.12 16.857 42.063 38.387l0.184 3.833v44.321c213.464 21.215 380.166 201.308 380.166 420.34a42.247 42.247 0 0 1-84.493 0c0-172.322-128.971-314.526-295.647-335.295l-0.026 377.514h168.96a42.247 42.247 0 0 1 3.833 84.31l-3.833 0.184h-168.96v168.96a42.247 42.247 0 0 1-84.31 3.833l-0.184-3.833v-168.96H295.647a42.247 42.247 0 0 1-3.833-84.31l3.833-0.184h168.96v-377.54c-166.702 20.795-295.673 163-295.673 335.294a42.247 42.247 0 1 1-84.467 0c0-219.005 166.702-399.098 380.14-420.313v-44.32c0-23.316 18.905-42.22 42.247-42.22z" fill="#409EFF" ></path></symbol><symbol id="icon-shichen-yin" viewBox="0 0 1024 1024"><path d="M506.88 337.92a211.207 211.207 0 0 1 126.713 380.193 210.786 210.786 0 0 1 84.494 168.934 42.247 42.247 0 0 1-84.494 0 126.713 126.713 0 1 0-253.426 0 42.247 42.247 0 0 1-84.494 0 210.891 210.891 0 0 1 84.494-168.987A211.207 211.207 0 0 1 506.88 337.92z m0 84.493a126.713 126.713 0 1 0 0 253.427 126.713 126.713 0 0 0 0-253.427z m0-337.92c22.055 0 40.12 16.857 42.063 38.387l0.184 3.833v84.494l-0.105 2.31c190.122 20.953 338.025 182.14 338.025 377.83a42.247 42.247 0 1 1-84.494 0c0-163.289-132.384-295.647-295.673-295.647-163.315 0-295.673 132.358-295.673 295.647a42.247 42.247 0 1 1-84.494 0c0-195.715 147.903-356.877 338.052-377.83l-0.132-2.31v-84.494c0-23.315 18.905-42.22 42.247-42.22z" fill="#409EFF" ></path></symbol><symbol id="icon-shichen-zi" viewBox="0 0 1024 1024"><path d="M234.667 730.697a39.229 39.229 0 0 1 55.466 0c74.704 74.703 189.44 92.794 288.817 47.494a39.229 39.229 0 0 1 32.524 71.388c-128.536 58.587-278.43 34.938-376.807-63.415a39.229 39.229 0 0 1 0-55.467z m-22.504-455.826c137.874-137.874 361.375-137.874 499.224 0 137.875 137.85 137.875 361.35 0 499.224a39.229 39.229 0 1 1-55.466-55.466c107.227-107.228 107.227-281.064 0-388.291-107.203-107.228-281.064-107.228-388.267 0a39.229 39.229 0 0 1-55.491-55.467z" fill="#409EFF" ></path><path d="M644.535 490.789a39.229 39.229 0 0 1 3.56 78.287l-3.56 0.17h-392.24a39.229 39.229 0 0 1-3.56-78.287l3.56-0.17h392.24z" fill="#409EFF" ></path></symbol><symbol id="icon-shichen-you" viewBox="0 0 1024 1024"><path d="M823.664 126.713a42.247 42.247 0 0 1 3.86 84.31l-3.834 0.184H633.593v114.898A295.726 295.726 0 0 1 806.23 595.023c0 163.315-132.384 295.7-295.673 295.7-163.315 0-295.674-132.385-295.674-295.7 0-116.474 67.374-217.246 165.258-265.453V211.207H190.096a42.247 42.247 0 0 1-3.833-84.284l3.833-0.183h633.62zM510.582 383.87c-15.754 0-31.14 1.706-45.949 4.988l0.027 160.296a42.247 42.247 0 0 1-84.283 3.833l-0.184-3.833V428.898a211.207 211.207 0 1 0 253.427-5.513v125.768a42.247 42.247 0 0 1-84.283 3.833l-0.184-3.833V387.387a212.414 212.414 0 0 0-38.597-3.518z m84.467 232.316c23.342 0 42.273 18.905 42.273 42.247a126.713 126.713 0 1 1-253.453 0 42.247 42.247 0 0 1 84.283-3.86l0.184 3.86a42.247 42.247 0 0 0 84.309 3.833l0.184-3.833c0-23.342 18.904-42.273 42.22-42.273zM549.127 211.18h-84.494v91.714a297.905 297.905 0 0 1 84.494-1.05V211.18z" fill="#409EFF" ></path></symbol><symbol id="icon-shichen-xu" viewBox="0 0 1024 1024"><path d="M633.593 136.35a42.247 42.247 0 0 1 15.492 57.711 336.487 336.487 0 0 0-16.28 31.823l1.182 0.262c48.128 12.21 88.694-0.787 93.21-16.804a42.247 42.247 0 1 1 81.29 22.975c-19.613 69.395-108.229 97.779-195.295 75.697a42.667 42.667 0 0 1-5.067-1.628 360.859 360.859 0 0 0-4.989 42.798l245.182 0.026a42.247 42.247 0 0 1 3.86 84.31l-3.86 0.183H608.203a413.276 413.276 0 0 0 57.817 149.058 306.491 306.491 0 0 1 115.423-22.344 42.247 42.247 0 1 1 0 84.493c-21.057 0-41.354 2.862-60.494 8.218a464.082 464.082 0 0 0 103.844 81.343 42.247 42.247 0 1 1-42.247 73.176 547.052 547.052 0 0 1-139.343-114.425c-44.74 36.312-72.966 89.98-72.966 149.53a42.247 42.247 0 0 1-84.467 0c0-87.723 41.774-165.862 107.179-217.56-36.89-59.419-60.837-124.797-70.315-191.489H214.699v105.892l204.17 0.027a42.247 42.247 0 0 1 3.86 84.31l-3.86 0.183h-204.17v237.883a42.247 42.247 0 0 1-84.283 3.833l-0.184-3.833V181.694a42.247 42.247 0 0 1 84.31-3.833l0.183 3.833V349.21h303.787c2.993-68.004 21.609-135.404 57.396-197.395a42.247 42.247 0 0 1 57.685-15.465z" fill="#409EFF" ></path></symbol><symbol id="icon-shichen-chen" viewBox="0 0 1024 1024"><path d="M564.198 615.503h0.289l2.389 0.079-2.678-0.08a42.745 42.745 0 0 1 20.585 5.33 50.465 50.465 0 0 1 5.986 4.044 66.954 66.954 0 0 1 2.836 2.52 60.915 60.915 0 0 1 2.153 2.259l0.446 0.525c0.473 0.525 0.92 1.05 1.34 1.628l0.787 1.024 145.96 199.89h91.45a42.247 42.247 0 0 1 3.86 84.31l-3.86 0.183H727.146c-15.754 0-29.538-8.638-36.759-21.451a41.223 41.223 0 0 1-10.713-8.612L677.1 884 542.746 699.97h-99.249v182.954a42.247 42.247 0 0 1-84.283 3.834l-0.184-3.834V665.68c0-1.313 0.079-2.652 0.184-3.965a42.247 42.247 0 0 1 38.203-46.054l3.86-0.157h162.92z m217.245-488.79a42.247 42.247 0 0 1 3.834 84.31l-3.834 0.184h-488.79c-17.775 0-37.414 25.153-39.121 61.36l-0.079 4.99v597.412a42.247 42.247 0 0 1-84.31 3.86l-0.183-3.86V277.583c0-79.085 49.73-147.377 118.39-150.712l5.304-0.158h488.79zM699.97 452.555a42.247 42.247 0 0 1 3.86 84.336l-3.86 0.158H374.154a42.247 42.247 0 0 1-3.834-84.283l3.834-0.184h325.842z m-108.597-162.92a42.247 42.247 0 0 1 3.834 84.309l-3.834 0.184H374.128a42.247 42.247 0 0 1-3.834-84.31l3.834-0.184h217.245z" fill="#409EFF" ></path></symbol><symbol id="icon-shichen-hai" viewBox="0 0 1024 1024"><path d="M887.047 253.453a42.247 42.247 0 0 1 3.833 84.283l-3.833 0.184h-145.33l65.011 63.042a168.986 168.986 0 0 1 15.728 220.869l-3.335 4.306V879.51a42.247 42.247 0 0 1-84.283 4.043l-0.21-4.07V610.042c0-11.185 4.464-21.924 12.367-29.853a84.703 84.703 0 0 0 20.165-87.539l-1.707 1.838-59.733 59.76a42.247 42.247 0 0 1-62.49-56.714l2.73-3.02 59.76-59.733a40.94 40.94 0 0 1 8.06-6.328l-93.394-90.532H460.117l65.011 63.015a168.986 168.986 0 0 1 15.728 220.87l-3.335 4.305v253.375a42.247 42.247 0 0 1-84.283 4.043l-0.21-4.07V610.041c0-11.185 4.464-21.924 12.34-29.853a84.624 84.624 0 0 0 14.18-100.956 41.305 41.305 0 0 1-7.038 12.262l-2.757 3.02-59.733 59.733a42.247 42.247 0 0 1-62.49-56.714l2.757-3.02 59.733-59.733a42.125 42.125 0 0 1 17.723-10.608l-88.957-86.252h-0.866a126.713 126.713 0 0 0 0 253.453 42.247 42.247 0 1 1 0 84.467 211.207 211.207 0 0 1-168.986-337.92h-42.22a42.247 42.247 0 0 1-3.834-84.283l3.833-0.184h760.334z m-84.494-147.85a42.247 42.247 0 0 1 3.86 84.283l-3.86 0.184H211.207a42.247 42.247 0 0 1-3.86-84.283l3.86-0.184h591.346z" fill="#409EFF" ></path></symbol><symbol id="icon-shichen-chou" viewBox="0 0 1024 1024"><path d="M212.468 269.512c141.212-141.212 370.188-141.212 511.4 0s141.212 370.188 0 511.4a40.186 40.186 0 1 1-56.82-56.82c109.843-109.842 109.843-287.918 0-397.76s-287.918-109.843-397.761 0a40.186 40.186 0 0 1-56.82-56.82z" fill="#409EFF" ></path><path d="M575.013 491.92a40.186 40.186 0 0 1 3.647 80.196l-3.647 0.175h-241.09a40.186 40.186 0 0 1-3.646-80.197l3.647-0.174h241.09z" fill="#409EFF" ></path><path d="M454.456 371.387c20.98 0 38.163 16.035 40.011 36.515l0.175 3.671v241.065a40.186 40.186 0 0 1-80.172 3.671l-0.175-3.671v-241.04c0-22.203 17.983-40.186 40.161-40.186z m120.557 441.969a40.186 40.186 0 0 1 3.647 80.196l-3.647 0.175h-241.09a40.186 40.186 0 0 1-3.646-80.196l3.647-0.175h241.09z" fill="#409EFF" ></path></symbol><symbol id="icon-shichen-mao" viewBox="0 0 1024 1024"><path d="M210.183 126.74l3.833 0.052c7.64 0.42 15.281 2.967 22.003 7.72a485.113 485.113 0 0 1 204.879 396.366c0 159.56-77.536 306.176-205.273 396.656a42.037 42.037 0 0 1-22.03 7.72l-3.806 0.026a42.247 42.247 0 0 1-23-76.67 402.878 402.878 0 0 0 102.084-104.762c-113.506-6.932-204.38-95.206-204.38-204.721 0-114.11 98.645-205.168 218.716-205.168 2.547 0 5.015 0.21 7.43 0.656l-0.13-0.315-3.677-6.826a402.327 402.327 0 0 0-119.729-134.066 42.247 42.247 0 0 1 23.106-76.668z m567.558 7.772a42.247 42.247 0 1 1 48.916 68.896A402.196 402.196 0 0 0 703.094 344.59l3.597-0.472 3.86-0.158c120.07 0 218.716 91.057 218.716 205.168 0 109.489-90.847 197.79-204.354 204.72a402.248 402.248 0 0 0 102.059 104.764 42.247 42.247 0 0 1-48.837 68.923 485.14 485.14 0 0 1-205.273-396.656c0-159.376 77.352-305.86 204.88-396.366zM337.946 410.23l-0.21 0.315a42.194 42.194 0 0 1-34.5 17.88c-74.884 0-134.276 54.824-134.276 120.702 0 65.85 59.392 120.674 134.275 120.674 9.453 0 18.222 3.15 25.259 8.402l2.1-5.409c16.805-44.53 25.837-92.449 25.837-141.916a401.723 401.723 0 0 0-18.485-120.648z m337.868 0l-1.838 5.987a401.802 401.802 0 0 0-16.647 114.661c0 51.463 9.768 101.298 27.937 147.351 7.037-5.303 15.806-8.402 25.285-8.402 74.857 0 134.249-54.85 134.249-120.7 0-65.878-59.392-120.701-134.249-120.701a42.194 42.194 0 0 1-34.737-18.17z" fill="#409EFF" ></path></symbol><symbol id="icon-shengxiaoniu" viewBox="0 0 1024 1024"><path d="M211.584 734.208a303.3856 206.0672 0 1 0 606.7712 0 303.3856 206.0672 0 1 0-606.7712 0Z" fill="#FFB07D" ></path><path d="M807.6288 679.9104c-0.7296 3.9936-38.5408 202.3552-292.8 202.3552-224.1792 0-280.4992-163.8272-291.2-205.5168-7.7824 18.24-12.0448 37.504-12.0448 57.4592 0 113.8048 135.8336 206.0672 303.3856 206.0672s303.3856-92.2624 303.3856-206.0672c0-18.8032-3.7888-36.992-10.7264-54.2976z" fill="#FF7931" ></path><path d="M514.9696 528.1408c167.552 0 303.3856 92.2624 303.3856 206.0672 0 1.4464-0.1152 2.88-0.1664 4.3264 57.0752-153.3696 36.2496-194.112 31.2704-204.0704-5.0048-10.0096-40.0128-81.024-49.024-114.0352-8.9984-33.0112-4.672-83.0336-33.0112-152.7168-39.9232-98.176-246.08-103.3728-246.08-103.3728s-174.0672-15.0016-245.0816 70.0288c-39.0144 49.024-42.0224 137.0496-45.0176 162.0608-2.9952 25.0112-31.0144 106.0352-47.0144 130.048-16 24.0128-23.0144 101.0304 27.008 205.0688l0.448 0.0128c2.0992-112.5888 137.0368-203.4176 303.2832-203.4176z" fill="#F2B655" ></path><path d="M767.4368 267.712c-39.9232-98.176-246.08-103.3728-246.08-103.3728s-174.0672-15.0016-245.0816 70.0288c-20.8 26.1376-31.36 63.36-37.1456 96.2176 23.6672-40.4352 63.8848-91.3536 112.1792-80.2048 23.0144 8 48.3328 17.0112 59.6864 126.0416 6.8224 65.6 3.776 123.584-3.328 165.0432 33.3696-8.576 69.5296-13.3248 107.328-13.3248 37.1712 0 72.768 4.5568 105.6768 12.864-8.6912-38.9632-17.5488-96.8576-14.272-162.5856 4.0064-58.0224 30.016-134.1568 83.0336-129.6 34.4192 2.9568 66.5728 29.7344 94.4 69.76-3.8016-15.6416-8.96-32.5632-16.3968-50.8672z" fill="#FFFFFF" ></path><path d="M712.64 210.4448c2.8032-30.2336 4.352-88.7552-23.5392-102.4512-33.8944-16.6528-80.4864 41.9712-93.504 64.32 37.2352 6.3744 81.7664 17.7792 117.0432 38.1312zM431.6416 166.72c-16.4608-25.1392-58.6752-74.1376-90.0224-58.7264-25.1264 12.3392-26.3552 61.0688-24.3072 92.7104 34.8544-20.0832 77.2224-29.632 114.3296-33.984z" fill="#F7F89B" ></path><path d="M338.1888 667.4176l53.6832 89.5232-79.9744-17.4976-11.8016-45.5168zM689.0112 667.4176l-53.6832 89.5232 79.9872-17.4976 11.8016-45.5168z" fill="#FF7931" ></path><path d="M236.3648 348.1856a468.224 468.224 0 0 1 2.0992-13.7984c-26.56-14.0672-89.8304-50.56-131.5968-99.0336-16.8448-20.8512-34.0096-40.512-60.6848-24.9216-26.6752 15.5904 0.6656 64.2688 31.3472 92.288 27.9168 25.5104 106.7008 64.8064 158.8352 45.4656z" fill="#FFFFFF" ></path><path d="M276.2624 234.368c6.6816-8 14.272-15.104 22.5536-21.44-33.7024 19.0208-111.3472 48.6144-214.8864-1.3056 8.2176 5.8112 15.6032 14.6688 22.9376 23.744 41.7664 48.4736 105.0368 84.9664 131.5968 99.0336 5.632-33.7536 16.1792-72.8704 37.7984-100.032z" fill="#F2B655" ></path><path d="M978.7648 210.4448c-26.6752-15.5904-43.8528 4.0832-60.6848 24.9216-41.4208 48.064-103.9616 84.3392-130.9056 98.6624 0.9856 5.0048 1.8816 9.9072 2.6368 14.6176 52.1344 18.2784 129.9072-20.6208 157.6192-45.9136 30.6688-28.0192 58.0096-76.6976 31.3344-92.288z" fill="#FFFFFF" ></path><path d="M708.544 208.1408c26.5728 14.528 48.4352 33.856 58.8928 59.5712 9.9712 24.5248 15.8592 46.5536 19.7376 66.3168 26.944-14.3232 89.4848-50.5984 130.9056-98.6624 7.3344-9.0752 14.72-17.92 22.9376-23.744-108.0064 49.344-204.9408 9.9584-232.4736-3.4816z" fill="#F2B655" ></path><path d="M651.008 442.4448m-43.7632 0a43.7632 43.7632 0 1 0 87.5264 0 43.7632 43.7632 0 1 0-87.5264 0Z" fill="#FFFFFF" ></path><path d="M370.9824 442.4448m-43.7632 0a43.7632 43.7632 0 1 0 87.5264 0 43.7632 43.7632 0 1 0-87.5264 0Z" fill="#FFFFFF" ></path><path d="M1005.0048 225.6384c-1.3056-12.3776-7.8208-22.5792-18.3296-28.7232-21.5296-12.5824-39.0912-8.4992-53.0688 0.8448-87.8208 39.7184-167.9488 17.2416-204.48 2.3936 2.5984-42.2784-1.92-90.9056-33.1136-106.2272-41.3952-20.3392-88.0512 31.744-108.0448 61.2096-34.5344-5.312-61.0048-6.2976-65.7536-6.4384-5.3376-0.4352-39.6928-2.8928-83.072 1.3696-16.192-22.2592-61.76-77.12-104.4352-56.1408-24.3328 11.9552-35.5712 45.056-33.5104 98.3808-3.4432 2.2144-6.7968 4.544-10.0608 6.976 0 0-0.0128 0-0.0256 0.0128-33.7792 19.0592-104.576 44.1472-199.7696-1.4976-14.0288-9.3952-31.5648-13.44-53.0688-0.8832-10.5088 6.144-17.0112 16.3456-18.3296 28.7232-3.0336 28.6592 22.2336 66.048 47.0144 88.6656 24.1024 22.0032 83.9168 54.7584 137.856 54.7584 4.5184 0 8.9856-0.32 13.4016-0.8064-0.5376 5.2736-0.9856 10.1504-1.3696 14.4512-0.4352 4.8-0.7936 8.8192-1.1648 11.8656-2.7776 23.1168-30.2848 101.9136-44.4928 123.2256-18.5728 27.8528-27.0848 108.7616 24.7808 218.1248 1.3184 121.4976 143.8848 220.0576 318.9888 220.0576 172.3648 0 313.152-95.5008 318.784-214.3616 38.5664-104.3328 48.6144-176.3712 29.7344-214.1184-13.4016-26.816-40.6656-84.5568-47.9104-111.168-2.7136-9.9328-4.1728-22.3616-5.8496-36.7488-0.4224-3.5968-0.8576-7.3088-1.3184-11.1232 3.8528 0.3584 7.7184 0.6144 11.648 0.6144 54.016 0 114.0096-32.896 137.9456-54.7456 24.768-22.6432 50.048-60.0448 47.0144-88.6912z m-118.784 20.224c-0.5504 0.5248-1.1008 1.0496-1.664 1.5744-2.5344 2.3552-5.1072 4.672-7.7056 6.9504-0.896 0.7808-1.7792 1.5872-2.6752 2.3552-3.4688 2.9824-6.976 5.9136-10.5088 8.7424-0.5504 0.4352-1.1008 0.8576-1.6384 1.2928a403.2704 403.2704 0 0 1-12.3776 9.472c-2.5984 1.92-5.184 3.8016-7.7568 5.6192-1.024 0.7296-2.048 1.4592-3.0592 2.1632-3.4432 2.4064-6.848 4.7488-10.1888 6.976-0.0256 0.0128-0.0384 0.0256-0.064 0.0384-3.4176 2.2784-6.7584 4.4288-10.0224 6.5024-0.96 0.6144-1.8944 1.1904-2.8416 1.7792-2.3424 1.472-4.6464 2.8928-6.8736 4.2624-0.9088 0.5504-1.8304 1.1136-2.7264 1.6512-2.56 1.5488-5.056 3.0208-7.4368 4.4032-0.2688 0.1536-0.5504 0.32-0.8064 0.4736-1.9968-7.808-4.352-15.936-7.1424-24.3968 0-0.0128 0-0.0128-0.0128-0.0256-1.1648-3.5072-2.4064-7.0784-3.7248-10.7008-0.2688-0.7296-0.5248-1.4464-0.7936-2.176-1.344-3.6224-2.752-7.2832-4.2624-11.0208-1.2288-3.0208-2.6368-5.9776-4.1472-8.896-0.4864-0.9472-1.0496-1.8432-1.5616-2.7776-0.7936-1.4208-1.536-2.8672-2.4064-4.2752 31.4752 6.1184 70.208 8.5376 112.3968 0.0128z m-204.032-123.8016c10.944 5.376 16.832 29.44 16.192 63.5648-16.7808-7.552-35.7504-14.0544-56.7296-19.5072-1.1136-0.2944-2.2272-0.5504-3.3408-0.832-2.0224-0.512-4.0448-1.024-6.1056-1.5232-3.3664-0.8064-6.7072-1.5616-10.0224-2.2912 18.2912-22.9888 45.2864-46.656 60.0064-39.4112z m-349.8624 53.6192c0.6272-33.5232 8.2432-49.728 16.192-53.632 1.856-0.9088 3.904-1.3312 6.1056-1.3312 13.504 0 32.8064 15.9872 48.5632 34.3168-12.096 2.176-24.4224 4.9664-36.672 8.512-0.3968 0.1152-0.8064 0.2176-1.2032 0.3328-4.864 1.4336-9.7024 3.008-14.5152 4.6848-1.4464 0.4992-2.8928 1.0112-4.3264 1.536-4.3392 1.6-8.6528 3.264-12.9024 5.0944-0.3968 0.1792-0.8448 0.32-1.2416 0.4864z m-84.0704 73.4592c-6.9248 13.3504-12.6976 28.7744-17.4464 46.3616-0.2432 0.896-0.4736 1.792-0.7168 2.688-0.576 2.2144-1.1392 4.4672-1.6768 6.7584-0.3456 1.4336-0.6784 2.8544-1.0112 4.2752l-0.2304 0.9856c-0.5632-0.32-1.152-0.6784-1.728-1.0112-1.9712-1.152-3.9808-2.3424-6.0672-3.5968-1.0112-0.6016-2.048-1.2416-3.0848-1.8688-2.0224-1.2288-4.1088-2.5216-6.2208-3.84-1.0496-0.6528-2.0864-1.3056-3.1488-1.9712-2.6368-1.6768-5.3376-3.4176-8.0768-5.2224-0.5632-0.3712-1.1008-0.7168-1.664-1.088-3.2896-2.176-6.6304-4.4544-10.0096-6.7968-0.9216-0.64-1.8432-1.3056-2.7648-1.9584-2.5088-1.7664-5.0176-3.5712-7.552-5.4272-1.1648-0.8576-2.3424-1.728-3.5072-2.5984-2.4064-1.792-4.8128-3.6352-7.2192-5.5168-1.1136-0.8704-2.24-1.728-3.3536-2.624-3.0976-2.4576-6.1696-4.9792-9.2288-7.552-0.3584-0.3072-0.7296-0.5888-1.088-0.896a364.2752 364.2752 0 0 1-10.0224-8.8576c-0.256-0.2304-0.512-0.4864-0.768-0.7168 41.4592 9.4336 77.4272 7.2448 106.5856 0.4736zM88.0896 291.1488C66.56 271.488 49.6256 243.008 51.1104 228.9408c0.3072-2.8928 1.28-3.9808 2.9696-4.9664 3.776-2.2144 7.104-3.4304 10.4192-3.4304 8.0512 0 16.064 7.2064 30.4896 25.0624 2.5088 2.9056 5.1072 5.7728 7.7568 8.5888 0.8448 0.896 1.7152 1.7792 2.56 2.6752a339.47776 339.47776 0 0 0 8.6016 8.6528c1.8944 1.8304 3.8016 3.6352 5.7344 5.4272 0.9472 0.8832 1.8944 1.7664 2.8416 2.624a403.328 403.328 0 0 0 7.5136 6.6304c0.384 0.3328 0.7552 0.6656 1.1392 0.9984 2.8928 2.4704 5.8112 4.8896 8.7424 7.2576 0.9856 0.7936 1.9712 1.5744 2.9568 2.3552 1.9968 1.5872 3.9936 3.1616 6.0032 4.7104 1.1264 0.8704 2.24 1.7152 3.3664 2.5728 1.92 1.4464 3.8272 2.8672 5.7344 4.2752 1.0752 0.7936 2.1504 1.5872 3.2256 2.368 2.2272 1.6128 4.4416 3.1872 6.656 4.736 0.6912 0.4864 1.3824 0.9856 2.0736 1.4592 2.816 1.9584 5.6064 3.8528 8.3584 5.696 0.9984 0.6656 1.9712 1.3056 2.9568 1.9584 1.8176 1.2032 3.6224 2.3936 5.4144 3.5328 1.1008 0.704 2.176 1.3952 3.264 2.0864 1.664 1.0496 3.2896 2.0736 4.9024 3.0848 1.0368 0.64 2.0608 1.28 3.072 1.9072 1.8048 1.1008 3.5456 2.1632 5.2736 3.2 0.704 0.4224 1.4336 0.8704 2.1248 1.28 2.2016 1.3184 4.352 2.5728 6.4128 3.776-43.9552 3.1744-101.76-26.3936-123.584-46.3104z m426.88 633.4592c-158.6432 0-287.7056-85.4144-287.7056-190.4 0-0.768 0.0768-1.5232 0.0896-2.2912 0-0.0256 0.0128-0.0512 0.0128-0.0768 1.8816-100.4416 123.0208-182.7328 273.0112-187.7888 4.8384-0.1664 9.7024-0.2432 14.6048-0.2432 158.6432 0 287.7056 85.4144 287.7056 190.4 0 0.9728-0.0896 1.92-0.1152 2.8928l-0.0384 0.9856v0.0384c-3.1872 103.1936-130.9184 186.4832-287.5648 186.4832z m320.5248-383.0144c11.392 22.784 6.848 69.5936-12.6464 134.3616-0.7168-1.8176-1.5232-3.6096-2.304-5.4144-0.384-0.896-0.7424-1.8048-1.152-2.7008-1.4464-3.2128-2.9952-6.4-4.6592-9.5488-0.3072-0.5888-0.6528-1.152-0.9728-1.7408-1.3824-2.56-2.816-5.1072-4.3392-7.6288-0.6272-1.0368-1.28-2.048-1.92-3.072-1.2928-2.0608-2.624-4.1216-4.0064-6.1568a206.30144 206.30144 0 0 0-6.6304-9.1648c-0.768-1.0112-1.536-2.0224-2.3296-3.0336-1.7152-2.1632-3.5072-4.3136-5.3248-6.4256-0.6272-0.7296-1.216-1.472-1.856-2.1888-2.5088-2.8544-5.1072-5.6704-7.7952-8.4352-0.32-0.32-0.6528-0.64-0.9728-0.96-2.368-2.4064-4.8-4.7872-7.3088-7.1296-0.8832-0.8192-1.792-1.6256-2.688-2.4448-2.0096-1.8304-4.0576-3.648-6.144-5.44-1.0368-0.8832-2.0992-1.7664-3.1488-2.6496-2.0736-1.7152-4.1856-3.4048-6.3232-5.0688-1.0624-0.832-2.1248-1.664-3.2128-2.4832-2.3936-1.8176-4.8512-3.584-7.3344-5.3376-0.8576-0.6016-1.6896-1.2288-2.5472-1.8176a306.7264 306.7264 0 0 0-10.432-6.912c-0.2816-0.1792-0.576-0.3456-0.8576-0.5248-3.2384-2.0352-6.5408-4.0192-9.9072-5.9648-1.1136-0.64-2.24-1.2544-3.3664-1.8944-2.5856-1.4592-5.2096-2.8928-7.8592-4.3008-1.3184-0.6912-2.6496-1.3824-3.9936-2.0608-2.5856-1.3184-5.1968-2.6112-7.8336-3.8784-1.344-0.64-2.688-1.2928-4.0448-1.92-2.88-1.3312-5.8112-2.6368-8.7552-3.904-1.1264-0.4864-2.2272-0.9856-3.3664-1.4592-4.1088-1.728-8.2816-3.4048-12.5056-5.0048-0.2432-0.0896-0.4864-0.1664-0.7296-0.256-3.9552-1.4848-7.9744-2.9184-12.032-4.288-1.344-0.4608-2.7136-0.8832-4.0576-1.3184-3.008-0.9856-6.0288-1.9456-9.0752-2.8544-1.5872-0.4736-3.1872-0.9344-4.7872-1.3952-2.9312-0.8448-5.888-1.6512-8.8576-2.432-1.6128-0.4224-3.2256-0.8448-4.8512-1.2544-3.2-0.7936-6.4384-1.5488-9.6768-2.2784-1.3952-0.3072-2.7648-0.64-4.16-0.9472-4.6464-0.9984-9.344-1.9328-14.08-2.7904-0.2048-0.0384-0.4096-0.064-0.6016-0.1024-4.5184-0.8064-9.088-1.536-13.6832-2.2016-1.536-0.2176-3.072-0.4096-4.6208-0.6144-3.3152-0.448-6.6304-0.8704-9.984-1.2416-1.8048-0.2048-3.6096-0.384-5.4144-0.5632-3.1744-0.32-6.3616-0.6016-9.5744-0.8448-1.8304-0.1408-3.6736-0.2816-5.5168-0.4096-3.4048-0.2304-6.8352-0.3968-10.2784-0.5504-1.6-0.064-3.2-0.1664-4.8128-0.2176-5.0432-0.1664-10.112-0.2688-15.2064-0.2688-5.4016 0-10.7648 0.1024-16.128 0.2816-0.9856 0.0384-1.9584 0.1024-2.9568 0.1408-4.4288 0.1792-8.8576 0.3968-13.248 0.704-0.5632 0.0384-1.1136 0.1024-1.6768 0.1408-70.6688 5.1584-136.4224 26.2912-187.9296 60.8768-42.816 28.7488-72.5248 64.4736-86.9888 103.7056-26.6752-76.4032-18.816-128.1024-8.7808-143.1552 17.024-25.5488 46.2208-109.2352 49.536-136.8704 0.3968-3.2768 0.7936-7.6032 1.2544-12.7616 0.8576-9.4464 2.0096-21.8624 3.8912-35.5968 0.576-4.1984 1.216-8.512 1.9584-12.9408v-0.0128c6.8992-41.3056 18.4832-72.4608 34.432-92.6336a113.9072 113.9072 0 0 1 4.5312-5.0944c1.2544-1.3312 2.5728-2.624 3.904-3.9168 0.3072-0.2944 0.5888-0.6016 0.896-0.896 3.3152-3.1488 6.8736-6.1696 10.6368-9.0496 0.0256-0.0256 0.0512-0.0512 0.0896-0.0768 5.1968-3.968 10.7008-7.5904 16.448-10.9184 0.0896-0.0512 0.1792-0.064 0.2688-0.1152 17.3696-10.0096 38.0544-17.9584 61.824-23.7696 0.1408-0.0384 0.2816-0.0768 0.4224-0.1024 4.4928-1.1008 9.1136-2.0992 13.8368-3.0464 0.3712-0.0768 0.7424-0.1536 1.1008-0.2304 4.6464-0.9088 9.408-1.7536 14.2592-2.5088 0.4608-0.0768 0.9088-0.1408 1.3696-0.2176 4.672-0.7168 9.4464-1.3568 14.2976-1.9456 22.592-2.688 43.3024-3.4176 58.9312-3.4176 17.3312 0 28.416 0.8832 28.8384 0.9216 0.3072 0.0256 0.6272 0.0384 0.9344 0.0512 0.7808 0.0256 32.2176 1.0112 71.9616 7.7312 0.0128 0 0.0384 0.0128 0.0512 0.0128 44.5952 7.6288 82.5088 19.8272 109.9648 35.2512 21.9264 12.3264 37.5424 26.7776 46.4128 43.0976 1.3184 2.432 2.5216 4.928 3.5712 7.5008 2.0352 4.992 3.9168 9.984 5.696 15.0144 0.0768 0.2048 0.1536 0.4096 0.2176 0.6144 5.44 15.4752 9.7152 31.2448 12.9664 47.7952v0.0128c0.9088 4.5824 1.7024 9.0496 2.4192 13.3888 1.9072 11.7888 3.2 22.7072 4.3776 32.7552 1.8304 15.6416 3.4176 29.1584 6.7456 41.3568 9.9072 36.2368 48.512 113.664 50.2016 117.056z m101.3632-250.4448c-21.6576 19.7632-79.6928 49.3696-123.5968 46.2976 2.2016-1.28 4.5056-2.6368 6.8736-4.0576 0.6272-0.3712 1.28-0.768 1.92-1.152 1.8304-1.1008 3.6992-2.24 5.6064-3.4176 0.832-0.512 1.664-1.0368 2.5088-1.5616 1.856-1.152 3.7248-2.3424 5.6448-3.5584 0.8576-0.5504 1.7024-1.0752 2.56-1.6384 2.2272-1.4336 4.48-2.9184 6.7712-4.4416 0.5504-0.3584 1.0752-0.704 1.6256-1.0752 2.8416-1.9072 5.7344-3.8784 8.6528-5.9008 0.6272-0.4352 1.2672-0.896 1.9072-1.344 2.2784-1.6 4.5568-3.2256 6.848-4.8896 0.96-0.704 1.9328-1.408 2.8928-2.1248 2.0352-1.4976 4.0832-3.0336 6.1312-4.5824 1.0112-0.768 2.0096-1.5232 3.0208-2.304 2.1888-1.6896 4.3776-3.4176 6.5536-5.1584 0.8064-0.6528 1.6256-1.28 2.432-1.9328 2.9696-2.4064 5.9136-4.864 8.8576-7.3728 0.4864-0.4096 0.96-0.8448 1.4336-1.2544 2.432-2.0992 4.8384-4.2368 7.232-6.4 0.96-0.8704 1.8944-1.7536 2.8416-2.624 1.9328-1.792 3.84-3.5968 5.7344-5.4272 1.0112-0.9856 2.0224-1.9584 3.0208-2.9568 1.8816-1.8688 3.7376-3.7632 5.568-5.6832 0.8832-0.9216 1.7792-1.8304 2.6496-2.7648a286.464 286.464 0 0 0 7.488-8.3072l0.2688-0.3072c0.0768-0.1024 0.1536-0.192 0.2432-0.2944 7.2192-8.9216 12.8128-15.104 17.6256-19.0208 0.4096-0.3328 0.832-0.6528 1.2416-0.96 7.808-5.8496 13.6704-5.5296 21.4784-0.9728 1.6896 0.9856 2.6624 2.0736 2.9696 4.9664 1.4592 14.08-15.4752 42.56-37.0048 62.2208z" fill="#333B44" ></path><path d="M688.96 635.1872c-4.7232-1.0368-9.7536-0.0896-13.7728 2.6368a17.95072 17.95072 0 0 0-7.6032 11.968c-10.6112 66.8288-55.3472 94.1568-74.0736 102.7968-7.3984 3.4176-11.52 11.392-10.0096 19.392a17.79712 17.79712 0 0 0 16.4352 14.4896c4.4928 0.2816 8.9728 0.4096 13.4528 0.4096 34.3808 0 67.712-7.9744 92.992-22.4512 39.5392-22.1056 41.5872-51.8912 39.2832-67.6736-4.1088-28.3008-29.0176-55.3472-56.704-61.568z m1.9968 101.9904c-12.0576 6.8992-26.4448 11.9808-42.0736 15.04 18.432-17.4976 36.864-43.2768 46.1696-80.3584 9.4464 6.656 17.8816 17.6 19.6096 29.44 2.0224 13.8752-5.9136 25.92-23.7056 35.8784zM437.2224 752.6144c-18.7392-8.6528-63.4624-35.968-74.0736-102.8096-0.7808-4.8512-3.5456-9.2032-7.6032-11.968a17.69984 17.69984 0 0 0-13.7856-2.6368c-27.6608 6.208-52.5696 33.2544-56.6912 61.5808-2.304 15.7952-0.256 45.568 39.1552 67.5968 25.408 14.5408 58.752 22.528 93.1456 22.528 4.4672 0 8.96-0.128 13.4528-0.4096 8.1664-0.4992 14.9248-6.4512 16.4352-14.4896 1.472-8.0128-2.6368-15.9872-10.0352-19.392z m-97.5872-15.5136c-17.6512-9.8816-25.5872-21.9264-23.5648-35.8016 1.728-11.84 10.1632-22.784 19.6096-29.44 9.3056 37.0688 27.7248 62.8608 46.1568 80.3456-15.6416-3.0592-30.0672-8.1792-42.2016-15.104zM721.7536 262.6432c-1.3696-0.768-33.8816-18.7392-65.9328-9.4464-17.1648 4.9792-30.6688 16.4096-40.1408 33.9712-4.1088 7.616-1.2672 17.1264 6.3616 21.2352 2.368 1.28 4.9152 1.8816 7.424 1.8816 5.5808 0 10.9824-2.9824 13.8112-8.2304 5.376-9.984 12.3008-16.1024 21.1456-18.7008 19.1616-5.6448 41.472 6.3488 42.0352 6.656 7.552 4.2112 17.0752 1.5104 21.2992-6.016 4.224-7.552 1.5488-17.1008-6.0032-21.3504zM318.2848 290.0096c0.2304-0.128 22.7328-12.352 42.048-6.656 8.8576 2.5984 15.7696 8.7296 21.1584 18.7008 2.8416 5.248 8.2304 8.2304 13.8112 8.2304 2.5088 0 5.056-0.6016 7.424-1.8816 7.616-4.1088 10.4576-13.6192 6.3488-21.2352-9.472-17.5616-22.9888-28.992-40.1408-33.9712-32.0512-9.2928-64.576 8.6784-65.9328 9.4464-7.5264 4.224-10.1888 13.7216-5.9904 21.2736 4.1728 7.5392 13.7088 10.2528 21.2736 6.0928zM366.016 373.0816c-35.5072 0-64.3968 28.8896-64.3968 64.3968 0 35.5072 28.8896 64.3968 64.3968 64.3968s64.3968-28.8896 64.3968-64.3968c0-35.5072-28.8896-64.3968-64.3968-64.3968z m0 97.4592c-18.2272 0-33.0496-14.8224-33.0496-33.0496s14.8224-33.0496 33.0496-33.0496 33.0496 14.8224 33.0496 33.0496c0.0128 18.2144-14.8224 33.0496-33.0496 33.0496zM657.8944 369.2288c-36.5696 0-66.3296 29.7472-66.3296 66.3296 0 36.5696 29.7472 66.3296 66.3296 66.3296 36.5696 0 66.3168-29.7472 66.3168-66.3296 0-36.5696-29.7472-66.3296-66.3168-66.3296z m0 101.312c-19.2896 0-34.9824-15.6928-34.9824-34.9824 0-19.2896 15.6928-34.9824 34.9824-34.9824 19.2896 0 34.9824 15.6928 34.9824 34.9824-0.0128 19.2896-15.7056 34.9824-34.9824 34.9824z" fill="#333B44" ></path></symbol><symbol id="icon-shengxiaohou" viewBox="0 0 1024 1024"><path d="M660.877752 335.872a84.898909 84.898909 0 1 0 84.898909-84.898909 84.898909 84.898909 0 0 0-84.898909 84.898909z m0 0" fill="#FF8A15" ></path><path d="M745.776661 427.947372a92.143074 92.143074 0 1 1 92.075372-92.143074 92.210777 92.210777 0 0 1-92.075372 92.143074z m0-169.797818a77.654744 77.654744 0 1 0 77.587041 77.722446 77.722446 77.722446 0 0 0-77.587041-77.722446z m0 0" fill="#7F0518" ></path><path d="M694.458182 335.872A51.318479 51.318479 0 1 0 745.776661 284.350413a51.183074 51.183074 0 0 0-51.318479 51.31848z m0 0" fill="#DB1616" ></path><path d="M745.776661 394.366942a58.630347 58.630347 0 1 1 58.562645-58.562644 58.69805 58.69805 0 0 1-58.562645 58.562644z m0-102.636959a44.074314 44.074314 0 1 0 44.006612 44.074315 44.209719 44.209719 0 0 0-44.006612-44.074315z m0 0" fill="#7F0518" ></path><path d="M211.942612 335.872a84.898909 84.898909 0 1 0 84.763504-84.898909A84.898909 84.898909 0 0 0 211.942612 335.872z m0 0" fill="#FF8A15" ></path><path d="M296.706116 427.947372a92.143074 92.143074 0 1 1 92.075372-92.075372 92.210777 92.210777 0 0 1-92.075372 92.075372z m0-169.797818A77.654744 77.654744 0 1 0 374.428562 335.804298a77.654744 77.654744 0 0 0-77.722446-77.654744z m0 0" fill="#7F0518" ></path><path d="M245.387636 335.872A51.318479 51.318479 0 1 0 296.706116 284.350413a51.318479 51.318479 0 0 0-51.31848 51.31848z m0 0" fill="#DB1616" ></path><path d="M296.706116 394.366942a58.630347 58.630347 0 1 1 58.630347-58.562644 58.630347 58.630347 0 0 1-58.630347 58.562644z m0-102.636959A44.074314 44.074314 0 1 0 340.577322 335.804298a44.074314 44.074314 0 0 0-44.006611-44.074315z m0 0" fill="#7F0518" ></path><path d="M755.390413 351.44357c0 124.23405-104.397223 224.975339-233.099636 224.975339S289.123438 475.67762 289.123438 351.44357s104.329521-225.043041 233.167339-225.043041 233.099636 100.741289 233.099636 225.043041z m0 0" fill="#DB1616" ></path><path d="M522.290777 583.663074c-132.561455 0-240.411504-104.194116-240.411504-232.219504S389.729322 119.156364 522.290777 119.156364s240.343802 104.261818 240.343802 232.287206-107.85005 232.219504-240.343802 232.219504z m0-449.950677c-124.572562 0-225.923174 97.694678-225.923174 217.798876s101.553719 217.731174 225.923174 217.731173 225.787769-97.694678 225.787768-217.731173-101.553719-217.798876-225.787768-217.798876z m0 0" fill="#7F0518" ></path><path d="M726.481455 351.44357c0-64.45276-24.440595-127.009851-94.783472-130.25957-39.944463-1.827967-63.708033 46.511603-109.542611 48.204165-45.969983-1.692562-69.733554-50.032132-109.542612-48.204165-70.139769 3.249719-94.783471 65.80681-94.783471 130.25957 0.677025 106.292893 90.450512 192.952066 202.295009 196.946513h4.942281C637.181884 544.395636 726.481455 457.804165 726.481455 351.44357z m0 0" fill="#FFFFFF" ></path><path d="M525.066579 556.040463l-2.234182-7.244165v6.770247a15.368463 15.368463 0 0 1-2.911207 0c-116.989884-4.332959-208.659041-94.106446-208.659041-204.326082 0-83.138645 37.981091-134.524826 101.553719-137.436033 22.409521-0.880132 39.87676 11.644826 56.870082 23.898975s32.49719 23.560463 53.349554 24.30519c20.310744-0.744727 36.897851-12.728066 52.807934-24.30519s34.39286-24.84681 56.80238-23.898975c63.572628 2.911207 101.553719 54.161983 101.553719 137.436033 0 109.745719-90.856727 199.180694-207.169587 204.25838a5.483901 5.483901 0 0 1-1.827967 0z m0-7.244165zM522.764694 541.619835a6.296331 6.296331 0 0 1 1.963372-0.338513C633.999868 537.286876 719.711207 453.606612 719.711207 351.511273c0-35.814612-8.73362-119.359471-88.013224-122.947703-16.92562-0.744727-31.41395 9.410645-47.391735 21.190876s-36.017719 26.065455-61.338446 27.080992c-25.794645-0.947835-44.954446-14.75914-61.880066-27.080992s-30.127603-22.138711-47.391736-21.190876c-79.144198 3.655934-87.674711 87.200793-87.674711 122.947703 0 102.366149 85.508231 185.775603 194.780033 189.566942h1.150942z m0 0" fill="#7F0518" ></path><path d="M591.076496 379.133884a41.366215 41.366215 0 1 0 41.298512-41.366215A41.366215 41.366215 0 0 0 591.076496 379.133884z m0 0" fill="#7F0518" ></path><path d="M603.127537 371.077289A19.092099 19.092099 0 1 0 622.219636 352.052893a19.092099 19.092099 0 0 0-19.092099 19.092099z m0 0M637.926612 398.767603a8.665917 8.665917 0 1 0 8.665917-8.665917 8.665917 8.665917 0 0 0-8.665917 8.665917z m0 0" fill="#FFFFFF" ></path><path d="M384.583934 379.133884a41.366215 41.366215 0 1 0 41.366215-41.366215A41.366215 41.366215 0 0 0 384.583934 379.133884z m0 0" fill="#7F0518" ></path><path d="M396.431868 371.077289A19.092099 19.092099 0 1 0 415.523967 352.052893a19.092099 19.092099 0 0 0-19.092099 19.092099z m0 0M431.230942 398.767603a8.73362 8.73362 0 1 0 8.665918-8.665917 8.665917 8.665917 0 0 0-8.665918 8.665917z m0 0" fill="#FFFFFF" ></path><path d="M606.580364 311.431405a7.37957 7.37957 0 0 1-4.603769-1.62486 7.244165 7.244165 0 0 1-1.015537-10.223074 43.600397 43.600397 0 0 1 28.299636-14.75914 46.105388 46.105388 0 0 1 34.325157 14.014413 7.311868 7.311868 0 0 1-9.884562 10.696992 31.210843 31.210843 0 0 0-23.425058-10.290777 29.112066 29.112066 0 0 0-18.144264 9.478347 7.10876 7.10876 0 0 1-5.551603 2.708099z m0 0M399.816992 311.431405a7.37957 7.37957 0 0 1-4.603769-1.62486 7.244165 7.244165 0 0 1-1.015537-10.223074 43.600397 43.600397 0 0 1 28.299636-14.75914 46.173091 46.173091 0 0 1 34.325157 14.014413 7.244165 7.244165 0 0 1-9.816859 10.696992 31.549355 31.549355 0 0 0-23.49276-10.290777 29.112066 29.112066 0 0 0-18.144265 9.478347 6.770248 6.770248 0 0 1-5.551603 2.708099z m0 0M496.293025 418.401322c0 12.863471 14.894545 23.289653 33.241917 23.289653s33.241917-10.426182 33.241918-23.289653-14.894545-23.22195-33.241918-23.22195S496.293025 405.605554 496.293025 418.401322z m0 0" fill="#7F0518" ></path><path d="M504.417322 478.250314a38.522711 38.522711 0 0 1-5.551603-0.54162 40.012165 40.012165 0 0 1-25.591537-20.310744 7.37957 7.37957 0 0 1 3.249719-9.816859 7.311868 7.311868 0 0 1 9.681454 3.249719 25.523835 25.523835 0 0 0 15.368463 12.660364 25.794645 25.794645 0 0 0 20.310744-7.650381v-18.618181a7.311868 7.311868 0 0 1 14.623736 0v21.8679a6.770248 6.770248 0 0 1-2.43729 5.348496 44.819041 44.819041 0 0 1-29.721388 13.540496z m0 0" fill="#7F0518" ></path><path d="M554.04324 478.250314a44.615934 44.615934 0 0 1-29.653686-13.540496A7.244165 7.244165 0 0 1 534.138711 453.606612c8.46281 7.785785 16.316298 10.967802 23.086545 9.816859a25.320727 25.320727 0 0 0 15.368463-12.728066 7.311868 7.311868 0 0 1 9.749157-3.182017 7.37957 7.37957 0 0 1 3.249719 9.749157 40.012165 40.012165 0 0 1-25.591537 20.310744 25.523835 25.523835 0 0 1-5.619306 0.609323z m0 0" fill="#7F0518" ></path></symbol><symbol id="icon-shengxiaohu" viewBox="0 0 1047 1024"><path d="M680.412328 159.129759c20.355348 42.500907-0.33152 97.002849-46.412846 121.667962s-99.456099 10.144522-119.811448-32.29008 0.397824-96.936545 46.412847-121.667962 99.456099-10.144522 119.745143 32.29008z m0 0" fill="#FF8A15" ></path><path d="M587.785548 299.893292a93.157213 93.157213 0 0 1-24.598809-3.248899A83.742036 83.742036 0 0 1 508.41958 251.955452a92.825693 92.825693 0 0 1-1.989122-73.464906 110.197358 110.197358 0 0 1 51.120436-57.883449c49.131313-26.521627 106.948459-10.542347 128.961409 35.406371s0 104.959337-49.197618 131.414659a104.627817 104.627817 0 0 1-49.529137 12.796685z m19.360787-177.89381A91.698524 91.698524 0 0 0 563.584564 133.204869a96.339808 96.339808 0 0 0-44.688941 50.391091A77.310541 77.310541 0 0 0 520.48692 245.325045a70.28231 70.28231 0 0 0 45.948718 37.594406 88.118104 88.118104 0 0 0 64.779073-8.486921c42.368298-22.808599 61.729086-72.934473 43.163947-111.921263a72.934473 72.934473 0 0 0-67.232323-40.511785z m0 0" fill="#7F0518" ></path><path d="M578.834499 266.144522a42.036778 42.036778 0 0 1-37.528102-19.89122c-13.260813-22.609687-2.718467-55.76172 24.13468-73.86273a64.24864 64.24864 0 0 1 35.804196-11.536907 42.23569 42.23569 0 0 1 37.528102 19.89122c13.260813 22.675991 2.718467 55.76172-24.200984 73.929034a64.182336 64.182336 0 0 1-35.737892 11.470603z m0 0" fill="#DB1616" ></path><path d="M601.311577 168.346024a35.671588 35.671588 0 0 1 31.759648 16.244497c11.536908 19.294483 1.591298 47.93784-22.145558 63.91712a58.612795 58.612795 0 0 1-32.157472 10.409738 35.804196 35.804196 0 0 1-31.825952-16.3108c-11.536908-19.228179-1.591298-47.871536 22.145558-63.850816a58.281274 58.281274 0 0 1 32.223776-10.409739m0-14.52059a71.011655 71.011655 0 0 0-39.782439 12.664076c-30.102046 20.289044-41.90417 57.88345-26.521627 83.874644a49.065009 49.065009 0 0 0 43.296555 23.007511 71.409479 71.409479 0 0 0 39.78244-12.597772c30.102046-20.355348 41.90417-57.88345 26.521627-83.874644a49.065009 49.065009 0 0 0-43.296556-23.073815z m0 0" fill="#7F0518" ></path><path d="M150.974359 159.129759c-20.355348 42.500907 0.33152 97.002849 46.412846 121.667962s99.456099 10.144522 119.745144-32.29008-0.397824-96.936545-46.412846-121.667962-99.456099-10.144522-119.745144 32.29008z m0 0" fill="#FF8A15" ></path><path d="M243.60114 299.893292a105.158249 105.158249 0 0 1-49.529138-12.796685c-49.131313-26.521627-71.144263-85.333333-49.197617-131.414659s79.56488-61.861694 128.895105-35.406372S344.781145 205.542606 322.967107 251.955452a83.80834 83.80834 0 0 1-54.700855 45.020461 93.687646 93.687646 0 0 1-24.665112 3.248899zM157.008029 162.24605c-18.565139 38.920487 0.795649 89.112665 43.230251 111.921264a87.72028 87.72028 0 0 0 64.977985 8.486921A70.28231 70.28231 0 0 0 310.833463 245.325045c18.565139-38.854183-0.795649-89.112665-43.230251-111.921264s-92.030044-9.680394-110.595183 29.107486z m0 0" fill="#7F0518" ></path><path d="M252.618493 266.144522a64.182336 64.182336 0 0 1-35.804196-11.470603c-26.919451-18.167314-37.793318-51.253043-24.532505-73.929034a42.23569 42.23569 0 0 1 37.528102-19.89122A64.116032 64.116032 0 0 1 265.879306 172.390572c26.521627 18.10101 37.793318 51.253043 24.200984 73.86273a42.103082 42.103082 0 0 1-37.461797 19.89122z m0 0" fill="#DB1616" ></path><path d="M230.07511 168.346024A58.612795 58.612795 0 0 1 262.232582 179.020979c23.80316 15.97928 33.682466 44.622637 22.145558 63.850816a35.472675 35.472675 0 0 1-31.759647 16.3108 58.944315 58.944315 0 0 1-32.223777-10.409738c-23.670552-15.97928-33.682466-44.622637-22.145558-63.91712a35.804196 35.804196 0 0 1 31.825952-16.244496m0-14.520591a48.932401 48.932401 0 0 0-43.296555 23.073815c-15.581456 25.991194-3.779332 63.519296 26.521626 83.874644a71.475783 71.475783 0 0 0 39.78244 12.597773 48.932401 48.932401 0 0 0 43.230251-23.007511c15.581456-25.991194 3.845636-63.5856-26.521626-83.874644a71.343175 71.343175 0 0 0-39.716136-12.929293z m0 0" fill="#7F0518" ></path><path d="M662.046102 356.45066c0 119.347319-111.85496 216.549081-249.900026 216.549081S162.24605 476.063196 162.24605 356.45066s111.85496-216.482776 249.900026-216.482776 249.900026 96.870241 249.900026 216.482776z m0 0" fill="#FF8A15" ></path><path d="M412.146076 580.16058c-141.559182 0-256.729345-100.384356-256.729345-223.776224S270.586895 132.608133 412.146076 132.608133s256.729345 100.45066 256.729345 223.776223S553.705258 580.16058 412.146076 580.16058z m0-433.031857c-134.066822 0-243.137011 93.820254-243.137011 209.255633s109.070189 209.255633 243.137011 209.255634 243.137011-93.886558 243.137011-209.255634-109.070189-209.255633-243.137011-209.255633z m0 0" fill="#7F0518" ></path><path d="M479.113183 330.857291a43.69438 43.69438 0 1 0 87.189847 0 46.943279 46.943279 0 0 0-21.814038-39.78244 41.57265 41.57265 0 0 0-43.561771 0 46.810671 46.810671 0 0 0-21.814038 39.78244z m0 0" fill="#7F0518" ></path><path d="M491.644652 321.508418a21.747734 21.747734 0 0 0 10.011914 18.498834 19.228179 19.228179 0 0 0 19.89122 0 21.946646 21.946646 0 0 0 0-36.931365 19.228179 19.228179 0 0 0-19.89122 0 21.747734 21.747734 0 0 0-10.011914 18.432531z m0 0M528.3108 352.538721a9.746698 9.746698 0 0 0 4.574981 8.420616 8.752137 8.752137 0 0 0 9.149961 0 10.011914 10.011914 0 0 0 0-16.841233 8.752137 8.752137 0 0 0-9.149961 0 9.813002 9.813002 0 0 0-4.574981 8.420617z m0 0" fill="#FFFFFF" ></path><path d="M261.105413 330.857291a43.69438 43.69438 0 1 0 43.628076-46.412847 45.020461 45.020461 0 0 0-43.628076 46.412847z m0 0" fill="#7F0518" ></path><path d="M273.636882 321.508418a19.89122 19.89122 0 1 0 40.180264 0 21.747734 21.747734 0 0 0-10.011914-18.432531 19.228179 19.228179 0 0 0-19.89122 0 21.68143 21.68143 0 0 0-10.078218 18.432531z m0 0M310.30303 352.538721a9.879306 9.879306 0 0 0 4.574981 8.420616 8.884745 8.884745 0 0 0 9.216265 0 10.011914 10.011914 0 0 0 0-16.841233 8.884745 8.884745 0 0 0-9.216265 0 9.94561 9.94561 0 0 0-4.574981 8.420617z m0 0" fill="#FFFFFF" ></path><path d="M550.32375 264.752137a6.630407 6.630407 0 0 1-4.641284-1.922818 34.08029 34.08029 0 0 0-25.195546-11.669516 30.698783 30.698783 0 0 0-19.891219 11.006475 6.630407 6.630407 0 0 1-9.61409 0.928257 7.426055 7.426055 0 0 1-0.994561-10.078218 44.291116 44.291116 0 0 1 29.306397-16.244496 45.882414 45.882414 0 0 1 35.53898 15.515151 7.558664 7.558664 0 0 1 0.397824 10.144522 6.630407 6.630407 0 0 1-4.972805 2.320643z m0 0M281.858586 264.752137a6.630407 6.630407 0 0 1-4.309764-1.591298 7.426055 7.426055 0 0 1-0.994561-10.144522 44.291116 44.291116 0 0 1 29.306397-16.244496 45.948718 45.948718 0 0 1 35.538979 15.515151 7.558664 7.558664 0 0 1 0.397825 10.144522 6.630407 6.630407 0 0 1-9.680394 0.397825 33.152033 33.152033 0 0 0-25.328153-11.603212 30.963999 30.963999 0 0 0-19.89122 10.940171 6.630407 6.630407 0 0 1-5.238021 2.585859z m0 0M455.508936 414.798239c0 15.581456-17.106449 28.311836-38.191143 28.311836s-38.124838-12.730381-38.124838-28.311836 17.040145-28.311836 38.124838-28.311837 38.191142 12.664077 38.191143 28.311837z m0 0" fill="#7F0518" ></path><path d="M376.673401 498.672883a41.970474 41.970474 0 0 1-8.1554-0.795649c-25.062937-4.972805-37.727014-31.494431-38.323751-32.621601a7.359751 7.359751 0 0 1 3.049987-9.614089 6.630407 6.630407 0 0 1 9.216265 3.182595S352.803937 480.174048 371.302771 484.019684c12.001036 2.386946 25.195545-3.049987 39.78244-16.111888v-35.074851a6.630407 6.630407 0 1 1 13.260813 0V470.758871a7.624968 7.624968 0 0 1-2.254338 5.370629c-15.515152 14.918415-30.632479 22.477078-45.219373 22.477079z m0 0" fill="#7F0518" ></path><path d="M458.02849 498.672883c-14.520591 0-29.704222-7.558664-45.285677-22.543383a7.492359 7.492359 0 0 1-0.397825-10.210826 6.630407 6.630407 0 0 1 9.61409-0.464129c15.051023 14.586895 29.041181 20.686869 41.638954 18.167315 18.366226-3.514116 28.577053-24.665113 28.643356-24.864025a6.630407 6.630407 0 0 1 9.216265-3.248899 7.492359 7.492359 0 0 1 3.049988 9.680393c-0.596737 1.127169-13.260813 27.648796-38.323751 32.621601a37.859622 37.859622 0 0 1-8.1554 0.861953z m0 0M648.718985 292.599845c-29.704222 20.885781-33.152033 22.079254-58.811707 22.145558-3.248899 0-7.492359 1.591298-7.426056 4.972805s2.983683 4.24346 5.503238 5.039109c18.631443 5.503238 39.78244 7.359751 75.65294-14.653199M654.487438 331.520332c-30.49987 19.493395-47.208495 26.057498-72.934472 24.996633-3.248899 0-7.558664 1.259777-7.624968 4.707588s2.784771 4.376068 5.304325 5.238021c18.43253 6.298886 50.921523 4.707589 87.653976-15.714063M176.832945 292.599845c29.704222 20.885781 33.152033 22.079254 58.811707 22.145558 3.248899 0 7.492359 1.591298 7.426055 4.972805s-2.983683 4.24346-5.503237 5.039109c-18.631443 5.503238-39.78244 7.359751-75.65294-14.653199M171.064491 331.520332c30.433566 19.493395 47.142191 26.057498 72.934473 24.996633 3.248899 0 7.558664 1.259777 7.624968 4.707588s-2.851075 4.376068-5.304326 5.238021c-18.43253 6.298886-50.987827 4.707589-87.720279-15.714063M348.759389 207.332815c53.905206-23.935768 85.001813-22.145558 132.276612 4.906501 4.442372 2.519555 7.956488 6.630407 5.967366 8.951049-1.060865 1.127169-3.58042 2.784771-8.48692 0a77.443149 77.443149 0 0 0-23.869464-8.288008 193.077441 193.077441 0 0 0-102.041958 5.901062c-2.718467 0.795649-10.873867 4.442372-12.531469 0-1.193473-3.049987-1.392385-6.630407 8.685833-11.536908z m0 0" fill="#7F0518" ></path><path d="M340.007252 174.644911c60.204092-23.736856 94.947423-21.880342 147.858068 5.370629 4.906501 2.45325 8.818441 6.630407 6.630406 8.884745s-4.044548 2.784771-9.547785 0a96.406112 96.406112 0 0 0-26.521627-8.420617 238.694639 238.694639 0 0 0-114.042994 5.304326c-2.983683 0.795649-12.133644 4.376068-13.990158 0-1.326081-2.917379-1.524994-6.166278 9.680394-11.4043z m0 0M366.926703 234.185962c28.643357-11.404299 58.281274-17.835794 97.732194 3.779332 4.840197 2.652163 9.017353 9.813002 6.630406 11.934732-1.127169 1.127169-4.044548 2.784771-9.547785 0a148.123284 148.123284 0 0 0-92.228956-1.79021c-3.049987 0.861953-12.133644 4.376068-13.990158 0-1.259777-2.983683 0-9.083657 11.205387-14.18907z m0 0" fill="#7F0518" ></path><path d="M403.526548 158.135198c0.596737 22.543383 1.060865 45.153069 1.657601 67.762756a13.260813 13.260813 0 0 0 4.641285 11.669516A20.421652 20.421652 0 0 0 419.306915 218.803419c1.259777-20.952085 0-35.936804 1.922818-59.67366" fill="#7F0518" ></path></symbol><symbol id="icon-shengxiaoshe" viewBox="0 0 1024 1024"><path d="M497.512242 541.207055h-34.532463c-96.717359 0-137.468312-86.9927-175.90387-175.90387C188.903159 136.608308 387.696363 62.25105 484.281414 66.154144c116.034369 4.366174 278.839718 57.62026 189.333161 299.413658C640.008269 456.000517 576.897216 541.207055 497.512242 541.207055z m0 0" fill="#DB1616" ></path><path d="M497.512242 547.624007h-34.532463C358.588539 547.624007 315.588346 447.929711 281.122036 367.817042c-37.112475-86.463467-36.252471-158.769946 2.447704-215.331739C332.920731 80.509594 431.358098 57.421797 484.612184 59.53873s148.185283 15.678532 194.559339 85.074229c35.524776 52.923315 35.657084 128.074423 0.595387 222.939467C647.417533 454.545126 582.652626 547.624007 497.512242 547.624007z m-19.846243-475.449836c-51.931003 0-138.923703 22.624717-183.643905 87.588088-36.054009 52.923315-36.384779 120.863622-1.12462 203.027068 41.809419 97.445055 80.906519 172.000775 170.016151 172.000776H497.512242c78.392661 0 138.923703-88.712708 169.949997-172.000776 33.672459-90.82964 33.937076-161.879191 0.860004-211.362491C625.189741 86.9927 534.360101 74.158796 484.281414 72.30648h-6.615415z m0 0" fill="#7F0518" ></path><path d="M485.009109 620.658182a28.777053 28.777053 0 0 1-24.675496-13.230829 28.380128 28.380128 0 0 1-19.846243 8.269268 33.804768 33.804768 0 0 1-9.129272-1.455391c-28.710899-7.938497-28.843207-40.817107-24.873958-57.024872a6.615414 6.615414 0 0 1 6.218489-4.961561h0.661542a6.615414 6.615414 0 0 1 5.75541 6.086181c0 1.12462 1.786162 27.321662 20.441631 27.917049 12.635442 0 19.383164-39.229408 19.383164-67.543381a6.615414 6.615414 0 0 1 2.050779-4.696945 6.152335 6.152335 0 0 1 4.366173-1.720007l11.378513 0.860004a6.615414 6.615414 0 0 1 5.887719 5.953873 239.544157 239.544157 0 0 1-4.63079 53.32024l-0.860004 5.358486a14.024679 14.024679 0 0 0 2.513857 10.320046 8.533885 8.533885 0 0 0 5.358486 3.373861 17.200078 17.200078 0 0 0 2.646166 0c16.538536 0 22.02933-24.080109 22.095484-24.344725a6.615414 6.615414 0 0 1 6.284644-5.027715h0.463079a6.615414 6.615414 0 0 1 5.953873 5.953873c1.256929 16.670844-4.233865 49.086375-33.937076 52.19562h-3.638478z m0 0" fill="#FF8A15" ></path><path d="M465.493637 518.714646l10.849279 0.860004a269.247367 269.247367 0 0 1-5.292331 57.355643 18.060081 18.060081 0 0 0 13.230829 20.970863h3.506169c21.897022 0 28.380128-29.37244 28.380128-29.37244s3.109245 42.074036-28.181665 45.315589a22.426255 22.426255 0 0 1-2.910783 0c-11.18005 0-18.986239-6.615414-23.418567-18.853931A25.138575 25.138575 0 0 1 440.222753 608.618128a26.461658 26.461658 0 0 1-7.012339-0.992312c-30.298598-8.335422-20.375476-49.350992-20.375476-49.350992s1.720008 33.077072 26.461657 34.00323h0.396925c25.469346 0 25.601654-73.828025 25.601654-73.828025m0-12.833904a12.833904 12.833904 0 0 0-12.833904 12.833904c0 30.761677-7.210802 58.612572-12.900058 61.192584-12.569287-0.396925-14.090833-21.632405-14.090833-21.830868a13.230829 13.230829 0 0 0-11.643129-12.172363h-1.256929A13.230829 13.230829 0 0 0 400.26565 555.694812c-4.498482 18.324698-4.035403 55.503327 29.438594 64.764908a41.280186 41.280186 0 0 0 10.452355 1.389237 34.00323 34.00323 0 0 0 19.118548-5.755411 34.730926 34.730926 0 0 0 25.667808 10.981588h4.300019c34.532463-3.572324 41.015569-40.22172 39.692487-59.141805A12.833904 12.833904 0 0 0 516.961561 555.694812h-0.926158a13.230829 13.230829 0 0 0-12.569288 10.121584s-4.763098 19.31701-15.81084 19.317011h-1.786162a1.91847 1.91847 0 0 1-0.992312-0.860004 7.607727 7.607727 0 0 1-1.323083-5.490794c0-1.256929 0.463079-3.043091 0.860004-5.226178a242.388785 242.388785 0 0 0 4.763098-54.841785A13.230829 13.230829 0 0 0 477.665999 506.873054l-10.84928-0.860004a3.109245 3.109245 0 0 0-1.058466 0z m0 0M568.363331 286.381291a42.801731 42.801731 0 1 0 21.764713-37.046321 42.669423 42.669423 0 0 0-21.433942 37.046321z m0 0" fill="#7F0518" ></path><path d="M580.668002 277.847406a19.846243 19.846243 0 0 0 9.856967 17.067769 19.449318 19.449318 0 0 0 19.846244 0A19.846243 19.846243 0 1 0 580.668002 277.847406z m0 0M616.589702 306.492151a9.063118 9.063118 0 1 0 13.230829-7.806189 8.798501 8.798501 0 0 0-8.996964 0 8.930809 8.930809 0 0 0-4.233865 7.806189z m0 0" fill="#FFFFFF" ></path><path d="M313.934492 286.381291a42.801731 42.801731 0 1 0 21.367789-37.046321 42.735577 42.735577 0 0 0-21.367789 37.046321z m0 0" fill="#7F0518" ></path><path d="M326.173009 277.847406a19.846243 19.846243 0 1 0 19.846243-19.846243 19.846243 19.846243 0 0 0-19.846243 19.846243z m0 0M362.160863 306.492151a8.996964 8.996964 0 1 0 17.993927 0 8.996964 8.996964 0 0 0-4.498481-7.806189 8.798501 8.798501 0 0 0-8.996964 0 8.996964 8.996964 0 0 0-4.498482 7.806189z m0 0" fill="#FFFFFF" ></path><path d="M584.108017 224.924091a6.020027 6.020027 0 0 1-3.969248-1.455391 6.615414 6.615414 0 0 1-0.992313-9.063118 44.190968 44.190968 0 0 1 28.578591-14.884683 45.778668 45.778668 0 0 1 34.730926 14.223141 6.615414 6.615414 0 0 1 0.595387 9.063118 6.615414 6.615414 0 0 1-9.129272 0.396925 33.672459 33.672459 0 0 0-25.072421-10.84928 30.96014 30.96014 0 0 0-19.846243 10.187739 6.21849 6.21849 0 0 1-5.027715 2.381549z m0 0M334.17766 224.924091a6.21849 6.21849 0 0 1-4.035403-1.455391 6.615414 6.615414 0 0 1-0.926158-9.063118 44.190968 44.190968 0 0 1 28.578591-14.884683 45.778668 45.778668 0 0 1 34.730925 14.223141 6.615414 6.615414 0 1 1-8.666193 9.460043A34.00323 34.00323 0 0 0 358.588539 212.354803a31.224756 31.224756 0 0 0-19.846243 10.187739 6.086181 6.086181 0 0 1-4.961561 2.381549z m0 0M518.416952 441.181989c-14.487758-0.529233 44.521739-35.855546 50.343304 12.767749 1.984624 15.744686-6.615414-11.047742-50.343304-12.767749z m0 0M444.192002 434.632728c14.421603-0.529233-44.521739-35.855546-50.409458 12.76775C391.665611 463.07901 400.199496 436.617353 444.192002 434.632728z m0 0" fill="#7F0518" ></path><path d="M479.782932 196.411654s46.307901-7.806189 108.095872-108.955875A293.989017 293.989017 0 0 0 483.686026 66.154144a230.216422 230.216422 0 0 0-87.786549 15.876995c18.589315 40.817107 48.160217 93.674268 83.883455 114.711286z m0 0" fill="#EE3E2B" ></path><path d="M479.716778 202.828606a5.755411 5.755411 0 0 1-3.241554-0.926158C439.36275 180.005427 408.931843 125.692874 390.011758 84.346534a5.755411 5.755411 0 0 1 0-5.093869 6.615414 6.615414 0 0 1 3.572324-3.572324A240.933394 240.933394 0 0 1 483.884489 59.53873 301.199819 301.199819 0 0 1 590.128044 81.56806a6.615414 6.615414 0 0 1 3.572324 3.903094 6.615414 6.615414 0 0 1-0.595387 5.292332c-62.383358 102.47277-110.477421 111.535887-112.462045 111.932812a3.109245 3.109245 0 0 1-1.124621 0zM404.89644 85.272692c17.861619 37.972479 44.654047 84.214226 76.14342 104.258931 9.26158-3.109245 48.027909-19.846243 97.643517-99.231216a298.421345 298.421345 0 0 0-94.997351-18.258544 223.667162 223.667162 0 0 0-78.789586 13.230829z m0 0" fill="#7F0518" ></path></symbol><symbol id="icon-shengxiaotu" viewBox="0 0 1024 1024"><path d="M636.279682 312.857691s144.390458-231.642446 59.174116-264.844529S524.950919 266.739786 524.950919 266.739786z m0 0" fill="#FFFFFF" ></path><path d="M636.279682 319.315602a8.072388 8.072388 0 0 1-2.527009-0.491363L522.494105 272.355361a6.5983 6.5983 0 0 1-3.579929-8.072389c2.597203-7.581026 63.877159-186.156293 136.669043-220.130518a52.7864 52.7864 0 0 1 42.116808-2.176035 44.854401 44.854401 0 0 1 27.375926 29.271182c23.795997 71.738964-79.109405 237.959967-83.461475 244.979435a6.387716 6.387716 0 0 1-5.475185 3.088566zM532.953112 262.808884l100.448588 42.116808c16.706334-27.656704 99.114889-169.590348 79.319989-229.255826a32.640526 32.640526 0 0 0-19.865095-21.058405 38.887853 38.887853 0 0 0-31.868385 1.544283C599.989032 84.233617 544.32465 231.642446 532.953112 262.808884z m0 0" fill="#7F0518" ></path><path d="M625.259117 270.881272s88.304908-146.426104 46.398684-167.484508-100.869756 138.143131-100.869756 138.143132z m0 0" fill="#FF8A15" ></path><path d="M625.259117 277.409378a5.896353 5.896353 0 0 1-3.018371-0.772142L568.050452 247.29586a6.457911 6.457911 0 0 1-3.018371-8.002194c4.703044-12.845627 47.802577-126.350425 88.796271-142.214423a24.427749 24.427749 0 0 1 21.058404 0.561558 25.480669 25.480669 0 0 1 13.1966 16.565944c12.14368 43.169729-49.838223 148.180971-56.857691 160.114067a6.528105 6.528105 0 0 1-5.615575 3.088566zM578.930628 238.661914l44.012065 23.655607c20.145873-34.535783 61.139567-114.206745 52.365231-144.390458a12.635043 12.635043 0 0 0-6.528105-8.633945 12.00329 12.00329 0 0 0-10.529202 0c-28.709624 11.160954-65.210858 92.516589-79.319989 129.368796z m0 0" fill="#7F0518" ></path><path d="M287.692898 312.857691s-144.390458-231.642446-59.24431-264.844529S398.951467 266.739786 398.951467 266.739786z m0 0" fill="#FFFFFF" ></path><path d="M287.692898 319.315602a6.5983 6.5983 0 0 1-5.545379-3.088566c-4.35207-7.019468-107.257472-173.170277-83.461476-244.979435A45.13518 45.13518 0 0 1 226.132163 42.116808a52.224842 52.224842 0 0 1 42.116809 2.176035c73.072662 33.833836 134.282424 212.409103 136.879627 219.990129a6.457911 6.457911 0 0 1-3.650124 8.072389l-111.258568 46.468878a6.457911 6.457911 0 0 1-2.527009 0.491363zM244.312586 51.522896A37.554154 37.554154 0 0 0 231.115986 54.049904a32.359748 32.359748 0 0 0-19.7949 21.058404c-19.7949 59.735673 62.68385 201.599123 79.249794 229.326022l100.448588-42.116809C379.577735 231.642446 323.913353 84.233617 262.984371 56.155744a43.661091 43.661091 0 0 0-18.671785-4.562654z m0 0" fill="#7F0518" ></path><path d="M298.643268 270.881272S210.408555 124.455169 252.17439 103.396764s101.010145 138.143131 101.010145 138.143132z m0 0" fill="#FF8A15" ></path><path d="M298.643268 277.409378a6.528105 6.528105 0 0 1-5.545379-3.088566c-7.019468-11.933096-69.422539-116.944338-56.927886-160.114067a25.550864 25.550864 0 0 1 13.126405-16.565944 24.848917 24.848917 0 0 1 21.058404-0.561558c40.993693 16.074582 84.233617 129.298602 88.796271 142.214423a6.528105 6.528105 0 0 1-3.018371 8.002194l-54.471072 29.341376a6.387716 6.387716 0 0 1-3.158761 0.772142z m-38.39649-169.379765a10.739786 10.739786 0 0 0-5.054017 1.19331 12.915821 12.915821 0 0 0-6.5983 8.633946c-8.70414 30.183713 32.289553 109.78448 52.435427 144.390458L345.041952 238.661914c-14.038936-36.641623-50.610365-117.997258-79.319989-129.298602a14.038936 14.038936 0 0 0-5.475185-1.193309z m0 0" fill="#7F0518" ></path><path d="M692.435426 394.213326c0 115.751028-104.168906 163.553606-232.835755 163.693995s-233.046339-47.521799-233.186729-163.272827 107.257472-235.222375 235.924322-235.362764 229.957774 119.330957 230.098162 234.941596z m0 0" fill="#FFFFFF" ></path><path d="M459.108308 564.365232c-68.790787 0-126.771593-13.547573-167.835481-39.168632-47.311215-29.622155-71.38799-73.564025-71.38799-130.562106 0-114.066356 103.607349-241.75048 242.452427-241.820674 135.194955 0 236.345489 127.403345 236.415684 241.399506 0 106.415136-89.357828 170.081711-239.363861 170.2221zM462.758432 165.799835c-106.134357 0-229.466411 100.097614-229.466411 228.834659 0 52.295037 22.04113 92.516589 65.351247 119.330957 38.887853 24.427749 94.622429 37.203181 160.956403 37.203181h0.421168c68.159035 0 226.518234-15.513024 226.377845-157.095695 0-107.889224-95.67535-228.413491-223.429668-228.413491z m0 0" fill="#7F0518" ></path><path d="M525.021113 338.619139a43.801481 43.801481 0 1 0 21.970935-37.905127 43.731286 43.731286 0 0 0-21.90074 37.905127z m0 0" fill="#7F0518" ></path><path d="M537.585961 329.914999a20.075679 20.075679 0 0 0 10.108034 17.40828 19.935289 19.935289 0 0 0 20.145873 0A20.145873 20.145873 0 1 0 537.585961 329.914999z m0 0M574.438168 359.18618a9.195503 9.195503 0 1 0 9.125309-9.195503 9.125308 9.125308 0 0 0-9.125309 9.195503z m0 0" fill="#FFFFFF" ></path><path d="M306.294489 338.619139a43.801481 43.801481 0 1 0 21.90074-37.905127 43.731286 43.731286 0 0 0-21.90074 37.905127z m0 0" fill="#7F0518" ></path><path d="M318.929531 329.914999a20.145873 20.145873 0 1 0 20.145873-20.145874A20.145873 20.145873 0 0 0 318.929531 329.914999z m0 0M355.711544 359.18618a9.195503 9.195503 0 1 0 9.125308-9.195503 9.125308 9.125308 0 0 0-9.125308 9.195503z m0 0" fill="#FFFFFF" ></path><path d="M541.16589 275.7949a6.106937 6.106937 0 0 1-4.071292-1.474088 6.457911 6.457911 0 0 1-0.982725-9.125309 45.13518 45.13518 0 0 1 29.200987-15.232246 47.030436 47.030436 0 0 1 35.09734 14.530299 6.387716 6.387716 0 0 1 0.421168 9.125309 6.528105 6.528105 0 0 1-9.265698 0.421168 34.395393 34.395393 0 0 0-25.621058-11.09076A31.517412 31.517412 0 0 0 546.219907 273.759254a6.457911 6.457911 0 0 1-5.054017 2.386619z m0 0M327.072114 275.7949a6.387716 6.387716 0 0 1-4.141486-1.474088 6.457911 6.457911 0 0 1-0.912531-9.125309 44.643817 44.643817 0 0 1 29.200987-15.232246 47.24102 47.24102 0 0 1 35.09734 14.530299 6.528105 6.528105 0 0 1-8.563751 9.265698 34.325199 34.325199 0 0 0-25.691253-11.090759A31.517412 31.517412 0 0 0 332.055936 273.759254a6.177132 6.177132 0 0 1-4.983822 2.386619z m0 0M500.172196 407.129147c0 14.881272-17.127502 26.814368-38.256101 26.814368s-38.256101-11.933096-38.2561-26.814368 17.127502-26.814368 38.2561-26.814368 38.256101 12.073485 38.256101 26.814368z m0 0" fill="#7F0518" ></path><path d="M427.661091 484.904853a23.866191 23.866191 0 0 1-9.195503-1.825061c-17.829449-7.019468-19.7949-33.342473-19.935289-36.29065a6.457911 6.457911 0 0 1 6.036742-7.019468 6.317521 6.317521 0 0 1 7.019468 6.106937c0.350973 5.40499 3.228955 21.479572 11.933096 24.989306 7.019468 2.807787 18.180422-2.176035 31.79819-14.038936V423.975871a6.457911 6.457911 0 1 1 12.915822 0v35.869481a6.5983 6.5983 0 0 1-2.105841 4.843433c-14.811078 13.547573-27.44612 20.216068-38.326295 20.216068z m0 0" fill="#7F0518" ></path><path d="M495.609542 484.904853c-10.599397 0-23.164245-7.019468-37.975322-20.216068a6.457911 6.457911 0 1 1 8.70414-9.616671c14.530299 13.266795 26.3932 18.882369 33.272279 15.934193 8.282972-3.439539 10.669591-19.584316 10.880175-24.989307a6.528105 6.528105 0 0 1 6.457911-6.317521 6.528105 6.528105 0 0 1 6.247327 7.019468c0 2.948177-1.403894 29.200987-18.812175 36.571429a21.690156 21.690156 0 0 1-8.984919 1.895256z m0 0" fill="#7F0518" ></path><path d="M583.774061 412.042775c0 9.265698 7.65122 17.899644 19.935289 22.602687a59.103921 59.103921 0 0 0 39.940773 0c12.354264-4.703044 19.935289-13.336989 19.93529-22.602687s-7.581026-17.969838-19.93529-22.672882a59.103921 59.103921 0 0 0-39.940773 0c-12.284069 4.703044-19.935289 13.336989-19.935289 22.672882z m0 0M260.387168 412.042775c0 14.038936 17.829449 26.042226 39.870578 26.042226s39.870579-11.652317 39.870579-26.042226S322.36907 386.070743 300.257746 386.070743s-39.870579 11.652317-39.870578 26.112421z m0 0" fill="#DB1616" ></path></symbol><symbol id="icon-shengxiaolong" viewBox="0 0 1024 1024"><path d="M605.179956 208.857072a12.638855 12.638855 0 0 1-2.085411-0.505554 12.259689 12.259689 0 0 1-7.709702-15.608985c1.011108-3.033325 25.783263-74.822019 87.524068-120.069119a12.638855 12.638855 0 1 1 14.597877 19.906196c-55.484572 40.760306-78.550481 107.430264-78.740064 108.125401a12.638855 12.638855 0 0 1-13.586768 8.27845z m0 0" fill="#7F0518" ></path><path d="M707.365095 160.955813a12.638855 12.638855 0 0 1-9.731918-7.962478c-0.505554-1.200691-11.185386-28.563811-38.990866-30.333251a12.638855 12.638855 0 0 1 1.453468-24.645767c44.80474 2.527771 60.034559 44.741545 60.666502 46.57418a12.638855 12.638855 0 0 1-7.456924 15.735374 11.185386 11.185386 0 0 1-5.940262 0.631942z m-39.812392 23.255493a12.070106 12.070106 0 0 1-9.921501-8.531227 23.950629 23.950629 0 0 0-24.077018-15.22982 12.322883 12.322883 0 0 1 0-24.582572 48.533202 48.533202 0 0 1 47.648482 32.608245 12.638855 12.638855 0 0 1-8.215255 15.356208 12.638855 12.638855 0 0 1-5.308319 0.379166z m-194.701555 24.645766a13.207603 13.207603 0 0 0 2.148605-0.505554 12.259689 12.259689 0 0 0 7.646507-15.608985C481.635152 189.582819 456.862997 117.920513 394.932609 72.547025a12.638855 12.638855 0 0 0-14.597877 19.906196c55.547766 40.760306 78.613676 107.430264 78.740064 108.125402a12.638855 12.638855 0 0 0 13.586769 8.278449z m0 0" fill="#7F0518" ></path><path d="M370.602814 160.955813a12.638855 12.638855 0 0 0 9.731918-7.962478c0.505554-1.200691 11.185386-28.563811 38.990867-30.333251a12.638855 12.638855 0 0 0-1.453469-24.645767c-44.80474 2.527771-60.034559 44.741545-60.666502 46.57418a12.638855 12.638855 0 0 0 7.456924 15.735374 11.248581 11.248581 0 0 0 5.940262 0.631942z m39.875586 23.255493A12.259689 12.259689 0 0 0 420.210318 175.680079a23.887435 23.887435 0 0 1 24.013824-15.22982 12.322883 12.322883 0 0 0 0-24.582572 48.533202 48.533202 0 0 0-47.648482 32.608245 12.638855 12.638855 0 0 0 8.27845 15.356208 13.01802 13.01802 0 0 0 5.371513 0.379166z m0 0" fill="#7F0518" ></path><path d="M607.391755 576.078993c-18.199951-5.118736-49.733893-30.586028-68.755369-30.586028s-50.555418 25.277709-68.818563 30.586028c-73.937299 20.664527-146.294742-59.086645-140.291286-130.87534 3.538879-41.834609 36.399901-124.745495 45.942236-165.695383 17.504814-75.833128 80.951864-130.875339 157.985683-130.87534h9.984695c77.160207 0 141.491977 55.990126 157.985682 130.87534 9.099975 41.076277 42.403357 123.923969 45.942237 165.695383 6.319427 71.788694-66.417181 151.666255-140.291286 130.87534z m0 0" fill="#FF8A15" ></path><path d="M631.215996 585.684522a97.129598 97.129598 0 0 1-25.277709-3.475685 150.339176 150.339176 0 0 1-28.879783-14.029128c-13.46038-7.646507-28.6902-16.304122-38.232535-16.304123s-24.772155 8.657615-37.916564 16.304123a151.666255 151.666255 0 0 1-28.816588 14.029128c-32.355468 8.973587-67.681066 0.315971-97.003209-23.950629-34.567267-28.627006-54.789435-73.178968-51.376944-113.749692 2.2118-26.667983 16.051345-69.5137 28.184645-107.051098 7.39373-22.813133 14.3451-44.235991 17.820785-59.5922 18.642311-79.940755 86.260183-135.741298 164.30511-135.741298h9.984695c79.056036 0 146.610713 55.800543 164.30511 135.804493 3.538879 15.798568 10.806221 37.916564 18.452728 61.993582 12.638855 38.548507 25.277709 78.487287 27.615897 104.586521 3.412491 40.444335-16.809677 84.996297-51.376944 113.749692a112.485806 112.485806 0 0 1-71.346334 27.426314z m-22.117996-15.735374c28.753394 8.025673 59.023451 0.379166 85.438658-21.422858 31.597137-26.03604 49.923476-66.353987 46.826956-102.753888-2.085411-24.645766-15.356208-65.65885-27.047149-101.74278-7.772896-24.077018-15.103431-46.763762-18.958282-63.194273C679.306838 206.708467 616.618119 155.015552 543.565539 155.015552h-9.984695c-72.231054 0-134.73019 51.75611-151.666255 125.882992C377.996544 297.013083 370.918785 318.499136 363.335473 341.249074c-11.943718 37.031844-25.277709 78.992841-27.615898 104.270551-3.033325 36.399901 15.293014 76.654653 46.763762 102.690693 26.415206 21.802024 56.874846 29.511725 85.501852 21.422859a132.707973 132.707973 0 0 0 25.972846-12.638855c15.545791-8.847198 31.597137-17.947174 44.235991-17.947173s28.942977 9.099975 44.235991 17.947173a139.469761 139.469761 0 0 0 26.036041 12.638855z m0 0" fill="#7F0518" ></path><path d="M601.641076 310.157492A42.087386 42.087386 0 1 0 622.431992 273.757591a42.087386 42.087386 0 0 0-21.043693 36.399901z m0 0" fill="#7F0518" ></path><path d="M613.711182 301.626265a19.400642 19.400642 0 1 0 19.400642-19.400642 19.463836 19.463836 0 0 0-19.400642 19.400642z m0 0M649.099975 329.874105a8.910392 8.910392 0 1 0 8.910393-8.847198 8.847198 8.847198 0 0 0-8.910393 8.847198z m0 0" fill="#FFFFFF" ></path><path d="M391.39373 310.157492a42.087386 42.087386 0 1 0 42.024192-42.087386 42.087386 42.087386 0 0 0-42.024192 42.087386z m0 0" fill="#7F0518" ></path><path d="M403.463836 301.626265a19.400642 19.400642 0 1 0 19.400642-19.400642 19.400642 19.400642 0 0 0-19.400642 19.400642z m0 0M439.1686 329.874105a8.847198 8.847198 0 1 0 8.847199-8.847198 8.847198 8.847198 0 0 0-8.847199 8.847198z m0 0" fill="#FFFFFF" ></path><path d="M617.186867 249.806961a6.319427 6.319427 0 0 1-3.981239-1.390274 6.319427 6.319427 0 0 1-0.947914-8.973587 42.59294 42.59294 0 0 1 28.121452-14.597877 45.373488 45.373488 0 0 1 34.124907 13.965935 6.319427 6.319427 0 0 1-8.594421 9.415946A32.924216 32.924216 0 0 0 641.390274 237.547272a30.522834 30.522834 0 0 0-18.958282 9.984695 6.319427 6.319427 0 0 1-4.992347 2.274994z m0 0M464.44631 249.806961a6.319427 6.319427 0 0 1-4.297211-1.643051 32.734633 32.734633 0 0 0-24.456184-10.679832 30.143668 30.143668 0 0 0-19.337447 10.047889 6.319427 6.319427 0 0 1-9.858307-8.088867 42.782523 42.782523 0 0 1 28.121452-14.597877 45.689459 45.689459 0 0 1 34.188101 13.965935 6.319427 6.319427 0 0 1 0 9.036781 6.319427 6.319427 0 0 1-4.676376 1.959022z m0 0" fill="#7F0518" ></path><path d="M624.643792 491.651444c0 9.352752 11.627746 16.999259 25.909652 16.99926s25.909652-7.646507 25.909652-16.99926-11.627746-16.999259-25.909652-16.999259-25.909652 7.583313-25.909652 16.999259z m0 0" fill="#DB1616" ></path><path d="M650.553444 515.033325c-18.073562 0-32.292274-10.300667-32.292274-23.381881s14.218711-23.381881 32.292274-23.381881 32.292274 10.300667 32.292273 23.381881-14.218711 23.381881-32.292273 23.381881z m0-34.061713c-11.248581 0-19.590225 5.62429-19.590225 10.679832s8.341644 10.616638 19.590225 10.616638 19.590225-5.62429 19.590224-10.616638-8.404838-10.679832-19.590224-10.679832z m0 0" fill="#7F0518" ></path><path d="M394.174278 491.651444c0 9.352752 11.564552 16.999259 25.909652 16.99926s25.909652-7.646507 25.909652-16.99926-11.627746-16.999259-25.909652-16.999259-25.909652 7.583313-25.909652 16.999259z m0 0" fill="#DB1616" ></path><path d="M420.210318 515.033325c-18.136756 0-32.292274-10.300667-32.292273-23.381881s14.155517-23.381881 32.292273-23.381881 32.292274 10.300667 32.292274 23.381881-14.3451 23.381881-32.292274 23.381881z m0-34.061713c-11.248581 0-19.590225 5.62429-19.590224 10.679832s8.341644 10.616638 19.590224 10.616638 19.590225-5.62429 19.590225-10.616638-8.468033-10.679832-19.590225-10.679832z m0 0" fill="#7F0518" ></path><path d="M472.092817 201.842508a43.098494 43.098494 0 0 0 13.586768-9.731918 21.170081 21.170081 0 0 1 14.78746-6.319427c6.95137 0.631943 12.006912 7.330536 18.199951 10.995803a23.192298 23.192298 0 0 0 25.783263-1.959022c4.360405-3.475685 7.83609-8.657615 13.207603-9.795113 7.267341-1.453468 13.397186 5.245125 19.400642 9.731918 15.293014 11.501358 45.247099 7.330536 52.19847-4.044433C635.070847 180.925204 635.070847 170.245372 628.751419 164.30511s-14.534683-6.319427-18.958282-13.081215a58.075537 58.075537 0 0 1-4.234016-11.501357c-7.014564-19.779807-18.958282-6.95137-26.099235-18.958282-1.895828-3.286102 0.505554-9.16317-6.888175-15.22982-5.434707-4.549988-24.645766 7.39373-35.009628-10.237472-3.033325 8.784004-14.597877 13.649963-20.032584 15.545791-9.668724 3.538879-16.746482-5.687485-24.708961 1.200691-5.245125 4.486793-4.992348 13.01802-7.772895 19.590225-6.319427 14.913848-18.010368 5.62429-29.954086 14.913848a29.890891 29.890891 0 0 0-10.869415 20.664527 37.916564 37.916564 0 0 0 3.791657 20.980499c3.475685 6.319427 16.620094 16.367317 23.761046 13.965934z m0 0" fill="#DB1616" ></path><path d="M469.817823 208.541101a37.916564 37.916564 0 0 1-27.047149-17.568008 43.667243 43.667243 0 0 1-4.549988-24.329795 36.273513 36.273513 0 0 1 13.333992-25.277709 32.165885 32.165885 0 0 1 17.947173-6.319428c5.687485-0.695137 7.899284-0.88472 10.111084-6.319427a37.095038 37.095038 0 0 0 1.895828-6.319427 26.983955 26.983955 0 0 1 7.583313-15.545791 18.958282 18.958282 0 0 1 18.958282-2.843743 12.638855 12.638855 0 0 0 8.088867 0.568749c12.070106-4.423599 15.356208-9.226364 16.177734-11.627746a6.319427 6.319427 0 0 1 11.501357-1.137497c4.423599 7.456924 10.237472 7.456924 19.274254 6.319427a18.326339 18.326339 0 0 1 14.3451 2.2118 21.043693 21.043693 0 0 1 8.088867 15.419402 6.824981 6.824981 0 0 0 0 1.706246c1.32708 2.148605 2.464577 2.401382 6.319427 2.97013a21.675636 21.675636 0 0 1 20.095779 16.936066c0.44236 1.263885 0.821526 2.527771 1.263885 3.85485a25.846458 25.846458 0 0 0 2.464577 6.319427 17.694396 17.694396 0 0 0 7.583313 5.308319 37.916564 37.916564 0 0 1 10.174278 6.319428c8.341644 8.27845 8.847198 21.991607 1.453468 34.188101a32.481856 32.481856 0 0 1-22.497161 12.638855 51.629721 51.629721 0 0 1-38.990867-6.95137l-3.728462-2.906937c-3.791656-3.159714-7.709701-6.319427-10.616638-5.750678A17.694396 17.694396 0 0 0 552.918292 195.902246c-1.32708 1.32708-2.717354 2.654159-4.170822 3.854851a29.448531 29.448531 0 0 1-33.050605 2.464577 56.874846 56.874846 0 0 1-7.014564-5.118736 19.779807 19.779807 0 0 0-8.72081-5.118737 15.988151 15.988151 0 0 0-10.047889 5.055542l-2.022217 1.832634a39.496421 39.496421 0 0 1-13.649963 9.099976 18.199951 18.199951 0 0 1-4.486794 0.568748z m2.274994-6.698593z m27.80548-86.323377a3.412491 3.412491 0 0 0-2.590965 1.074303 17.315231 17.315231 0 0 0-3.53888 8.720809 59.844977 59.844977 0 0 1-2.527771 8.468033A21.612441 21.612441 0 0 1 470.765737 147.495433a20.917304 20.917304 0 0 0-11.627746 3.791657 23.571464 23.571464 0 0 0-8.404839 15.861762 32.039496 32.039496 0 0 0 2.970131 17.631202c2.843742 5.245125 13.270797 11.817329 16.11454 10.995804a30.586028 30.586028 0 0 0 9.226364-6.319427l2.211799-1.895829a26.983955 26.983955 0 0 1 19.527031-8.152061 29.57492 29.57492 0 0 1 15.608985 7.962479 48.406813 48.406813 0 0 0 5.245125 3.85485A16.746482 16.746482 0 0 0 540.279437 189.582819c1.137497-0.947914 2.274994-2.022217 3.286102-3.033325a26.225623 26.225623 0 0 1 12.638855-8.088867c8.910392-1.832634 15.67218 3.791656 21.29647 8.341644 1.074303 0.821526 2.148605 1.76944 3.286102 2.590965a38.485312 38.485312 0 0 0 28.942977 4.676376 21.233276 21.233276 0 0 0 13.965935-6.888175 15.482597 15.482597 0 0 0 0.505554-18.642311A25.277709 25.277709 0 0 0 617.37645 164.30511a29.006171 29.006171 0 0 1-12.638854-10.04789 38.674895 38.674895 0 0 1-3.791657-9.415946 24.013824 24.013824 0 0 0-1.011108-3.222908c-2.654159-7.583313-5.055542-7.899284-9.795112-8.531227a18.958282 18.958282 0 0 1-15.798569-9.352752 14.913848 14.913848 0 0 1-1.832634-6.319428 8.910392 8.910392 0 0 0-3.665267-7.204147 27.615897 27.615897 0 0 1-4.802765 0.695137 31.597137 31.597137 0 0 1-25.277709-5.245125 48.406813 48.406813 0 0 1-18.389534 10.93261 25.277709 25.277709 0 0 1-15.67218 0 22.117996 22.117996 0 0 0-4.423599-0.88472z m0 0M758.236485 447.415453a102.437917 102.437917 0 0 1-37.916564-7.204147 6.319427 6.319427 0 1 1 5.245125-11.690941c9.16317 4.107628 35.767959 10.300667 55.421377 2.085411a36.336707 36.336707 0 0 0 20.664527-21.991607 24.708961 24.708961 0 0 0-28.437422-32.481856 15.545791 15.545791 0 0 0-9.668724 8.404838 9.921501 9.921501 0 0 0 1.453468 12.638855 11.185386 11.185386 0 0 0 13.523574-1.074303 6.319427 6.319427 0 1 1 9.16317 8.784004 23.634658 23.634658 0 0 1-31.597136 1.579857 22.560355 22.560355 0 0 1-4.044434-27.868674 28.374229 28.374229 0 0 1 17.378425-14.597877 37.347815 37.347815 0 0 1 43.92002 49.038755A48.533202 48.533202 0 0 1 785.915576 442.359911a72.547025 72.547025 0 0 1-27.679091 4.992348z m0 0M318.34115 447.857813a71.28314 71.28314 0 0 1-27.615897-4.992348 48.975562 48.975562 0 0 1-27.679092-29.385337 37.41101 37.41101 0 0 1 44.235992-49.10195 28.437423 28.437423 0 0 1 17.062453 14.78746 22.560355 22.560355 0 0 1-3.981239 27.868675 23.697852 23.697852 0 0 1-31.597136-1.579857 6.319427 6.319427 0 1 1 9.226363-8.847199 11.122192 11.122192 0 0 0 13.460381 1.137497 9.984695 9.984695 0 0 0 1.516662-12.638854 15.22982 15.22982 0 0 0-9.668724-8.341644 23.697852 23.697852 0 0 0-17.252036 2.527771A24.077018 24.077018 0 0 0 274.86349 409.056529a36.210318 36.210318 0 0 0 20.601334 22.054802c19.653419 8.27845 46.321402 2.085411 55.421377-2.085411a6.319427 6.319427 0 0 1 8.404838 3.222907 6.319427 6.319427 0 0 1-3.222908 8.468033 101.110837 101.110837 0 0 1-37.916563 7.140953z m0 0" fill="#7F0518" ></path></symbol><symbol id="icon-shengxiaoshu" viewBox="0 0 1024 1024"><path d="M716.732709 349.912929a137.497837 137.497837 0 0 1-16.374131-1.06544c-35.776354-4.822518-46.48683-14.804009-49.683149-20.299436a11.215158 11.215158 0 0 1-1.457971-8.467444 5.607579 5.607579 0 0 0-0.280379-5.215049c-1.457971-2.803789-35.944581-66.001205 16.822737-107.889819a72.898527 72.898527 0 0 1 45.701769-17.607798c34.262308 0 66.505887 30.393078 76.655605 72.281693 5.607579 24.11259 2.074804 46.318602-10.542249 62.412354s-34.823066 25.850939-60.954384 25.850939z m0 0" fill="#DB1616" ></path><path d="M711.573736 195.368052c31.458518 0 61.234763 28.486501 70.823723 67.739554 5.607579 22.430316 2.018728 42.6176-9.532884 57.253382s-31.907124 23.495756-56.07579 23.495756a115.628279 115.628279 0 0 1-15.58907-1.06544c-33.309019-4.429987-42.449373-13.233886-44.860632-16.822737a8.52352 8.52352 0 0 1-1.401894-3.757078 9.757187 9.757187 0 0 0-0.616834-10.486173c-1.401895-2.467335-33.645474-61.290838 15.364766-100.039209a67.571327 67.571327 0 0 1 42.000767-16.374131m0-12.056294a79.403319 79.403319 0 0 0-49.458847 18.897541c-57.589836 45.645693-18.392859 115.516127-18.392859 115.516127s-11.215158 28.037895 56.07579 37.010021a131.273424 131.273424 0 0 0 17.215268 1.177592c57.14123 0 90.674552-41.15963 77.38459-95.721373-10.430097-42.449373-43.570889-76.879908-82.599639-76.879908z m0 0" fill="#7F0518" ></path><path d="M362.165489 349.912929c-26.24347 0-47.832649-9.19643-60.954383-25.850939S284.780899 285.986529 290.612781 261.649636c10.205794-41.888615 42.449373-72.281693 76.711681-72.281693a72.898527 72.898527 0 0 1 45.701769 17.607798c52.935546 42.000767 18.392859 105.142106 16.822737 107.833744a5.607579 5.607579 0 0 0 0 5.215048 11.215158 11.215158 0 0 1-1.570122 8.803899c-3.364547 5.607579-14.243251 15.252615-49.458847 20.019057a139.180111 139.180111 0 0 1-16.430207 1.06544z m0 0" fill="#DB1616" ></path><path d="M367.324462 195.368052A67.290948 67.290948 0 0 1 409.43738 211.742183c48.729861 38.524068 16.822737 97.62795 15.420842 100.039209a8.747823 8.747823 0 0 0-0.841136 9.925415 5.607579 5.607579 0 0 1-1.233668 4.373911c-2.411259 3.532775-11.607689 12.280598-44.860632 16.822737a124.880784 124.880784 0 0 1-15.589069 1.06544c-24.336893 0-44.299874-8.299217-56.07579-23.495756s-14.860084-34.935217-9.476809-57.253381c9.532884-39.253053 39.253053-67.79563 70.823723-67.79563m0-12.056295c-39.253053 0-72.225617 34.430535-82.543563 76.935984-13.233886 54.561744 20.299436 95.721373 77.38459 95.721373a141.647445 141.647445 0 0 0 17.159192-1.177591c67.290948-9.028202 56.07579-37.010021 56.07579-37.010022s39.253053-69.870434-18.392859-115.516127a79.51547 79.51547 0 0 0-49.514923-18.953617z m0 0" fill="#7F0518" ></path><path d="M662.227041 316.996441s-26.411697-37.907234 4.149609-67.290948 67.290948-7.570232 78.954712 25.907015-9.813263 60.842232-49.01024 59.440337-34.09408-18.056404-34.094081-18.056404z m0 0" fill="#FF8A15" ></path><path d="M699.124911 341.221182h-2.972017c-18.897541-0.672909-31.402442-4.990745-37.010021-12.841356A16.261979 16.261979 0 0 1 656.170856 318.510487c-9.757187-15.532994-19.738678-48.169104 6.224413-72.898527a48.729861 48.729861 0 0 1 45.757844-14.243251c19.009693 4.542139 35.608127 20.860194 43.122283 42.561525a49.570998 49.570998 0 0 1-5.215049 47.047588c-9.757187 13.121735-26.636 20.523739-46.767209 20.523739z m-31.065988-22.710695a3.813154 3.813154 0 0 0 1.06544 3.084168c1.626198 1.962653 7.514156 6.841246 27.421062 7.514156 17.607798 0.560758 31.682821-4.878594 39.253053-15.589069a38.187613 38.187613 0 0 0 3.58885-35.944582c-6.112261-17.495646-19.682602-31.178139-34.486611-34.76699a36.505339 36.505339 0 0 0-34.598762 11.215158c-26.523849 25.514484-4.373912 58.094518-3.420623 59.496414a5.887958 5.887958 0 0 1 0.897212 4.990745z m0 0" fill="#7F0518" ></path><path d="M413.755216 316.996441s26.411697-37.907234-4.149608-67.290948S342.146432 242.135261 330.931274 275.612508 340.464159 336.45474 379.661136 335.164996s34.09408-18.168556 34.09408-18.168555z m0 0" fill="#FF8A15" ></path><path d="M376.857346 341.221182c-20.075133 0-37.010021-7.402004-46.655057-20.523739a49.68315 49.68315 0 0 1-5.271124-47.047588c7.570232-21.701331 24.056514-38.019386 43.122282-42.561525a48.505558 48.505558 0 0 1 45.757845 14.243251c25.963091 25.009802 15.9816 57.645912 6.224413 72.898527a16.149828 16.149828 0 0 1-3.084169 9.813263c-5.607579 7.850611-18.056404 12.168446-37.066097 12.841356z m1.73835-99.310224a33.140792 33.140792 0 0 0-7.738459 0.897212c-14.860084 3.588851-28.430425 17.215268-34.542687 34.76699a38.019386 38.019386 0 0 0 3.588851 35.944582c7.850611 10.710476 21.925634 16.318055 39.253053 15.589069 19.906905-0.672909 25.850939-5.607579 27.421061-7.514156a4.149608 4.149608 0 0 0 1.121516-3.140244 5.607579 5.607579 0 0 1 0.841137-4.878594c1.009364-1.401895 22.991074-34.09408-3.364548-59.496413a38.860522 38.860522 0 0 0-26.860303-12.168446z m0 0" fill="#7F0518" ></path><path d="M726.882427 442.99874c0 95.777449-86.300641 135.254805-192.844642 135.254806S341.193144 538.664038 341.193144 442.99874s86.300641-211.630031 192.844641-211.630031S726.882427 347.10914 726.882427 442.99874z m0 0" fill="#DB1616" ></path><path d="M534.093861 584.141504C409.43738 584.141504 335.193034 531.262034 335.193034 442.99874c0-98.525163 88.7119-217.574065 198.900827-217.574064S732.994688 344.30535 732.994688 442.99874c0 88.487597-74.412573 141.310991-198.900827 141.310991z m0-346.716609c-103.459832 0-186.844532 112.15158-186.844532 205.461694 0 116.637643 130.656591 128.974317 186.844532 128.974317s186.844532-12.560977 186.844532-128.974317c0-93.085811-83.3847-205.461694-186.844532-205.461694z m0 0" fill="#7F0518" ></path><path d="M509.644817 440.587482c0 9.420733 10.934779 16.822737 24.392968 16.822736s24.392969-7.626307 24.392969-16.822736-10.934779-16.822737-24.392969-16.822737-24.392969 7.682383-24.392968 16.822737z m0 0M572.954384 363.371119a36.22496 36.22496 0 1 0 36.22496-36.224961 36.22496 36.22496 0 0 0-36.22496 36.224961z m0 0" fill="#7F0518" ></path><path d="M583.272329 356.02519a16.822737 16.822737 0 1 0 16.822737-16.822737 16.822737 16.822737 0 0 0-16.822737 16.822737z m0 0M613.833635 380.306007a7.570232 7.570232 0 0 0 3.757077 6.616944 7.570232 7.570232 0 0 0 11.215158-6.560868 7.514156 7.514156 0 0 0-3.757077-6.560867 7.570232 7.570232 0 0 0-11.215158 6.560867z m0 0" fill="#FFFFFF" ></path><path d="M422.727342 363.371119a36.22496 36.22496 0 1 0 36.224961-36.224961 36.22496 36.22496 0 0 0-36.224961 36.224961z m0 0" fill="#7F0518" ></path><path d="M433.157439 356.02519a16.822737 16.822737 0 1 0 16.822737-16.822737 16.822737 16.822737 0 0 0-16.822737 16.822737z m0 0M463.606593 380.306007a7.514156 7.514156 0 0 0 3.813154 6.616944 7.345928 7.345928 0 0 0 7.570232 0 7.570232 7.570232 0 0 0 0-13.121735 7.626307 7.626307 0 0 0-11.215158 6.560867z m0 0" fill="#FFFFFF" ></path><path d="M582.543344 310.043043a6.112261 6.112261 0 0 1-4.878594-9.925415 37.907234 37.907234 0 0 1 24.617272-12.78528 39.589508 39.589508 0 0 1 29.83232 12.168446A6.056185 6.056185 0 1 1 624.15158 308.416845a28.37435 28.37435 0 0 0-20.748042-9.028203 25.346257 25.346257 0 0 0-16.093752 8.411369 6.168337 6.168337 0 0 1-4.766442 2.299107z m0 0M439.94261 310.043043a6.168337 6.168337 0 0 1-3.813154-1.401895 6.056185 6.056185 0 0 1-0.841137-8.52352A37.907234 37.907234 0 0 1 459.905591 287.332348a39.645583 39.645583 0 0 1 29.888396 12.168446A6.056185 6.056185 0 0 1 481.550846 308.416845a28.37435 28.37435 0 0 0-20.748042-9.028203 25.346257 25.346257 0 0 0-16.093752 8.411369 6.448716 6.448716 0 0 1-4.766442 2.299107z m0 0M508.13077 499.07453a30.50523 30.50523 0 0 1-5.607578-0.504682 40.206341 40.206341 0 0 1-25.794864-20.748042 6.00011 6.00011 0 0 1 2.691638-8.074914 6.112261 6.112261 0 0 1 8.13099 2.691638 28.318274 28.318274 0 0 0 16.822737 14.075023c6.953398 1.233667 14.747933-1.738349 23.159301-8.859974v-29.43979a6.056185 6.056185 0 1 1 12.11237 0v32.187503a6.056185 6.056185 0 0 1-1.962652 4.486064A45.701769 45.701769 0 0 1 508.13077 499.07453z m0 0" fill="#7F0518" ></path><path d="M560.000876 499.07453a45.869996 45.869996 0 0 1-30.000547-13.962871 6.056185 6.056185 0 1 1 8.411368-9.084278c9.252505 8.411368 17.71995 11.944143 25.17803 10.542248a28.542577 28.542577 0 0 0 16.822737-14.075023 6.056185 6.056185 0 1 1 10.822627 5.607579c-0.336455 0.672909-8.859975 17.439571-25.626636 20.579815a36.449263 36.449263 0 0 1-5.607579 0.448606z m0 0M691.106073 455.615793a6.00011 6.00011 0 0 1-5.944034-4.822518 6.112261 6.112261 0 0 1 4.710367-7.121625L751.499699 431.391052a6.056185 6.056185 0 1 1 2.411259 11.831992l-61.683369 12.280598a4.598215 4.598215 0 0 1-1.177592 0z m61.683369 18.280708h-62.356278a6.056185 6.056185 0 0 1 0-12.056295h62.636657a6.056185 6.056185 0 0 1 0 12.056295z m-2.915941 33.309019h-1.289743l-61.234763-12.953508a6.056185 6.056185 0 0 1-4.65429-7.121625 6.00011 6.00011 0 0 1 7.121625-4.65429l61.683369 12.841355a6.00011 6.00011 0 0 1 4.65429 7.121626 5.887958 5.887958 0 0 1-5.607579 4.766442z m0 0M378.371393 455.615793h-1.233668l-61.346914-12.336674a6.056185 6.056185 0 1 1 2.411259-11.831991l61.683369 12.280598a5.944034 5.944034 0 0 1 4.710366 7.121625 6.112261 6.112261 0 0 1-5.944033 4.766442z m0.560757 18.280708H316.407645a6.056185 6.056185 0 1 1 0-12.056295h62.580581a6.056185 6.056185 0 0 1 6.056186 6.056185 6.112261 6.112261 0 0 1-6.112262 6.00011z m-59.66464 33.309019a6.168337 6.168337 0 0 1-5.944034-4.766442 5.944034 5.944034 0 0 1 4.654291-7.121626L379.212529 482.251793a6.00011 6.00011 0 0 1 2.467335 11.775916l-61.234762 13.065659h-1.177592z m0 0" fill="#7F0518" ></path></symbol><symbol id="icon-shengxiaoma" viewBox="0 0 1024 1024"><path d="M822.72 338.8416c-0.1664-0.256-0.3072-0.4992-0.3328-0.7936-3.0208-32.8064-20.3904-77.9264-62.5408-118.336-0.2432-0.2432-0.4224-0.5504-0.4736-0.896-7.2192-44.7744 36.8128-95.3088 83.392-159.5392 0.768-1.0624-0.0768-2.5856-1.3824-2.5088-115.6352 7.5136-150.4512 87.1168-155.7632 101.312-0.3712 0.9984-1.6 1.3056-2.4192 0.6144-5.5552-4.7488-25.6128-18.8032-68.032-18.8032-44.1984 0-72.6528 15.2704-79.4752 19.3536-0.832 0.4992-1.8688 0.128-2.2016-0.7808-4.8-13.056-39.1808-94.1056-155.904-101.696-1.3056-0.0896-2.1504 1.4464-1.3824 2.5088 46.5792 64.2304 90.5984 114.752 83.392 159.5392-0.0512 0.3328-0.2304 0.6528-0.4736 0.896-42.1504 40.4096-59.5328 85.5296-62.5408 118.336-0.0256 0.3072-0.1408 0.5632-0.3328 0.7936-18.3808 21.4912-45.0048 71.7056-9.4848 155.4176 0.064 0.1408 4.928 1.9968 4.9408 2.1504 7.7568 89.9584 20.3904 158.8992 81.3184 227.5968 0.0384 0.0512 0.0768 0.0896 0.1152 0.1408 10.2784 14.5664 25.0752 48.7936 34.7392 78.1184 12.4544-1.984 26.3296 0.9472 39.488 8.7936 40.6912 24.2176 41.664 20.3392 64.9088 21.312 32.7424 1.3696 61.4016-31.296 98.9184-30.208 9.664-29.2992 24.384-63.4624 34.6624-78.0032 0.0384-0.0512 0.0768-0.0896 0.1152-0.1408 60.928-68.7104 73.3312-139.3536 81.088-229.312 0.0128-0.1536 0.0512-0.3072 0.1152-0.448 35.4944-83.6992 24.7552-112.1536-4.4544-155.4176z" fill="#E58339" ></path><path d="M565.1328 304.5504c-3.7248 17.0112-4.9408 35.5584-1.5616 54.784 13.568 77.3376 34.88 172.352 34.88 227.584s-20.3392 117.1072 12.1088 164.608c27.6096-44.1856 8.2304-119.3216 8.2304-161.2928 0-41.984 24.2176-165.7216 35.8528-219.8528 7.04-32.7936-1.2032-74.88-14.5024-107.6608-16.6016 30.1184-47.5136 37.9648-75.008 41.8304z" fill="#FFEAD9" ></path><path d="M658.7264 146.3296a5.0176 5.0176 0 0 0-1.4336-0.7168c-10.5088-3.2256-24.3072-5.7216-42.1248-5.7216-17.2032 0-31.9488 2.3296-44.032 5.3888-1.1648 0.2944-2.112 0.9984-2.752 1.9968-13.632 21.2224-36.1088 49.6512-63.1168 58.5984-4.8128 1.6-4.5696 8.3328 0.3584 9.4848 29.7216 6.9376 59.4432-0.832 71.4112-4.7232 2.8928-0.9344 5.9392 0.9728 6.2848 3.9936 2.8416 25.0624-9.024 60.48-37.0048 85.12-2.8672 2.5216-0.7936 7.2192 3.008 6.7584 40.0512-4.7872 97.4208-10.2784 102.528-88.3328 0.2816-4.3904 5.8752-6.144 8.6784-2.752 16.1024 19.4688 28.2624 37.76 33.1136 55.4368 1.28 4.672 7.8592 4.6464 9.3568 0.0512 10.3168-31.8976 14.8096-82.4576-44.2752-124.5824z" fill="#FFD6B8" ></path><path d="M380.0704 364.5184c-6.2592 13.8496-10.944 31.6288-10.7776 53.5552 30.4256 61.1456 78.3872 73.9328 97.9584 56.064 1.3312-66.7392-52.3008-96.4992-87.1808-109.6192zM753.9328 474.1376c18.9824 17.3312 64.6528 5.7984 95.1424-50.6752 0.3072-0.576 0.4864-1.2416 0.512-1.8816 0.6528-21.2992-3.2384-38.8224-8.8704-52.7616-0.8064-1.9968-3.1104-2.944-5.0944-2.1376-34.7264 14.1056-82.944 44.1344-81.6896 107.456z" fill="#FFFFFF" ></path><path d="M759.8464 219.712c9.088 8.704 16.96 17.6384 23.8464 26.6112 0.6016 0.7936 1.7536 0.832 2.3808 0.064 25.4336-31.3472 61.8752-92.7744 58.816-185.28-0.0512-1.472-1.9712-2.048-2.8416-0.8576-46.3104 63.7696-89.8688 114.0096-82.688 158.5664 0.064 0.3456 0.2304 0.6528 0.4864 0.896zM434.2784 247.616c7.104-9.408 15.3216-18.7776 24.8448-27.904 0.2432-0.2432 0.4224-0.5504 0.4736-0.896 7.1424-44.3392-35.9552-94.3104-82.0096-157.6448-0.9216-1.28-2.9568-0.4992-2.816 1.0752 11.3664 120.5504 38.0544 167.3856 57.2544 185.5744 0.6656 0.64 1.7024 0.5248 2.2528-0.2048z" fill="#E7D6BB" ></path><path d="M507.8528 802.2784c-9.664-29.3248-24.448-63.552-34.7392-78.1184-0.0384-0.0512-0.0768-0.0896-0.1152-0.1408-60.928-68.7104-73.5616-137.6384-81.3184-227.5968-0.0128-0.1536-4.8768-2.0096-4.9408-2.1504-35.52-83.712-8.896-133.9264 9.4848-155.4176 0.2048-0.2304 0.3072-0.4992 0.3328-0.7936 2.3552-25.6512 13.568-58.8288 38.464-91.4048-0.2432 0.32-0.512 0.64-0.7552 0.96-0.5504 0.7296-1.5872 0.8448-2.2528 0.2176-7.808-7.3984-16.8576-19.5456-25.6128-39.4624l-0.32 0.2176c-0.4736 0.32-0.8704 0.7296-1.1904 1.216-5.6832 8.704-10.9696 18.7136-15.5264 30.208-28.864 72.7936-74.8032 172.1216-187.5584 202.1376-3.6992 0.9856-4.2752 6.0416-0.9344 7.8976 35.1872 19.3792 65.408 18.6624 83.6096 15.1552 4.3136-0.832 6.912 4.608 3.5584 7.4496-27.0848 22.9632-86.976 69.4528-141.9136 82.432-4.1344 0.9728-4.416 6.7968-0.3968 8.1792 62.3616 21.4656 106.4192 14.1056 130.816 5.4784 4.2624-1.5104 7.5904 3.7632 4.4544 7.0144-21.6192 22.4768-33.5744 37.2096-64.7424 56.9472-36.8384 23.3216-73.664 57.1648-83.8784 122.56-0.6016 3.8528 3.2896 5.568 6.8992 4.0832 82.5216-33.9712 115.4304-108.8 110.5664-50.432-4.608 55.2832-26.6624 122.88-68.0064 153.3696-3.5584 2.624-1.3184 8.192 3.0592 7.6544 33.2288-4.0832 102.592-17.3824 147.5712-59.5072 2.7392-2.56 7.2576-0.6016 7.2064 3.1616-0.64 49.7536-32.448 98.7648-47.1936 118.8608-2.3808 3.2384 0.5888 7.6672 4.4928 6.6816 32.2432-8.1152 122.2016-33.5872 169.7408-75.4816 0.2432-37.4528 18.304-57.7408 41.1392-61.376z" fill="#FF9C4A" ></path><path d="M612.2624 832.384c38.72 1.6128 71.7312-44.3648 120.4608-25.8304 42.624 20.8256 53.44 137.2544-55.5392 153.7152-125.7216 18.9952-200.9728-8.6144-209.4848-79.872-8.4992-71.2576 38.9632-93.5424 79.6544-69.3248s41.6512 20.3392 64.9088 21.312z" fill="#E8D7BB" ></path><path d="M784.9216 262.1184h-0.2176c-5.1456-0.064-9.9072-2.4448-13.056-6.5408a220.8832 220.8832 0 0 0-22.3104-24.9088 16.82944 16.82944 0 0 1-4.9536-9.4464c-7.2192-44.8384 27.1488-91.2 66.9696-144.8832 6.016-8.1024 12.1856-16.4352 18.4192-25.0112 4.1856-5.7856 11.6096-8.256 18.4448-6.1696 6.848 2.0864 11.5968 8.2944 11.84 15.4368 3.2896 99.2384-37.5552 164.992-62.1952 195.3536a16.54144 16.54144 0 0 1-12.9408 6.1696z m10.816-25.024h0.0512-0.0512z m-21.44-0.2816c0 0.0128-0.0128 0.0128-0.0256 0.0256l0.0256-0.0256z m-0.4096-24.6016c3.6096 3.6096 7.1168 7.3216 10.496 11.136 17.1648-24.7808 37.5296-64.4096 43.6608-118.5408-30.8224 41.7408-56.0768 78.1952-54.1568 107.4048z m-3.584-3.4944l0.0384 0.0384-0.0384-0.0384z m84.0448-139.5584l-0.0256 0.0256c0.0128-0.0128 0.0128-0.0256 0.0256-0.0256zM433.0496 263.4112c-4.2368 0-8.3456-1.6256-11.456-4.5568-31.7312-30.08-52.5696-95.744-61.9392-195.1872-0.704-7.4752 3.712-14.5664 10.7392-17.2288 7.0272-2.6496 15.0144-0.2816 19.4432 5.7856 6.016 8.2688 11.968 16.2944 17.7664 24.1024 39.808 53.6832 74.2016 100.0448 66.9696 144.8832-0.5632 3.5328-2.304 6.8736-4.8896 9.3696-8.5376 8.192-16.3584 16.9728-23.296 26.1504v0.0128a16.73344 16.73344 0 0 1-11.9552 6.5792c-0.4608 0.0768-0.9216 0.0896-1.3824 0.0896z m1.2288-15.7952h0.0512-0.0512zM396.2752 112.0896c10.048 63.0016 24.6912 96.0256 36.5696 113.2288 3.9168-4.4928 8-8.8704 12.2496-13.1072 1.7792-27.4944-20.4928-61.4144-48.8192-100.1216z" fill="#333B44" ></path><path d="M864.576 408.4096c-0.1536-12.1344-2.1632-23.232-5.8752-34.0224-1.152-3.8144-2.432-7.5776-3.9168-11.2512-0.6656-1.6512-1.6-3.1104-2.6624-4.48-4.1088-8.3328-9.1392-16.7296-15.0144-25.5872-2.7008-22.5664-14.2848-72.1664-63.232-120.8576-2.0608-31.6032 27.6608-71.68 61.8624-117.7856 6.2976-8.4864 12.7744-17.2288 19.3024-26.24 3.7888-5.2224 4.2112-12.2496 1.088-17.92-3.1232-5.6576-9.2544-8.9984-15.744-8.64-101.888 6.6176-145.984 65.536-162.0864 96-6.7456-3.3792-15.6544-6.7456-26.8672-9.2032-0.4096-0.0896-0.8448-0.1664-1.2544-0.256-2.8544-0.6016-5.8624-1.1264-9.024-1.5872-0.896-0.128-1.792-0.2688-2.7008-0.384-2.752-0.3584-5.6448-0.64-8.6272-0.8704-0.9472-0.0768-1.856-0.1792-2.816-0.2304-3.776-0.2304-7.6928-0.384-11.84-0.384-4.1984 0-8.2688 0.128-12.2112 0.3712-0.0256 0-0.0512 0-0.0768 0.0128-4.0704 0.2432-7.9744 0.6144-11.7632 1.0752-0.5376 0.064-1.0496 0.1664-1.5872 0.2304-3.4176 0.448-6.7072 0.9472-9.8816 1.5232-0.7296 0.128-1.4464 0.2944-2.1632 0.4352-3.1616 0.6144-6.1952 1.28-9.088 1.9968-0.32 0.0768-0.6528 0.128-0.9728 0.2176-0.1152 0.0256-0.2304 0.0896-0.3456 0.128-10.2784 2.6368-18.9184 5.7472-25.5104 8.6144-15.424-30.208-59.1232-90.9312-163.008-97.6896-6.4384-0.4608-12.608 2.9824-15.7312 8.64-3.1232 5.6576-2.7008 12.6848 1.088 17.92 6.528 8.9984 13.0048 17.7408 19.3024 26.2272 34.1888 46.0928 63.9104 86.1696 61.8496 117.7856-4.3904 4.3648-8.384 8.7424-12.1984 13.1072-4.416-6.4128-8.6656-14.1696-12.5696-23.0528-1.8176-4.1472-5.5552-7.1424-9.9072-8.384-4.352-1.2288-9.1904-0.3456-12.928 2.2144a19.4432 19.4432 0 0 0-5.2736 5.4016c-6.5408 10.0224-12.2368 21.0944-16.9344 32.9088-33.5872 84.6976-78.3104 166.6944-177.344 193.0624-7.6928 2.048-13.2992 8.4992-14.2592 16.4224-0.9728 7.9488 2.9184 15.5776 9.92 19.4304 21.5424 11.8656 41.5232 16.9984 58.7008 18.496-28.992 21.8624-71.1424 49.3824-109.6192 58.4704-8.4992 2.0096-14.4896 9.216-14.9248 17.9456-0.4352 8.7296 4.8256 16.512 13.0816 19.3536 42.3808 14.5792 77.12 16.7424 104.0128 13.7344-9.8432 9.5104-20.5056 18.2912-36.672 28.5312-33.3312 21.12-79.0144 57.8816-90.752 133.0432-1.088 6.9632 1.4848 13.6704 6.8864 17.92 5.7088 4.4928 13.6832 5.4656 20.7872 2.5344 40.2048-16.5504 68.7488-41.728 87.6416-58.3936 0.4736-0.4096 0.9472-0.8448 1.4464-1.2672-5.3504 50.1888-25.9328 110.2464-61.3248 136.3328-7.1168 5.248-9.8048 14.6304-6.5408 22.8352s11.5968 13.1968 20.4544 12.1088c32.5632-3.9936 89.2544-15.1936 134.6304-46.3232-8.192 36.672-30.464 70.2336-41.152 84.7872-4.9152 6.7072-5.0944 15.488-0.4608 22.3872 3.6992 5.504 9.6768 8.6016 16.0384 8.6016 1.6128 0 3.2384-0.192 4.8768-0.6016 31.4368-7.9104 102.7712-28.3776 153.5488-61.8112 4.992 24.2816 17.3312 44.0832 36.8256 58.944 26.5216 20.2112 65.024 30.3488 114.9184 30.3488 22.2336 0 46.7456-2.0096 73.4592-6.0416 53.7728-8.128 90.24-41.408 97.536-89.0368 6.0928-39.7568-10.0736-79.8848-37.6064-93.3376-0.4096-0.2048-0.832-0.384-1.2672-0.5504-2.24-0.8448-4.4416-1.5872-6.6176-2.2144 8.8064-23.7184 19.1872-46.2208 26.3808-56.6912 64.8832-73.5104 76.6848-150.1696 84.096-235.2768 11.6736-27.776 18.4448-50.0608 21.2096-69.3504 0.896-2.1632 1.5104-4.4544 1.5872-6.7968 0.1536-4.5568 0.064-9.1008-0.1792-13.5808z m-30.3488 0.7936c0.0128 3.392-0.1792 6.9376-0.5504 10.6624-21.7216 37.888-46.1696 44.8256-53.3248 46.0416-4.1856 0.7168-7.9872 0.5888-11.0848-0.2816 2.1376-34.7008 22.6432-61.568 61.12-80.0512 2.0864 7.5136 3.3536 15.4112 3.84 23.6288z m-224.896 122.8928c-4.6464-35.7376-12.4288-76.8512-20.0448-117.0816-3.8528-20.3904-7.5008-39.6672-10.7648-58.2912-2.1888-12.48-2.3168-25.5232-0.384-38.8864 0.2944-0.0512 0.5888-0.128 0.8832-0.1792 1.8048-0.3456 3.6224-0.7168 5.44-1.1136 0.5504-0.1152 1.1008-0.2432 1.664-0.3712 2.112-0.4864 4.2368-0.9984 6.3744-1.5744l0.4224-0.1152c14.5664-3.9552 29.248-10.2016 41.7024-20.864 7.4368 26.944 9.472 53.6448 5.184 73.6-0.2816 1.2416-20.352 95.04-30.4768 164.8768z m-0.2304 174.3104c-2.6624-16.4992-1.9584-34.2912-0.384-52.7744 1.472 17.6256 2.2528 36.0192 0.384 52.7744z m41.4336-506.9312c-7.872 2.5472-13.2992 9.5104-13.8368 17.7408-0.9984 15.3216-4.0704 27.2384-8.8704 36.6464-0.3584 0.4992-0.704 0.9984-0.9984 1.5488-5.76 10.4576-13.824 17.6-23.1936 22.6432-0.0896 0.0384-0.1664 0.0896-0.256 0.128-1.1008 0.5888-2.2272 1.1392-3.3664 1.664-6.6944 3.0336-14.144 5.2608-22.2464 7.0016 17.0112-25.152 22.976-53.248 20.6336-73.9072-0.6784-5.9648-3.9808-11.2512-9.0368-14.5024a19.92064 19.92064 0 0 0-10.8032-3.1872c-2.0864 0-4.1728 0.32-6.208 0.9856-6.0032 1.9456-17.6128 5.184-31.4368 6.336 15.4112-12.6464 28.2624-29.0048 37.9008-43.4944 0.2048-0.0512 0.4096-0.0896 0.6144-0.1408 2.7264-0.6016 5.4656-1.152 8.2432-1.6128 0.0256 0 0.0384 0 0.064-0.0128 2.624-0.4352 5.2864-0.7808 7.9488-1.1008 0.7552-0.0896 1.5232-0.1664 2.304-0.2432 2.0864-0.2176 4.1728-0.384 6.2848-0.512 0.7808-0.0512 1.5488-0.1152 2.3424-0.1536 2.8416-0.1408 5.6832-0.2304 8.5632-0.2304 3.008 0 5.9392 0.1024 8.8192 0.256 0.7168 0.0384 1.408 0.0896 2.112 0.128 2.7264 0.1792 5.4144 0.4096 8 0.7424 0.0768 0.0128 0.1664 0.0128 0.2304 0.0256 2.7904 0.3584 5.4784 0.8064 8.1152 1.3184 0.3584 0.064 0.704 0.1408 1.0624 0.2048 2.5984 0.5376 5.12 1.1392 7.552 1.8432 0.0768 0.0256 0.1408 0.0384 0.2176 0.064 29.4144 21.4144 43.6096 46.4768 42.8544 76.0064-5.6576-9.1648-12.8768-18.9952-21.9008-29.9008-5.2992-6.3616-13.7984-8.832-21.7088-6.2848z m-242.9184-123.136c-0.0896-0.1024-0.1664-0.2176-0.2432-0.3328 81.664 16.9216 107.2384 75.0592 111.8976 87.744 1.6 4.3008 4.8896 7.6288 9.0496 9.4336-9.472 9.088-18.8928 15.3344-27.8144 18.2912-8.704 2.88-14.272 10.9312-13.8624 20.0448 0.4096 9.0752 6.656 16.5632 15.552 18.6368 24.9472 5.824 49.7024 2.4832 66.0096-1.3184-1.9328 18.4576-11.7504 41.8048-31.8976 59.5328-6.3104 5.5552-8.2432 14.4256-4.8128 22.0928 2.8672 6.4256 8.896 10.56 15.6928 11.1488-1.2928 13.7344-0.8448 27.2384 1.4592 40.3328 3.3024 18.8288 7.1424 39.0912 10.8416 58.688 11.6992 61.8624 23.808 125.8368 23.808 166.272 0 14.5536-1.4848 29.5936-3.0592 45.504-4.3136 43.648-8.768 88.768 17.8048 127.68 2.8288 4.1472 7.5264 6.6176 12.5312 6.6176h0.3072c5.12-0.1024 9.8432-2.7904 12.5568-7.1296 22.9888-36.7872 17.6384-89.2032 13.3504-131.3152-1.4464-14.1696-2.8032-27.5584-2.8032-38.016 0-37.6576 21.2352-150.208 35.5072-216.6656 6.5536-30.5664 1.7792-71.2064-12.7232-109.952 2.6368-5.8624 4.8896-12.3136 6.6048-19.5072 8.0896 11.6992 13.1584 21.7344 15.6416 30.7712 2.3424 8.5632 9.8944 14.464 18.7904 14.656 8.8576 0.2176 16.8832-5.4016 19.6608-13.952 13.632-42.1376 7.424-80.128-17.8304-111.7824 0.064-0.1408 0.1664-0.2688 0.2176-0.4096 4.7104-12.5952 30.5408-70.4896 111.7568-87.3728-0.0768 0.1024-0.1536 0.2048-0.2304 0.32-39.8208 53.6832-74.2016 100.0448-66.9696 144.8832 0.576 3.5712 2.3296 6.9248 4.9536 9.4464 39.808 38.1568 52.4288 76.4288 56.4352 98.2016-31.7696 13.4272-70.976 40.3072-96.3584 94.2464-42.0224 89.3184-31.4624 161.344-25.792 200.0256 0.3712 2.5216 0.7168 4.9024 1.024 7.1296 4.3008 30.8992-3.0336 129.2416-11.8912 164.5696-0.2816 0.1152-0.5504 0.2304-0.832 0.3456-0.8064 0.3328-1.6256 0.6528-2.432 0.9984-0.8576 0.3584-1.7024 0.7296-2.5472 1.1136-1.0624 0.4608-2.0992 0.9344-3.136 1.408-0.6272 0.2816-1.2416 0.576-1.856 0.8576-1.4848 0.6912-2.944 1.3952-4.3904 2.0864-0.128 0.064-0.2688 0.128-0.3968 0.192-1.792 0.8704-3.5584 1.7408-5.2864 2.5856-12.1088 5.9776-23.6672 11.5712-34.4064 12.6336-1.536 0.1536-3.0592 0.2048-4.5696 0.1664-3.3664-0.1408-6.272-0.1792-8.9216-0.2176h-0.192c-0.2176 0-0.4096-0.0128-0.6272-0.0128-2.2784-0.0384-4.288-0.064-6.208-0.2048-0.1792-0.0128-0.3456-0.0384-0.5248-0.0512-1.216-0.1024-2.4064-0.2304-3.6096-0.448-0.1792-0.0256-0.3712-0.0768-0.5504-0.1152-0.512-0.1024-1.024-0.192-1.5488-0.32l-0.128-0.0384c-7.1168-1.728-15.9232-6.144-35.4688-17.7792-1.472-0.8832-2.9696-1.7024-4.4672-2.4832-0.768-0.3968-1.5488-0.7552-2.3168-1.1264-8.8064-35.6992-16.064-133.376-11.7888-164.1472 0.3072-2.2144 0.6528-4.5952 1.024-7.1296 5.6704-38.6944 16.2304-110.7072-25.792-200.0256-25.8688-54.976-66.0352-81.9072-98.432-95.1168 0.0512-0.2944 0.1024-0.576 0.1536-0.8832 0.0384-0.2048 0.0768-0.4224 0.128-0.6272 0.32-1.5488 0.6656-3.1744 1.0752-4.8768 0.0256-0.0896 0.0384-0.1792 0.064-0.2688 0.8576-3.5712 1.9584-7.4496 3.3024-11.5712 0.2176-0.6528 0.4608-1.3312 0.6912-1.9968a143.1808 143.1808 0 0 1 2.6624-7.1936c0.256-0.6528 0.5376-1.3312 0.8064-1.9968 5.3248-12.9024 13.184-27.456 24.8704-42.7392 0.0256-0.0256 0.0384-0.0512 0.064-0.0768 0.0128-0.0128 0.0256-0.0384 0.0384-0.0512 0-0.0128 0.0128-0.0128 0.0128-0.0256 0.1152-0.1536 0.2304-0.3072 0.3456-0.4736 0-0.0128 0-0.0128 0.0128-0.0128s0.0128-0.0128 0.0128-0.0128c0.0512-0.064 0.0768-0.1536 0.1152-0.2176 6.208-8.0128 13.4272-16.1664 21.9392-24.32 2.624-2.5088 4.3776-5.8624 4.9536-9.4208 7.1808-44.8768-27.2-91.2384-67.008-144.9216z m104.0768 692.1472c-0.384-0.96-0.768-1.9328-1.1648-2.8928-0.3456-0.8448-0.6784-1.6896-1.024-2.5216-0.3968-0.96-0.7936-1.92-1.1904-2.8672-0.3584-0.8448-0.704-1.6768-1.0624-2.5216-0.4096-0.9728-0.8192-1.9328-1.2416-2.8928-0.3456-0.7936-0.6784-1.6-1.024-2.3936-0.4992-1.1392-0.9984-2.2656-1.5104-3.392l-0.8064-1.8048c-0.7424-1.6512-1.4976-3.2768-2.2528-4.8768-0.32-0.6656-0.6272-1.3184-0.9472-1.9712-0.4736-0.9728-0.9344-1.9584-1.408-2.9056-0.3456-0.6912-0.6784-1.3696-1.024-2.048-0.448-0.896-0.896-1.792-1.344-2.6624-0.3456-0.6656-0.6784-1.3184-1.024-1.9584-0.448-0.8576-0.896-1.6896-1.344-2.5088-0.3328-0.6272-0.6784-1.2288-1.0112-1.8432-0.4608-0.8192-0.9088-1.6128-1.3568-2.3936-0.32-0.5504-0.64-1.1008-0.9472-1.6384-0.4992-0.832-0.9856-1.6256-1.4848-2.4192-0.2688-0.4224-0.5248-0.8704-0.7936-1.28-0.7552-1.1648-1.4976-2.2784-2.2272-3.3152-0.1792-0.2432-0.4736-0.6272-0.6528-0.8704-0.1664-0.2048-0.32-0.3968-0.4992-0.5888-54.9504-61.952-69.2352-122.304-77.5296-218.5216-0.4608-6.9376-4.6464-10.496-8.3328-12.5056-0.7552-1.8816-1.4464-3.7376-2.1376-5.5808 12.0064 9.536 24.9728 15.8336 38.2848 18.3168 3.84 0.7168 7.6032 1.0624 11.2896 1.0624 12.288 0 23.424-3.9424 31.5648-11.3664 3.072-2.8032 4.864-6.7456 4.9408-10.9056 1.024-51.968-26.9568-92.224-81.0112-117.3376 0.2176-0.32 0.4224-0.6144 0.64-0.9216 27.0336 11.0848 60.5312 33.6768 82.2528 79.8592 38.1312 81.0368 28.4416 147.1744 23.232 182.6944-0.384 2.6112-0.7424 5.0688-1.0624 7.3472-3.904 28.0704 0.2816 100.0192 7.232 147.584-0.3456-0.896-0.6912-1.792-1.0496-2.7008-0.32-0.7936-0.64-1.6256-0.9728-2.4576z m-122.8672-383.8592c39.744 18.4832 60.9152 45.6576 63.0912 81.0112-3.2512 0.9216-7.2704 0.9984-11.6992 0.1792-7.6288-1.4208-33.7536-9.3056-55.7184-51.3536 0.192-10.4832 1.6384-20.4672 4.3264-29.8368z m-33.9584 429.1584c0.1024-7.7952-4.4544-14.8736-11.5968-18.0224-2.5344-1.1264-5.2224-1.664-7.872-1.664-4.8384 0-9.6 1.8048-13.2864 5.2608-30.1056 28.1984-73.2416 42.56-105.7152 49.7664 30.144-38.9632 45.0048-95.8208 48.6016-138.944 0.9728-11.6608 2.4448-29.2736-11.0464-36.0576-13.2352-6.6432-24.3968 3.2-41.3056 18.112-14.208 12.5312-34.368 30.3104-60.6592 44.3648 13.7984-48.3712 45.3504-73.9328 72.4224-91.072 28.4544-18.0096 41.9968-32.3072 59.136-50.4064 2.6752-2.816 5.4528-5.76 8.4224-8.8448a19.42656 19.42656 0 0 0 2.3424-24.0768c-4.9024-7.6032-14.2848-10.7776-22.8096-7.7696-18.624 6.592-47.5904 11.6096-87.1552 3.6864 45.4912-19.52 88.8832-53.0048 113.5232-73.9072a19.45216 19.45216 0 0 0 4.9664-23.232c-3.8144-7.9616-12.5056-12.3392-21.2096-10.688-11.712 2.2528-28.2752 3.008-47.8848-2.7776 106.5984-42.7008 148.672-148.8 169.728-201.9072 0.7936-1.9968 1.6256-3.968 2.4704-5.9008 2.5088 3.84 5.1072 7.3984 7.7696 10.6496-4.1088 6.2208-7.7056 12.3136-10.8416 18.24-0.2176 0.4096-0.4352 0.8192-0.64 1.2288-1.1008 2.0992-2.1504 4.1728-3.136 6.2336-0.8192 1.7024-1.6128 3.3792-2.368 5.0432-0.3712 0.8192-0.704 1.6128-1.0496 2.4192-0.768 1.7792-1.5104 3.5328-2.2016 5.2608-0.192 0.4864-0.3968 0.9728-0.576 1.4592-6.6944 17.1008-9.6896 31.7312-10.9696 42.1376-4.6848 5.9392-10.1888 14.2208-15.0656 24.8192-0.2048 0.3584-0.448 0.6912-0.6144 1.0752-8.2048 18.1632-12.2752 38.3232-12.1088 59.9168 0 0.256 0.0768 0.512 0.0896 0.768 0.2432 22.9632 5.312 49.9968 18.5472 81.2032 1.152 2.7392 2.7776 4.608 4.544 5.9648 7.3856 81.536 20.1856 155.3024 83.8144 227.3664 0.512 0.7552 1.0496 1.5872 1.6 2.4576 0.1664 0.2688 0.3328 0.5504 0.512 0.832 0.384 0.64 0.7808 1.2928 1.1904 1.984 0.2048 0.3456 0.4096 0.7168 0.6144 1.0752 0.384 0.6784 0.7808 1.3824 1.1776 2.112 0.2048 0.384 0.4224 0.768 0.6272 1.152 0.4352 0.8064 0.8704 1.6256 1.3056 2.4832l0.5376 1.0368c0.6144 1.1904 1.2288 2.4192 1.856 3.6864 0.0128 0.0256 0.0256 0.064 0.0512 0.0896 0.6656 1.344 1.3312 2.7264 1.9968 4.1472 0.1408 0.2944 0.2816 0.6016 0.4224 0.896 0.5248 1.1136 1.0496 2.24 1.5744 3.392 0.2048 0.4352 0.4096 0.8832 0.6016 1.3312 0.4864 1.0624 0.96 2.1376 1.4464 3.2256 0.2048 0.4608 0.3968 0.9088 0.6016 1.3696 0.512 1.1776 1.0368 2.3808 1.5488 3.5968 0.1536 0.3712 0.32 0.7424 0.4736 1.1136 1.3824 3.264 2.7648 6.6176 4.1216 10.0352 0.064 0.1664 0.128 0.3328 0.192 0.4864 0.6016 1.5104 1.1904 3.0336 1.7792 4.5696 0.1536 0.4096 0.32 0.8192 0.4736 1.2288 0.512 1.3312 1.0112 2.6624 1.5104 4.0064 0.1664 0.4352 0.32 0.8704 0.4864 1.3056l0.576 1.5744c-2.0224 0.9984-4.0064 2.0864-5.9264 3.3408-3.5456 2.304-6.7584 5.0048-9.728 8-0.384 0.384-0.768 0.7808-1.152 1.1904-0.5888 0.6272-1.1648 1.2544-1.728 1.8944-0.7808 0.896-1.536 1.8304-2.2784 2.7904-0.1792 0.2432-0.3712 0.4608-0.5632 0.704-7.9232 10.5344-13.5936 24.8704-15.0912 43.6352 0 0.0256 0 0.0512-0.0128 0.0768-0.0512 0.6912-0.1408 1.3568-0.1792 2.0736-35.648 28.7104-93.44 49.2288-130.5984 60.3136 16.2944-26.9824 33.216-64.256 33.7152-102.912z m392.1024 67.8656c-3.0976 20.16-16.5632 55.232-72.0768 63.616-77.12 11.6736-134.3104 5.2864-165.44-18.432-15.5008-11.8144-24.2432-27.584-26.7008-48.2432-0.768-6.4384-0.9856-12.4672-0.7552-18.112 0.0256-0.512 0.0256-1.0368 0.0512-1.536 0.1408-2.6112 0.4096-5.1072 0.768-7.5136 0.0384-0.3072 0.0768-0.6144 0.128-0.9216 0.4096-2.5216 0.9344-4.9408 1.5744-7.2192 0.0384-0.1152 0.064-0.2304 0.0896-0.3456 0.6784-2.368 1.4848-4.5952 2.4192-6.6816l0.0384-0.0768c0.9472-2.0992 2.0096-4.0576 3.2128-5.8496 0.0128-0.0256 0.0384-0.0512 0.064-0.0896 1.1776-1.7536 2.4704-3.3408 3.8784-4.7744 0.0768-0.0768 0.1664-0.1536 0.2432-0.2304 1.3568-1.3568 2.8288-2.5472 4.3904-3.584 0.2816-0.1792 0.5632-0.3456 0.8448-0.512 0.768-0.4736 1.5488-0.896 2.3552-1.28 0.448-0.2176 0.8832-0.4352 1.344-0.6272 0.7296-0.3072 1.4848-0.5632 2.24-0.8064 0.8832-0.2816 1.792-0.5376 2.7136-0.7424 0.6912-0.1536 1.3696-0.32 2.0736-0.4224 0.7296-0.1152 1.472-0.1664 2.2016-0.2304 0.5888-0.0512 1.1776-0.0896 1.7792-0.1152 0.6656-0.0256 1.3312-0.0256 2.0096 0 1.4976 0.0384 3.008 0.1408 4.544 0.3584 0.4992 0.0768 1.0112 0.192 1.5232 0.2816 1.2672 0.2304 2.5344 0.512 3.8144 0.8704 0.5504 0.1536 1.1008 0.2816 1.6512 0.4608 1.6384 0.512 3.2768 1.1264 4.928 1.8432 0.4608 0.192 0.9216 0.4096 1.3824 0.6272 1.7792 0.832 3.5584 1.7152 5.3376 2.7776 36.5696 21.7728 44.9408 22.976 63.7568 23.232 2.4448 0.0384 5.1584 0.064 8.2816 0.192 0.896 0.0384 1.7792 0.064 2.6624 0.064 0.768 0 1.5104-0.0896 2.2784-0.1152 1.2544-0.0384 2.5216-0.0896 3.7632-0.2048 0.9216-0.0896 1.8432-0.2176 2.7648-0.3328 1.4464-0.192 2.88-0.384 4.3008-0.6528 0.6912-0.128 1.3696-0.2944 2.048-0.448 1.5872-0.3456 3.1616-0.704 4.7232-1.152 0.4992-0.1408 0.9856-0.3072 1.4848-0.4608 1.7024-0.512 3.392-1.0368 5.056-1.6256 0.3456-0.128 0.6784-0.2688 1.024-0.384 1.7792-0.6528 3.5584-1.3184 5.2992-2.048 0.2816-0.1152 0.5504-0.2432 0.832-0.3584 1.792-0.7552 3.5712-1.5232 5.3248-2.3296 0.7424-0.3456 1.472-0.6912 2.2144-1.0496 1.2544-0.5888 2.5216-1.1776 3.776-1.7792 2.048-0.9856 4.0832-1.9968 6.1184-2.9952 13.3376-6.5792 26.1376-12.8384 39.3344-14.0928 0.2432-0.0256 0.4864-0.0384 0.7168-0.064 1.7792-0.1408 3.5584-0.2176 5.3504-0.1664 5.12 0.1536 10.3808 1.1136 15.8976 3.1232 13.4016 7.0784 24.6784 33.0368 20.3648 61.1584z m64.9344-388.2368c-7.2192 83.6992-17.4848 153.088-77.312 220.544-0.1792 0.192-0.3328 0.384-0.4992 0.5888-0.192 0.2432-0.4736 0.6272-0.6528 0.8704-7.8848 11.1616-16.9216 30.2592-24.768 49.664 6.2336-47.2448 9.7152-112.5632 6.0416-138.9824-0.32-2.2912-0.6784-4.7488-1.0624-7.3472-5.2096-35.5328-14.8992-101.6704 23.232-182.7072 21.1072-44.864 53.3888-67.456 79.7568-78.8224 0.2176 0.3456 0.4352 0.6784 0.6528 1.024-52.4288 25.2032-79.5392 65.1392-78.528 116.1984 0.0768 4.16 1.8688 8.1024 4.9408 10.9056 8.2048 7.488 19.072 11.392 31.3088 11.392 3.3792 0 6.8608-0.2944 10.4192-0.896 10.0608-1.7024 19.9552-5.6832 29.44-11.5712-0.5632 1.3696-1.1136 2.7136-1.7024 4.1088-0.6272 1.4592-1.1264 3.4432-1.2672 5.0304z" fill="#333B44" ></path><path d="M554.6112 841.8176c-19.9936-2.624-36.6848 4.9792-44.6208 20.2752-7.7312 14.9376-5.2096 34.6368 6.0288 46.8352 10.8672 11.8016 31.7952 26.2272 43.3024 33.7792 3.0464 1.9968 6.5408 3.0208 10.048 3.0208 2.5344 0 5.0688-0.5248 7.4624-1.5872 5.7088-2.5472 9.6896-7.7568 10.6368-13.9264 2.9824-19.3408 5.7856-54.72-8.9728-74.3552-5.952-7.936-14.208-12.7872-23.8848-14.0416z m4.7744 64.0768c-9.5104-6.9248-16.96-13.0944-21.0432-17.536-2.6496-2.88-3.3024-8.6272-1.3952-12.3136 1.7792-3.4304 5.824-4.4032 9.8176-4.4032 1.344 0 2.6752 0.1152 3.9168 0.2688 1.3312 0.1792 2.3424 0.5888 3.5328 2.1632 3.9296 5.2224 5.7216 17.0624 5.1712 31.8208zM677.632 836.7616c-9.6768 1.2544-17.9328 6.1056-23.8848 14.0288-14.7456 19.6352-11.9552 55.0144-8.9728 74.3424a18.176 18.176 0 0 0 10.6496 13.9392c2.3936 1.0624 4.928 1.5872 7.4496 1.5872 3.5072 0 7.0016-1.0112 10.048-3.008 11.5072-7.5392 32.4224-21.9648 43.3024-33.7792 11.2256-12.1984 13.76-31.8848 6.016-46.8352-7.9104-15.296-24.5632-22.912-44.608-20.2752z m16.2688 46.5408c-4.0832 4.4416-11.5328 10.6112-21.0432 17.536-0.5504-14.7584 1.2544-26.5984 5.1584-31.808 1.1904-1.5744 2.1888-1.984 3.52-2.1632 1.2416-0.1536 2.5856-0.2688 3.9168-0.2688 4.0064 0 8.0512 0.9728 9.8304 4.416 1.92 3.6608 1.2672 9.408-1.3824 12.288z" fill="#333B44" ></path></symbol><symbol id="icon-shengxiaogou" viewBox="0 0 1024 1024"><path d="M517.3504 277.952S371.5712 219.8528 302.4384 78.464c-0.6144-1.2544-2.4832-1.088-2.7904 0.2688-19.7376 86.0928 35.328 204.5056 42.6752 219.7504 0.4096 0.8448-0.0384 1.8176-0.9472 2.048-11.5712 2.9184-77.8112 23.1552-116.4928 112.2944-14.5024 30.8224-52.1344 61.6448-102.4256 31.36-1.1008-0.6656-2.5344 0.256-2.2656 1.5232 8.0128 37.9008 43.2768 69.7472 51.3152 76.608 0.7552 0.6528 0.6656 1.8432-0.192 2.368-7.9872 4.9152-39.4752 29.9904-38.8736 119.5904 0.0128 1.3824 1.728 2.0096 2.6368 0.9472 21.4144-25.2416 53.6704-37.3504 64.6912-40.9216 1.3056-0.4224 2.432 0.9984 1.7152 2.176-9.8048 16-48.9216 88.2048-25.5104 188.0064 0.3072 1.2928 2.0736 1.5488 2.7648 0.4096 21.9264-36.2112 36.48-50.2656 41.4592-54.464 0.8448-0.7168 2.1504-0.2432 2.3808 0.8448 4.9792 22.8352 52.928 205.4912 313.6256 205.5296h0.128c205.76-13.2096 268.8256-185.3568 275.6224-205.8624 0.3328-0.9856 1.5232-1.3568 2.3168-0.6912 4.7616 3.9552 19.4176 17.8816 41.6896 54.656 0.6912 1.1392 2.4576 0.8832 2.7648-0.4096 23.4112-99.8144-15.7056-172.0192-25.5104-188.0064-0.7168-1.1776 0.4096-2.5984 1.7152-2.176 11.0336 3.5712 43.2768 15.6928 64.6912 40.9216 0.896 1.0624 2.624 0.4352 2.6368-0.9472 0.6016-89.6-30.8864-114.6752-38.8736-119.5904-0.8576-0.5248-0.9472-1.7152-0.192-2.368 8.0384-6.848 43.3152-38.7072 51.3152-76.608 0.2688-1.2672-1.152-2.1888-2.2656-1.5232-50.2912 30.2848-87.9232-0.5376-102.4256-31.36-38.6816-89.1392-104.9216-109.3888-116.4928-112.2944-0.9088-0.2304-1.3568-1.2032-0.9472-2.048 7.3472-15.2448 62.4128-133.6576 42.6752-219.7504-0.3072-1.3568-2.176-1.5232-2.7904-0.2688-69.1328 141.376-214.912 199.4752-214.912 199.4752" fill="#F2B655" ></path><path d="M363.562676 574.677226a76.9792 47.424 9.231 1 0 15.215066-93.619682 76.9792 47.424 9.231 1 0-15.215066 93.619682Z" fill="#FFFFFF" ></path><path d="M694.6688 296.8576c-0.4096 0.8448 0.0384 1.8176 0.9472 2.048 11.5712 2.9184 77.8112 23.1552 116.4928 112.2944a85.9904 85.9904 0 0 0 15.1808 22.272c0.8192 0.8576 2.3168 0.4224 2.5856-0.7296 44.8128-196.8256-67.4432-331.328-89.7408-355.6736-1.0368-1.1264-2.8288-0.1536-2.496 1.344 18.8928 85.9648-35.6608 203.2768-42.9696 218.4448zM223.36 418.3424c1.3952-2.3552 2.6752-4.7488 3.8016-7.1424 38.6816-89.1392 104.9216-109.3888 116.4928-112.2944 0.9088-0.2304 1.3568-1.2032 0.9472-2.048-7.3472-15.232-62.3872-133.5936-42.7008-219.6736 0.32-1.3824-1.2288-2.3808-2.3296-1.4848-22.2208 18.2272-146.2784 131.648-76.2112 342.6432z" fill="#F7E9CF" ></path><path d="M519.6544 812.4032c31.3344 0 48.0384-21.9136 56.5504-40.3328 5.3632-11.6224-3.2896-24.8704-16.0896-24.8704h-80.0512c-13.0176 0-21.7088 13.6832-15.872 25.3184 9.1776 18.3296 26.1888 39.8848 55.4624 39.8848z" fill="#F7935C" ></path><path d="M590.877809 536.594925a47.424 76.9792 80.769 1 0 151.96458-24.697276 47.424 76.9792 80.769 1 0-151.96458 24.697276Z" fill="#FFFFFF" ></path><path d="M924.6208 430.848c-5.184-3.6992-12.0832-3.968-17.5488-0.6784-16.3712 9.856-31.8208 12.6848-45.9008 8.4096-5.6064-1.7024-11.0208-4.5824-16-8.3712 42.8672-200.3456-70.8992-337.3056-94.3616-362.9312-2.7264-2.9696-6.3872-4.6592-10.2016-5.0304-0.9216-0.2816-1.8688-0.512-2.8416-0.6272a16.01408 16.01408 0 0 0-16.2048 8.8576c-58.4064 119.4624-175.5264 178.0736-201.92 190.0672-26.4064-11.9552-143.36-70.3232-201.9072-190.08-2.4064-4.9152-7.1424-8.1536-12.4416-8.7936-5.0304-1.5872-10.6368-0.6272-14.8608 2.8416-25.9584 21.2736-150.7712 137.408-82.9184 351.7312-7.7824 10.9056-18.2016 18.944-29.3888 22.336-14.0928 4.2624-29.5296 1.4464-45.8752-8.3968a16.0064 16.0064 0 0 0-17.5616 0.6528 15.89888 15.89888 0 0 0-6.3488 16.2432c6.7712 32.0384 29.824 59.328 45.0816 74.4704-14.4768 15.9616-33.6128 50.5088-33.1392 121.2032 0.0512 6.6432 4.2624 12.6208 10.5216 14.8992 6.2464 2.2784 13.3248 0.384 17.6256-4.672 7.7696-9.152 17.3184-16.4096 26.5088-21.9904-14.0672 35.6608-27.5456 93.5296-10.7392 165.1584 1.472 6.336 6.592 11.0976 13.0304 12.1344 6.4256 1.024 12.8128-1.9072 16.2176-7.5008 9.6768-15.9744 17.7408-27.3152 24-35.2128 20.3008 57.3696 92.6336 194.0608 321.0752 194.0864 0.1792 0 0.3968 0 0.5888-0.0128 0.1536 0 0.3072-0.0128 0.4608-0.0128 182.3232-11.712 257.728-143.3472 280.7424-196.032 6.464 7.9488 15.0656 19.8144 25.5744 37.1712 3.3664 5.5936 9.7536 8.5376 16.1664 7.5264 6.4512-1.0112 11.5712-5.7472 13.0816-12.1088 16.8064-71.6416 3.3152-129.5232-10.752-165.1968 9.2032 5.5808 18.752 12.8384 26.5088 21.9904 4.3008 5.0688 11.3792 6.9632 17.6256 4.6848 6.2464-2.2656 10.4704-8.256 10.5216-14.8992 0.4864-70.6816-18.6624-105.216-33.1392-121.2032 15.2704-15.1424 38.3104-42.4192 45.0816-74.4448 1.28-6.2208-1.2032-12.5952-6.3616-16.2688zM821.76 397.4144c-0.4736-0.9984-0.9728-1.8944-1.4464-2.88-1.024-2.0992-2.0608-4.1344-3.1104-6.1568-1.1392-2.1888-2.2784-4.3392-3.4432-6.4384-1.0752-1.9456-2.176-3.84-3.2768-5.7088-1.1904-2.0096-2.3936-3.9936-3.6096-5.9136-1.1264-1.792-2.2656-3.5584-3.4176-5.2736-1.2288-1.8432-2.4704-3.648-3.7248-5.4016-1.1648-1.6512-2.3424-3.2768-3.5328-4.864-1.2672-1.6896-2.5216-3.3152-3.8016-4.9152-1.2032-1.5104-2.4064-3.0208-3.6096-4.4672-1.28-1.5232-2.56-2.9952-3.84-4.4416-1.2288-1.3824-2.4448-2.7648-3.6736-4.0832-1.28-1.3824-2.5728-2.7008-3.8528-4.0064-1.2416-1.2544-2.4704-2.5216-3.712-3.712-1.28-1.2416-2.56-2.4192-3.84-3.5968-1.2416-1.1392-2.4704-2.2784-3.712-3.3664-1.2672-1.1136-2.5216-2.1504-3.7888-3.2-1.2288-1.024-2.4576-2.048-3.6736-3.0208-1.2544-0.9856-2.4832-1.9072-3.7248-2.8416-1.2032-0.9088-2.4064-1.8304-3.5968-2.6752-1.2288-0.8832-2.4192-1.6896-3.6352-2.5088-1.1648-0.7936-2.3424-1.6128-3.4816-2.3552-1.2032-0.7808-2.3552-1.4848-3.5328-2.2144-1.1136-0.6912-2.2272-1.3952-3.3152-2.0352-1.1648-0.6912-2.2912-1.3056-3.4304-1.9456-1.0368-0.576-2.0864-1.1904-3.0976-1.728-1.152-0.6144-2.2528-1.1648-3.3664-1.728-0.9216-0.4608-1.8688-0.9728-2.7648-1.3952-1.1904-0.576-2.2912-1.0752-3.4304-1.5872-0.7552-0.3456-1.5488-0.7296-2.2784-1.0496a159.36 159.36 0 0 0-5.1712-2.1632c0.7936-1.792 1.6512-3.7632 2.5216-5.7984 0.1408-0.3328 0.2816-0.6528 0.4224-0.9984 0.896-2.112 1.8304-4.3264 2.7904-6.656 0.0768-0.1664 0.1408-0.3328 0.2048-0.4992 0.9984-2.432 2.0224-4.9792 3.072-7.6416 0.0128-0.0256 0.0128-0.0512 0.0256-0.0768 1.0496-2.6752 2.1248-5.4656 3.2128-8.3584 0.0896-0.2432 0.192-0.4992 0.2816-0.7424a553.088 553.088 0 0 0 6.656-18.688c0.064-0.1792 0.128-0.3584 0.192-0.5504 1.1136-3.3024 2.2144-6.6816 3.3024-10.1376 0.0512-0.1664 0.1024-0.3328 0.1536-0.512 2.176-6.9248 4.2752-14.1312 6.2592-21.5552 0.1024-0.3584 0.192-0.7168 0.2816-1.0752 0.9728-3.6992 1.9328-7.4496 2.8288-11.2384 0.0128-0.0256 0.0128-0.064 0.0256-0.0896 0.896-3.7504 1.728-7.552 2.5344-11.3792l0.192-0.9216c0.7808-3.7504 1.4976-7.5264 2.176-11.328l0.2688-1.536c1.3184-7.6032 2.4064-15.296 3.2128-23.0144 0.064-0.6528 0.1408-1.2928 0.2048-1.9456 0.3712-3.7504 0.6784-7.5008 0.896-11.2512l0.0768-1.5104c0.192-3.5072 0.32-7.0144 0.3712-10.5088 0.0128-0.3456 0.0384-0.704 0.0384-1.0496 34.752 50.2016 84.48 147.776 65.6896 276.736z m-538.496-285.44c0 0.2304 0.0128 0.4736 0 0.7168-0.0768 3.648-0.064 7.3216 0.0256 11.008l0.0384 2.1376c0.1152 3.7248 0.32 7.4624 0.5888 11.2l0.192 2.5728c0.3072 3.7632 0.6528 7.5136 1.1008 11.264 0.064 0.5376 0.1408 1.0752 0.2048 1.6256 0.4224 3.4816 0.9088 6.9504 1.4336 10.4064 0.1152 0.7296 0.2176 1.4592 0.3328 2.1888 0.576 3.648 1.2288 7.2704 1.9072 10.8672 0.1792 0.9216 0.3456 1.8304 0.5248 2.752 0.704 3.5712 1.4336 7.1296 2.2272 10.6496 0.1536 0.704 0.32 1.3952 0.4864 2.0992 0.7296 3.2 1.4976 6.3616 2.2784 9.4976 0.1664 0.6784 0.3328 1.3696 0.512 2.048 0.8704 3.4048 1.7792 6.7712 2.7136 10.0864 0.256 0.896 0.4992 1.7792 0.7552 2.6752 0.9344 3.2512 1.8688 6.464 2.8288 9.6128 0.2176 0.7296 0.448 1.4464 0.6784 2.176 0.896 2.8928 1.8048 5.7472 2.7264 8.5376 0.1664 0.512 0.3328 1.0368 0.4992 1.5488 1.0112 3.0592 2.0352 6.0288 3.0592 8.9472 0.2688 0.7552 0.5248 1.5104 0.7936 2.2656 0.9984 2.816 1.9968 5.568 2.9824 8.2304 0.2304 0.6272 0.4608 1.2416 0.704 1.856a482.04928 482.04928 0 0 0 3.1616 8.2432c1.0112 2.5728 1.984 5.0048 2.944 7.36 0.2176 0.5248 0.4224 1.0496 0.64 1.5744 0.9344 2.2528 1.8304 4.416 2.7008 6.4512 0.1792 0.4352 0.3584 0.832 0.5376 1.2544 0.896 2.0864 1.7536 4.0832 2.56 5.9136-1.5616 0.6144-3.2128 1.3056-4.928 2.0608-0.6016 0.2688-1.2544 0.576-1.8816 0.8576-1.152 0.5248-2.3168 1.0496-3.5328 1.6384-0.7808 0.3712-1.5872 0.7808-2.3936 1.1904-1.1392 0.5632-2.2784 1.152-3.4688 1.7664-0.8832 0.4608-1.7664 0.9472-2.6624 1.4464-1.1776 0.64-2.368 1.3184-3.5712 2.0224-0.9344 0.5376-1.8816 1.1008-2.8416 1.6768-1.2544 0.7552-2.5216 1.5488-3.7888 2.368-0.96 0.6144-1.9072 1.2032-2.88 1.856-1.3824 0.9088-2.7776 1.8944-4.1856 2.88-0.896 0.64-1.792 1.2288-2.7008 1.8944-1.9456 1.4208-3.9168 2.9312-5.9008 4.4928-0.5504 0.4352-1.088 0.8448-1.6384 1.2928-2.1632 1.7536-4.352 3.584-6.5408 5.5168-0.8704 0.768-1.728 1.5872-2.5984 2.3808-1.536 1.408-3.0848 2.816-4.6208 4.3136-0.9856 0.96-1.9712 1.9712-2.9696 2.9824a178.5728 178.5728 0 0 0-4.288 4.4544c-1.024 1.1008-2.048 2.24-3.072 3.392-1.3952 1.5616-2.7904 3.1744-4.1728 4.8256-1.024 1.216-2.0352 2.4448-3.0592 3.6992-1.3952 1.7408-2.7904 3.5456-4.16 5.376-0.9728 1.2928-1.9456 2.5728-2.9184 3.904-1.4592 2.0352-2.9056 4.16-4.352 6.3104-0.8448 1.2544-1.7024 2.4704-2.5344 3.7632-1.92 2.9952-3.8144 6.1056-5.6832 9.3056-0.32 0.5504-0.6528 1.0624-0.9728 1.6128-33.3056-137.088 19.776-225.3184 56.1792-267.0464z m572.8 397.7344a15.9808 15.9808 0 0 0-5.5168 13.3632c0.4096 5.0688 3.2256 9.6768 7.5392 12.3136 2.8928 1.7792 25.3312 17.4464 30.7968 77.056-18.688-13.2608-37.8368-20.4928-47.2064-23.5392-6.3488-2.048-13.3504 0.0896-17.4592 5.312-4.1088 5.2224-4.5312 12.5312-1.0624 18.1888 6.9888 11.4048 37.76 66.8672 29.1968 145.536-13.248-18.368-22.4384-27.0464-26.5344-30.464a15.90016 15.90016 0 0 0-14.5408-3.072c-5.0688 1.4464-9.088 5.2992-10.7648 10.3424-6.1952 18.7136-66.2144 183.1296-262.4128 195.9424-249.6128-0.2176-294.7584-174.272-299.072-194.1248-1.1776-5.44-5.1968-9.9328-10.4576-11.7248-1.664-0.5632-3.3792-0.8448-5.0944-0.8448-3.712 0-7.3984 1.2928-10.2784 3.7376-4.9664 4.1728-13.8496 12.9664-26.24 30.1696-8.5504-78.6688 22.208-134.1056 29.2096-145.5232 3.4688-5.6704 3.0208-12.9792-1.088-18.1888-4.1216-5.2096-11.136-7.3344-17.4336-5.2864-9.3696 3.0336-28.5184 10.2656-47.2064 23.5392 5.4656-59.6096 27.904-75.264 30.784-77.0432 4.3392-2.6624 7.168-7.2832 7.5648-12.352 0.3968-5.0688-1.6768-10.0736-5.5552-13.3632-4.736-4.032-23.3728-20.6464-35.9552-42.304 16.0896 3.6608 29.5424 1.856 39.2832-1.1008 19.6224-5.952 37.44-20.672 49.216-40.4608 0.0256-0.0384 0.064-0.064 0.0768-0.1024 1.6768-2.8416 3.1744-5.6448 4.6208-8.7552 28.0832-64.704 70.7328-90.1248 93.3632-99.4816 6.1952-2.56 10.9056-3.9168 13.3888-4.544 1.1648-0.2944 2.2912-0.7168 3.3408-1.2416 0.0512-0.0256 0.0896-0.064 0.1408-0.0896 0.9856-0.512 1.9328-1.1136 2.7904-1.8176 0.32-0.2688 0.576-0.6144 0.8704-0.896 0.5376-0.5248 1.1008-1.0112 1.5616-1.6128 0.2304-0.2944 0.384-0.6656 0.6016-0.9856 0.4352-0.6528 0.896-1.3056 1.2416-2.0352 0-0.0128 0-0.0128 0.0128-0.0256v-0.0128c0.192-0.4224 0.2816-0.8704 0.4352-1.3056 0.2432-0.6784 0.5376-1.344 0.6912-2.0352 0.7552-3.456 0.3456-7.0784-1.2288-10.3168-0.3712-0.7808-0.9344-1.9456-1.6256-3.4304-0.064-0.1408-0.1408-0.2944-0.2048-0.4352-0.2688-0.5888-0.576-1.2416-0.8832-1.92-0.128-0.2688-0.2432-0.5376-0.3712-0.8192-0.3072-0.6656-0.6272-1.3824-0.96-2.112-0.1408-0.32-0.2816-0.64-0.4352-0.9728-0.3584-0.7936-0.7296-1.6512-1.1136-2.5216-0.1536-0.3456-0.2944-0.6528-0.448-1.0112-0.5248-1.1904-1.0624-2.4576-1.6256-3.776l-0.5888-1.3824c-0.384-0.9216-0.7808-1.8432-1.1904-2.816-0.2688-0.6528-0.5504-1.3312-0.832-2.0096-0.3456-0.832-0.6912-1.6768-1.0496-2.5344-0.3072-0.768-0.64-1.5616-0.96-2.3552-0.3456-0.8448-0.6912-1.7024-1.0368-2.5856-0.3328-0.8448-0.6656-1.6896-1.0112-2.56-0.3456-0.896-0.704-1.8176-1.0624-2.7392-0.3456-0.896-0.6912-1.792-1.0368-2.7136-0.4096-1.0752-0.832-2.2016-1.2416-3.3152-0.4736-1.28-0.96-2.5728-1.4336-3.8912-0.4992-1.3568-0.9984-2.7264-1.4976-4.1344-0.3328-0.9472-0.6784-1.92-1.0112-2.88-0.3968-1.1264-0.7808-2.24-1.1776-3.392-0.3456-0.9984-0.6912-2.0224-1.0368-3.0464-0.3968-1.152-0.7808-2.3168-1.1648-3.4944-0.3456-1.0368-0.6784-2.0736-1.024-3.1232-0.3968-1.2288-0.7936-2.4832-1.1904-3.7376-0.32-1.024-0.64-2.0352-0.96-3.072-0.4352-1.4208-0.8704-2.8672-1.3056-4.3136-0.2688-0.896-0.5376-1.792-0.8064-2.7008-0.6784-2.304-1.344-4.6336-1.9968-7.0016-0.1792-0.6656-0.3584-1.344-0.5504-2.0224-0.4864-1.7792-0.96-3.5584-1.4336-5.3632-0.2432-0.9088-0.4608-1.8432-0.6912-2.752-0.3968-1.5872-0.7936-3.1872-1.1904-4.8-0.2304-0.9728-0.4608-1.9456-0.6912-2.9312-0.3712-1.6128-0.7424-3.2384-1.1008-4.864-0.2048-0.9472-0.4224-1.8944-0.6144-2.8416-0.384-1.7792-0.7424-3.5712-1.088-5.3632-0.1536-0.7936-0.32-1.5872-0.4736-2.3808-0.4864-2.5344-0.9472-5.0816-1.3696-7.6288-0.0128-0.0512-0.0128-0.1024-0.0256-0.1536-0.448-2.688-0.8704-5.3888-1.2544-8.0896-0.0768-0.4992-0.128-0.9984-0.2048-1.4976-0.2944-2.1504-0.576-4.288-0.8192-6.4384-0.0896-0.7424-0.1664-1.4848-0.2432-2.2272-0.2048-1.9456-0.3968-3.8912-0.5632-5.824l-0.192-2.3168c-0.1536-1.984-0.2816-3.9552-0.384-5.9264l-0.1152-2.0608c-0.1024-2.2912-0.1792-4.5824-0.2176-6.8608 0-0.3328-0.0128-0.6656-0.0256-0.9984 0-0.2432 0.0128-0.4864 0-0.7424 75.0592 118.3232 196.5056 167.8336 202.1248 170.0736 3.4432 1.3696 7.2704 1.3696 10.7136 0 5.6192-2.24 127.0528-51.7376 202.112-170.0608 0 0.4352 0.0128 0.8832 0 1.3184-0.0128 0.6912-0.0384 1.3824-0.0512 2.0736-0.0384 1.9456-0.1152 3.904-0.2048 5.8624-0.0384 0.7552-0.0768 1.5232-0.128 2.2784a307.69024 307.69024 0 0 1-0.5888 7.9872c-0.192 2.176-0.4096 4.3392-0.6656 6.5152-0.0512 0.4608-0.0896 0.9216-0.1536 1.3824-0.64 5.4272-1.4208 10.8544-2.3424 16.2432-0.0512 0.3328-0.1152 0.6528-0.1792 0.9856a313.66528 313.66528 0 0 1-1.6128 8.6784c-0.4096 2.0608-0.832 4.1216-1.2672 6.1696-0.128 0.6272-0.2688 1.2544-0.4096 1.8688-0.4608 2.0864-0.9344 4.1472-1.4208 6.208-0.1152 0.512-0.2304 1.024-0.3584 1.5232-0.576 2.4064-1.1648 4.7872-1.7792 7.1552-0.0384 0.128-0.064 0.2688-0.1024 0.3968-1.344 5.1968-2.7648 10.2912-4.224 15.2576-0.0896 0.2816-0.1664 0.5632-0.256 0.8448-0.6272 2.1248-1.2672 4.2112-1.9072 6.2848-0.1536 0.4864-0.2944 0.96-0.448 1.4336-0.5888 1.8944-1.1904 3.7632-1.792 5.6064-0.1536 0.4864-0.3072 0.96-0.4736 1.4464-0.6272 1.9072-1.2544 3.776-1.8816 5.6192-0.1152 0.3456-0.2432 0.704-0.3584 1.0496-2.2784 6.656-4.5696 12.9152-6.7712 18.688l-0.3456 0.8832c-0.6016 1.5744-1.2032 3.1104-1.792 4.608-0.1536 0.3968-0.3072 0.7808-0.4608 1.1648l-1.6128 4.0448c-0.1664 0.3968-0.32 0.7936-0.4864 1.1904-0.5376 1.3184-1.0624 2.5984-1.5872 3.84a480.19328 480.19328 0 0 1-3.9168 9.1776c-0.0896 0.2176-0.1792 0.3968-0.2688 0.6144-0.4224 0.9728-0.8448 1.9072-1.2288 2.7904-0.1664 0.384-0.3328 0.7296-0.4864 1.1008-0.2944 0.64-0.576 1.2672-0.8448 1.856l-0.5248 1.1648c-0.2048 0.448-0.3968 0.8704-0.5888 1.28l-0.5504 1.1776c-0.1024 0.2304-0.2048 0.4224-0.2944 0.64-0.4736 1.0112-0.8832 1.8688-1.1648 2.4576a15.88736 15.88736 0 0 0-0.0768 13.6704c0.3584 0.7552 0.832 1.4336 1.2928 2.112 0.192 0.2944 0.3456 0.6272 0.5504 0.9088 2.1632 2.7776 5.1968 4.7744 8.6912 5.6576 1.8816 0.4736 5.0432 1.3696 9.152 2.8928 20.3392 7.5136 64.192 30.3744 94.2976 93.8624 1.1776 2.496 2.3424 5.0432 3.4816 7.6672 1.2544 2.6496 2.6624 5.248 4.16 7.808 0.5888 0.9984 1.2288 1.9584 1.8432 2.944 0.96 1.5232 1.9456 3.0208 2.9824 4.48a104.41984 104.41984 0 0 0 5.7728 7.36c0.6528 0.7552 1.2928 1.5232 1.9584 2.2528 0.3584 0.3968 0.6784 0.8192 1.0496 1.2032 0.32 0.3328 0.6912 0.576 1.024 0.8832 10.0864 10.3168 22.1056 18.0736 34.9696 21.9776 9.7536 2.9568 23.1936 4.7616 39.2832 1.1008-12.5312 21.6832-31.1808 38.3104-35.9424 42.368z" fill="#333B44" ></path><path d="M430.4128 670.4c-4.8128 6.3872-3.5328 15.4624 2.8416 20.2624 2.6112 1.9712 5.6704 2.9184 8.704 2.9184 4.3904 0 8.7296-1.984 11.5712-5.76 105.6256-140.1856-11.6608-296.7808-12.8512-298.3424-4.8512-6.3488-13.9136-7.552-20.2624-2.7136-6.3488 4.8384-7.5648 13.9264-2.7392 20.2752 4.3264 5.696 105.024 140.864 12.736 263.36z" fill="#333B44" ></path><path d="M360.448 588.7744c5.3248 1.1776 10.7776 1.728 16.2816 1.728 33.3696 0 68.352-20.1984 82.6368-42.5088 2.5984-4.0576 3.008-9.152 1.088-13.568-15.4752-35.6096-29.3504-59.5584-79.3344-67.6864-50.176-8.1536-77.9008 19.968-96.2304 38.5792a14.4768 14.4768 0 0 0-2.8416 16.2048c21.0816 45.888 54.272 61.9008 78.4 67.2512z m9.7152-94.2336c-11.1744 8.6272-15.936 23.8464-10.6624 37.7344 6.4512 16.9984 25.4592 25.5616 42.4576 19.1104 12.1472-4.608 19.9424-15.616 21.0816-27.7248 2.4832 4.224 4.8896 8.9984 7.3856 14.4896-13.888 14.7328-42.7264 27.0208-63.7056 22.3744-16.1408-3.584-37.9008-13.888-53.8368-42.176 16.4736-15.7568 32.1152-26.0608 57.28-23.808zM596.6464 693.5808c3.0336 0 6.0928-0.9472 8.704-2.9184 6.3872-4.8128 7.6544-13.888 2.8416-20.2624-92.3008-122.4832 8.4096-257.664 12.736-263.3472 4.8384-6.3488 3.6224-15.424-2.7136-20.2752-6.3488-4.8512-15.4368-3.648-20.288 2.7008-1.1904 1.5616-118.4768 158.1568-12.8512 298.3424a14.4768 14.4768 0 0 0 11.5712 5.76z" fill="#333B44" ></path><path d="M743.4496 639.4752c-2.5216 2.5984-61.7728 64.4352-68.672 132.4032-0.0256 0.2048-0.0384 0.4096-0.0512 0.6144l-0.1792 3.6224c-0.7936 17.2928-3.2384 27.9936-8.4608 33.9584 0.6912-36.5824-24.2816-54.4256-38.5024-58.8672-7.6416-2.4064-15.7568 1.8688-18.1248 9.4976-2.3808 7.6288 1.8688 15.744 9.4976 18.1248 0.8576 0.2688 21.1072 6.9376 17.856 35.84-2.4192 21.6192-20.8896 36.4544-100.0576 38.2336v-28.0064c22.5792-5.3376 40.9088-21.4656 52.5824-46.7712 4.5696-9.9072 3.7888-21.3248-2.112-30.5536-5.952-9.3056-16.0896-14.8608-27.1104-14.8608h-80.064c-11.2384 0-21.4912 5.7216-27.4048 15.296-5.8496 9.4848-6.3744 21.056-1.408 30.976 13.2864 26.5088 33.088 42.752 56.5632 46.8224v27.1488c-69.248-1.1776-101.9904-12.5568-105.5744-36.5184-3.8528-25.7152 14.6944-37.568 16.9088-38.8864 6.8736-3.9424 9.3056-12.7104 5.4016-19.648-3.9168-6.9632-12.7488-9.4464-19.712-5.5168-1.4208 0.7936-31.5648 18.368-32 56.1408-4.3904-6.1952-6.5152-16.512-7.2448-32.4352l-0.1792-3.648a8.7808 8.7808 0 0 0-0.0512-0.6016c-6.8864-67.968-66.1504-129.8048-68.672-132.4032-5.568-5.7472-14.7328-5.888-20.4672-0.32s-5.888 14.7328-0.32 20.4672c0.5504 0.5632 54.5536 56.8832 60.6208 114.8416l0.1536 3.008c0.7424 16.0384 2.9312 62.8608 46.464 67.3536 22.9632 32.2176 80.832 37.2224 136.9472 37.2224 54.8352 0 113.024-3.3536 135.9104-37.1328 44.5184-3.8784 46.7328-51.3024 47.4752-67.4688l0.1536-2.9952c6.0544-57.7408 60.0832-114.2784 60.6336-114.8416 5.5552-5.7344 5.4144-14.8992-0.3328-20.4544-5.7344-5.5296-14.8864-5.3888-20.4672 0.3584z m-266.3296 126.5664c-0.4608-0.9344-0.4096-1.8688 0.1664-2.8032 0.3584-0.576 1.2032-1.5616 2.7648-1.5616h80.064c1.536 0 2.368 0.9472 2.7264 1.4976 0.5888 0.9216 0.6656 1.8688 0.2176 2.816-9.7792 21.184-24.384 31.9232-43.4048 31.9232-17.6256 0.0128-31.9232-10.7136-42.5344-31.872zM577.6256 530.8032c-1.92 4.4288-1.5104 9.5104 1.088 13.568 14.2848 22.2976 49.2544 42.5088 82.6368 42.5088 5.504 0 10.9696-0.5504 16.2816-1.728 24.128-5.3504 57.3184-21.3632 78.3872-67.2384 2.5088-5.4656 1.3824-11.9168-2.8416-16.192-18.3296-18.6112-46.0032-46.7584-96.2304-38.5792-49.984 8.1024-63.8592 32.0512-79.3216 67.6608z m37.4144-10.7776c1.1392 12.1088 8.9344 23.1296 21.0816 27.7376 16.9984 6.4512 36.0064-2.112 42.4576-19.1104 5.2608-13.888 0.512-29.1072-10.6624-37.7344 25.152-2.2528 40.8192 8.0512 57.28 23.808-15.936 28.288-37.696 38.592-53.8368 42.176-21.0048 4.6592-49.8176-7.6416-63.7184-22.3744 2.5088-5.504 4.9024-10.2784 7.3984-14.5024z" fill="#333B44" ></path></symbol><symbol id="icon-shengxiaozhu" viewBox="0 0 1024 1024"><path d="M579.84 189.3888c-51.7632-15.0912-106.9184-13.1456-157.1456 6.4256-58.3552 22.7456-136.8192 70.336-194.6112 169.3312-22.1696 35.6608-105.9968 165.7472-77.0944 336.3072s218.752 223.5648 388.352 223.5648 291.0208-93.4784 318.9632-165.7472c27.9424-72.2688 61.6704-208.1408-48.1792-381.6064-26.24-46.6944-96.3328-149.1968-230.2848-188.2752z" fill="#FF9C4A" ></path><path d="M810.112 377.6896c22.08 34.8672 38.2848 68.1856 49.9712 99.8144 36.224-42.7136 44.992-103.4624 46.0672-146.4192-3.0208-1.2928-6.1312-2.6752-9.3568-4.1472-53.3248-24.4096-119.488-48.8192-149.0432-98.2912-6.3744-9.8048-39.68-13.5552-76.5056 1.728C747.072 277.76 790.6688 343.04 810.112 377.6896zM228.0832 365.1584c37.824-64.7936 84.5056-107.5712 128.6144-135.7696-35.904-14.1952-67.9552-10.3424-74.2016-0.7552-29.5552 49.472-95.7184 73.8816-149.0432 98.2912-3.2256 1.4848-6.3488 2.8544-9.3568 4.1472 1.088 43.5072 10.1504 105.2544 47.5776 148.032 19.9424-56.3584 45.5552-96.4864 56.4096-113.9456z" fill="#E8B792" ></path><path d="M366.464 574.912a149.0432 102.144 0 1 0 298.0864 0 149.0432 102.144 0 1 0-298.0864 0Z" fill="#FAC2AB" ></path><path d="M317.504 439.68m-41.7536 0a41.7536 41.7536 0 1 0 83.5072 0 41.7536 41.7536 0 1 0-83.5072 0Z" fill="#FFFFFF" ></path><path d="M714.4192 439.68m-41.7536 0a41.7536 41.7536 0 1 0 83.5072 0 41.7536 41.7536 0 1 0-83.5072 0Z" fill="#FFFFFF" ></path><path d="M948.1984 191.3856c-9.6384-32.1152-34.688-27.6224-41.7536-26.3424-7.0656 1.28-12.2112 3.8528-35.9808 10.2784-46.2592 12.2112-65.5232-8.3456-102.784-22.4896-37.2608-14.1312-48.8192 2.5728-62.3104 14.1312-7.872 6.7584-29.9776 34.0864-47.0272 55.6672 4.416 2.5088 8.704 5.1072 12.9152 7.7312 36.8256-15.296 70.144-11.5328 76.5056-1.728 29.5552 49.472 95.7184 73.8816 149.0432 98.2912s77.0944 23.7696 81.5872-16.064c4.4928-39.8208-20.5696-87.36-30.1952-119.4752zM282.496 228.6464c6.2336-9.6 38.2976-13.44 74.2016 0.7552 4.6592-2.9824 9.2928-5.7856 13.888-8.4608-16.8448-21.2992-38.0032-47.3856-45.6832-53.9648-13.4912-11.5584-25.0496-28.2624-62.3104-14.1312s-56.5376 34.688-102.784 22.4896c-23.7696-6.4256-28.9152-8.9984-35.9808-10.2784-7.0656-1.28-32.128-5.7856-41.7536 26.3424-9.6384 32.1152-34.688 79.6544-30.1952 119.488 4.4928 39.8336 28.2624 40.4736 81.5872 16.064s119.4752-48.8448 149.0304-98.304z" fill="#FF9C4A" ></path><path d="M515.5072 692.1472c-90.5088 0-164.1344-52.5952-164.1344-117.248s73.6384-117.248 164.1344-117.248c90.5088 0 164.1344 52.5952 164.1344 117.248s-73.6256 117.248-164.1344 117.248z m0-204.288c-73.856 0-133.952 39.0528-133.952 87.0528s60.0832 87.0528 133.952 87.0528c73.856 0 133.9392-39.0528 133.9392-87.0528s-60.0832-87.0528-133.9392-87.0528z" fill="#333B44" ></path><path d="M515.5072 780.864c-75.0464 0-142.2848-30.9632-167.3216-77.056-3.9808-7.3216-1.2672-16.4864 6.0544-20.4672 7.3216-3.9808 16.4864-1.2672 20.4672 6.0544 19.5968 36.0704 77.4912 61.2736 140.7872 61.2736 63.2064 0 119.488-24.1024 140.0576-59.968 4.1472-7.232 13.376-9.728 20.608-5.5936 7.232 4.1472 9.7408 13.376 5.5936 20.608-26.1632 45.6576-91.4176 75.1488-166.2464 75.1488zM453.2352 620.8384c-20.3264 0-35.648-23.4368-35.648-54.5024s15.3216-54.4896 35.648-54.4896 35.648 23.424 35.648 54.4896c0 31.0784-15.3216 54.5024-35.648 54.5024z m0-77.3376c-2.2656 3.3536-5.4656 11.008-5.4656 22.848s3.1872 19.4944 5.4656 22.848c2.2656-3.3536 5.4656-11.008 5.4656-22.848-0.0128-11.8528-3.2-19.4944-5.4656-22.848zM576.7424 620.8384c-20.3264 0-35.6608-23.4368-35.6608-54.5024s15.3216-54.4896 35.6608-54.4896c20.3264 0 35.648 23.424 35.648 54.4896 0.0128 31.0784-15.3216 54.5024-35.648 54.5024z m0-77.3376c-2.2784 3.3536-5.4656 11.008-5.4656 22.848 0 11.84 3.1872 19.4944 5.4656 22.848 2.2656-3.3536 5.4656-11.008 5.4656-22.848 0-11.8528-3.1872-19.4944-5.4656-22.848zM317.504 496.5376c-31.3472 0-56.8576-25.5104-56.8576-56.8576 0-31.3472 25.5104-56.8576 56.8576-56.8576s56.8576 25.5104 56.8576 56.8576c0 31.3472-25.4976 56.8576-56.8576 56.8576z m0-83.52c-14.6944 0-26.6624 11.968-26.6624 26.6624s11.968 26.6624 26.6624 26.6624c14.6944 0 26.6624-11.968 26.6624-26.6624s-11.9552-26.6624-26.6624-26.6624zM714.4192 496.5376c-31.3472 0-56.8576-25.5104-56.8576-56.8576 0-31.3472 25.5104-56.8576 56.8576-56.8576s56.8576 25.5104 56.8576 56.8576c0 31.3472-25.5104 56.8576-56.8576 56.8576z m0-83.52c-14.6944 0-26.6624 11.968-26.6624 26.6624s11.968 26.6624 26.6624 26.6624 26.6624-11.968 26.6624-26.6624-11.968-26.6624-26.6624-26.6624z" fill="#333B44" ></path><path d="M972.352 214.3232c-3.7632-9.92-7.3088-19.2896-9.7024-27.2768-8.6016-28.672-30.0544-42.112-58.9184-36.8512-4.3776 0.7936-7.8976 1.8944-13.2096 3.5584-5.1328 1.6-12.16 3.8016-23.9232 6.976-29.4272 7.7568-44.5184 0.5376-67.3536-10.4192-7.6928-3.6864-16.4096-7.8592-26.2272-11.584-41.7536-15.8336-60.7488 1.5488-73.3312 13.056-1.3952 1.2672-2.7648 2.5344-4.16 3.7248-2.432 2.0864-9.5232 8.1792-41.0752 47.7312a381.45024 381.45024 0 0 0-70.3872-28.3392C529.0112 158.848 469.7472 161.28 417.2032 181.76a392.4096 392.4096 0 0 0-42.7904 19.7632c-30.4-38.016-37.3248-43.9808-39.7056-46.016-1.3952-1.2032-2.7776-2.4576-4.16-3.7248-12.5696-11.5072-31.5776-28.8896-73.3312-13.056-9.8176 3.7248-18.5344 7.8976-26.2272 11.584-22.8352 10.944-37.9136 18.1888-67.264 10.432-11.84-3.2-18.8672-5.4016-24-7.0016-5.312-1.664-8.832-2.7648-13.1968-3.5584-28.864-5.2736-50.3296 8.1792-58.9184 36.8512-2.3936 7.9872-5.952 17.3568-9.7152 27.2896-11.0208 29.0944-24.7552 65.3184-21.0304 98.24 2.304 20.4416 9.472 33.792 21.888 40.8192 6.3232 3.5712 13.3632 5.1712 21.1584 5.1712 9.0624 0 19.1488-2.2144 30.2208-5.9008 3.328 41.3184 14.4512 91.1872 44.8128 129.8432C130.0352 556.288 123.6224 630.4 136.0896 704c14.1056 83.1872 64.4992 146.0352 149.7856 186.8416 85.184 40.7424 184.8448 49.2928 253.44 49.2928 182.9376 0 304.8832-102.5664 333.0432-175.3984 36.3648-94.0672 37.888-189.3504 4.7488-284.4672 29.0304-38.3232 39.7312-87.168 42.9824-127.6288 11.072 3.6992 21.1584 5.9008 30.2208 5.9008 7.7952 0 14.8352-1.5872 21.1584-5.1712 12.4288-7.0272 19.584-20.3776 21.888-40.8192 3.7504-32.9088-9.9712-69.12-21.0048-98.2272zM73.6128 327.104c-3.264-1.8432-5.6576-8.2048-6.7456-17.92-2.9056-25.664 8.8704-56.7424 19.264-84.16 3.9552-10.432 7.6928-20.3008 10.3936-29.312 3.8016-12.6848 9.7152-16.5248 17.7792-16.5248 2.1248 0 4.4032 0.2688 6.8224 0.7168 2.5472 0.4608 5.056 1.2416 9.6 2.6624 5.376 1.6768 12.7232 3.9808 25.216 7.3472 40.1664 10.6112 63.4496-0.5504 88.1152-12.3776 7.5008-3.5968 15.2576-7.3088 23.8848-10.5856 24.384-9.2416 31.4752-2.7392 42.24 7.104 1.6256 1.4848 3.2512 2.9696 4.8896 4.3776 1.9456 1.6768 8.1024 7.8208 26.4064 30.3232-0.2816-0.064-0.576-0.1152-0.8576-0.192-0.7168-0.1664-1.4336-0.32-2.1504-0.4736-1.5616-0.3456-3.1232-0.6656-4.6592-0.96-0.768-0.1408-1.536-0.2816-2.2912-0.4096-1.5232-0.256-3.0336-0.4864-4.5312-0.6912-0.704-0.0896-1.3952-0.192-2.0992-0.2816-1.728-0.2048-3.4432-0.3712-5.1328-0.4992-0.4224-0.0384-0.8448-0.0768-1.2544-0.1024-2.1248-0.1408-4.224-0.2304-6.2848-0.2432-0.32 0-0.6272 0.0128-0.9472 0.0128-1.6896 0-3.3536 0.0256-4.9792 0.1152-0.6016 0.0256-1.1776 0.0768-1.7664 0.1152-1.344 0.0896-2.6496 0.2048-3.9424 0.3456-0.6144 0.0768-1.2288 0.1408-1.8432 0.2304-1.2672 0.1792-2.496 0.384-3.6992 0.6144-0.5376 0.1024-1.0752 0.192-1.6 0.3072-1.472 0.32-2.8928 0.6784-4.2752 1.088-0.2048 0.064-0.4096 0.1024-0.6144 0.1664-1.5744 0.4736-3.072 1.024-4.5056 1.6128-0.3712 0.1536-0.704 0.3328-1.0624 0.4864-1.024 0.4608-2.0224 0.9344-2.9696 1.4592-0.448 0.2432-0.8576 0.4992-1.28 0.7552-0.8192 0.4992-1.6 1.0112-2.3424 1.5488-0.3968 0.2944-0.7936 0.5888-1.1776 0.8832-0.7296 0.5888-1.408 1.216-2.0608 1.856-0.2944 0.2944-0.6144 0.5632-0.8832 0.8704-0.8832 0.96-1.7024 1.9712-2.3936 3.0336-0.1024 0.1664-0.2048 0.32-0.3072 0.4864-23.5008 39.3472-75.9936 62.6944-122.2912 83.2896-6.8224 3.0336-13.5424 6.0288-20.0832 9.024-2.7648 1.2672-5.4144 2.432-8.0128 3.5456-29.6576 12.7744-41.1904 12.8128-45.568 10.3552z m66.1248 13.5552c6.4384-2.944 13.056-5.888 19.776-8.8832 49.92-22.208 106.4448-47.3472 135.1168-94.0416 0.384-0.2176 0.8704-0.4224 1.408-0.6272 0.1792-0.064 0.3968-0.128 0.5888-0.192 0.3968-0.128 0.832-0.256 1.2928-0.384 0.2688-0.0768 0.5632-0.1408 0.8704-0.2048 0.4736-0.1024 0.9728-0.2048 1.4976-0.3072 0.3456-0.064 0.6912-0.128 1.0624-0.1792 0.576-0.0896 1.2032-0.1664 1.8432-0.2432 0.384-0.0384 0.7296-0.0896 1.1264-0.128 0.9984-0.0896 2.0608-0.1664 3.1744-0.2176 0.4608-0.0256 0.9728-0.0256 1.4464-0.0384 0.7424-0.0128 1.4848-0.0384 2.2656-0.0256 0.576 0 1.1648 0.0256 1.7664 0.0384 0.7808 0.0256 1.5744 0.0512 2.3808 0.0896 0.6016 0.0256 1.2032 0.064 1.8304 0.1152 0.96 0.064 1.9328 0.1664 2.9312 0.2688l1.1264 0.1152c-0.576 0.448-1.1264 0.9216-1.7024 1.3696a398.656 398.656 0 0 0-12.0192 9.6896c-1.0112 0.8576-2.0352 1.7024-3.0336 2.56-4.0448 3.456-8.0768 7.0656-12.096 10.8032-0.7168 0.6656-1.4464 1.3184-2.1632 1.9968-4.416 4.1728-8.8192 8.512-13.1968 13.0304-0.4096 0.4224-0.7936 0.8576-1.2032 1.28-4.1856 4.3648-8.3328 8.8832-12.4544 13.5808-0.32 0.3712-0.64 0.7552-0.96 1.1264a425.4592 425.4592 0 0 0-12.1216 14.5792c-0.2048 0.256-0.3968 0.512-0.6016 0.768a431.7824 431.7824 0 0 0-11.8016 15.68c-0.128 0.1664-0.2432 0.3456-0.3712 0.5248-3.8272 5.3632-7.6032 10.88-11.3024 16.6016-0.1152 0.1792-0.2176 0.3584-0.3328 0.5376-3.584 5.5424-7.104 11.2384-10.5472 17.1264-0.064 0.1152-0.128 0.2176-0.192 0.32l-1.216 1.9456c-9.9456 15.9744-28.8768 46.3488-46.3232 88.32-19.5712-33.472-26.304-73.9968-28.032-106.8928 0.064-0.0512 0.1152-0.0768 0.1664-0.1024z m704.4864 413.184c-24.3456 62.9504-138.0736 156.096-304.8832 156.096-101.5424 0-341.184-20.5568-373.4528-210.9824-18.1632-107.1616 6.6048-216.0128 73.6128-323.5328 0.0256-0.0384 0.0512-0.0896 0.0768-0.128l1.3312-2.1504c0.0768-0.1152 0.1536-0.2432 0.2176-0.3584 3.8272-6.5664 7.8208-12.9536 11.9296-19.2128 0.3968-0.6144 0.8064-1.216 1.216-1.8176 3.7504-5.6448 7.616-11.136 11.5968-16.5248 0.6016-0.8064 1.1904-1.6256 1.792-2.4192 4.0576-5.4016 8.2304-10.6752 12.5184-15.8208 0.768-0.9216 1.5616-1.8176 2.3296-2.7392 3.8528-4.5312 7.7952-8.9344 11.8144-13.248 1.1264-1.2032 2.2656-2.4192 3.392-3.5968 4.1088-4.288 8.3072-8.4608 12.5824-12.5184 1.3696-1.2928 2.7392-2.56 4.1216-3.8272a370.3104 370.3104 0 0 1 16.7936-14.5408c4.2368-3.4432 8.5504-6.7968 12.928-10.048 1.344-0.9984 2.7008-2.0096 4.0448-2.9824 4.8512-3.4944 9.7792-6.8608 14.8096-10.1248 1.4464-0.9344 2.8928-1.8688 4.3264-2.7776 2.8672-1.8048 5.7728-3.5712 8.7424-5.3248 18.56-10.9568 36.288-19.2128 52.1216-25.3824 26.0992-10.176 54.1184-15.296 82.2912-15.296 21.8752 0 43.8656 3.0848 65.1392 9.2928 27.6736 8.064 52.5184 18.944 74.7776 31.5264 0.1664 0.1024 0.2944 0.2432 0.4608 0.3328 4.2368 2.4192 8.3456 4.8896 12.3904 7.424 0 0 0.0128 0 0.0128 0.0128C730.88 285.44 772.3264 343.1936 792.8704 377.9968c0.1536 0.2688 0.32 0.5376 0.4736 0.8064 1.28 2.176 2.496 4.288 3.6096 6.272 0.128 0.2304 0.2688 0.4608 0.4096 0.6912 20.2752 32.0128 36.6208 64.64 48.576 96.96 0.2304 0.6272 0.6144 1.1648 0.9216 1.7408 33.2032 90.2784 32.2432 179.1488-2.6368 269.376z m19.4432-307.8656c-2.7392-6.272-5.6448-12.544-8.6784-18.816-0.1024-0.2176-0.2176-0.448-0.32-0.6656-5.8624-12.0704-12.288-24.128-19.2768-36.1856-0.6272-1.0752-1.2544-2.1376-1.8816-3.2128-3.3664-5.7216-6.8096-11.4432-10.4192-17.152a340.33536 340.33536 0 0 0-3.7376-6.4896c-20.8896-35.6608-57.0368-85.632-112.8064-127.3344 0.0256 0 0.0384-0.0128 0.064-0.0128 1.728-0.2432 3.392-0.4352 5.0048-0.576l0.5632-0.0384c1.4208-0.1152 2.8032-0.2048 4.1216-0.256 0.3328-0.0128 0.64-0.0256 0.9728-0.0256a105.47968 105.47968 0 0 1 4.2496-0.0128c2.6624 0.0768 5.0432 0.2816 7.0784 0.576 0.1792 0.0256 0.3328 0.0512 0.4992 0.0896 0.7936 0.128 1.5232 0.2688 2.2016 0.4224 0.2432 0.0512 0.4608 0.1024 0.6912 0.1664 0.576 0.1408 1.088 0.2944 1.5616 0.448 0.1792 0.064 0.384 0.1152 0.5504 0.1792 0.5888 0.2176 1.1136 0.4352 1.5232 0.6656 28.6848 46.6816 85.1968 71.8336 135.1168 94.0416 6.72 2.9824 13.3376 5.9264 19.776 8.8832 0.0512 0.0256 0.1024 0.0512 0.1664 0.0768-1.7152 32.2944-8.2176 72.0768-27.0208 105.2288z m99.712-136.7936c-1.1008 9.7152-3.4944 16.0768-6.7456 17.92-4.352 2.4576-15.8464 2.4192-45.2992-10.24-2.6752-1.152-5.4016-2.3552-8.256-3.648-6.528-2.9824-13.248-5.9776-20.0704-9.0112-46.2976-20.5952-98.7904-43.9424-122.2912-83.2896-0.1024-0.1664-0.192-0.3328-0.2944-0.4864a22.2976 22.2976 0 0 0-2.7904-3.456c-0.3456-0.3584-0.768-0.6656-1.1392-1.0112-0.7552-0.6912-1.5104-1.3824-2.368-2.0224-0.4992-0.3712-1.0624-0.6912-1.6-1.024-0.832-0.5376-1.664-1.0752-2.5728-1.5616-0.6144-0.32-1.28-0.6144-1.92-0.9088-0.9344-0.4352-1.8688-0.8576-2.8672-1.2416-0.704-0.2688-1.4336-0.4992-2.176-0.7424-1.0368-0.3456-2.0864-0.6656-3.1872-0.96-0.768-0.2048-1.5744-0.384-2.368-0.5632-1.1392-0.256-2.304-0.4864-3.4944-0.6912-0.832-0.1408-1.6768-0.2688-2.5344-0.384-1.2416-0.1664-2.5216-0.3072-3.8144-0.4224-0.8704-0.0768-1.7536-0.1536-2.6368-0.2048a106.4576 106.4576 0 0 0-4.1088-0.1408c-0.576-0.0128-1.1264-0.064-1.7024-0.064-0.3328 0-0.6912 0.0256-1.024 0.0384-1.3952 0.0128-2.8288 0.0768-4.2624 0.1408-0.9472 0.0384-1.8688 0.0768-2.8288 0.1408-1.472 0.1024-2.9824 0.2688-4.4928 0.4224-0.9472 0.1024-1.8944 0.192-2.8672 0.3072-1.5744 0.2048-3.1744 0.4736-4.7744 0.7424-0.9216 0.1536-1.8304 0.2816-2.7648 0.448-1.792 0.3328-3.6096 0.7424-5.4272 1.152-0.6656 0.1536-1.3184 0.256-1.9968 0.4224 18.9952-23.3344 24.9216-29.0944 26.4704-30.4128 1.6384-1.408 3.264-2.88 4.8896-4.3776 10.752-9.8432 17.8688-16.3584 42.24-7.104 8.64 3.2768 16.384 6.9888 23.8848 10.5856 24.6656 11.8144 47.9488 22.9632 88.192 12.352 12.416-3.3536 19.7632-5.6576 25.1392-7.3344 4.544-1.4208 7.0528-2.2016 9.6128-2.6624 11.5968-2.1376 19.776-0.2176 24.5888 15.8208 2.7008 8.9984 6.4384 18.8672 10.3936 29.2992 10.3936 27.4304 22.1696 58.496 19.264 84.1728z" fill="#333B44" ></path></symbol><symbol id="icon-shengxiaoyang" viewBox="0 0 1024 1024"><path d="M977.344 373.9392c18.56-132.864-119.3216-229.0048-223.232-213.6192-60.928 9.024-150.8992 56.832-214.9504 94.8608 53.76 8.1536 78.8864 31.2448 88.8832 55.3984l0.8192-0.1152c24.8064 19.3536 49.5488 48.1152 57.8432 88.7424 0.0512-0.0384 0.1152-0.0768 0.1792-0.1152-4.5952-22.4768-14.208-41.344-26.1248-56.96 22.8864 6.272 73.6768 14.4256 150.4512-4.7616 30.7968-9.6256 82.112 3.2128 109.056 23.7312-14.016 29.0304-36.7616 54.3872-78.0672 68.2624-26.0736 40.2816-48.9216 62.4768-84.5568 106.5344-36.5696 45.2224-72.1664 160.6912 14.4384 191.488 82.3552 29.2864 142.9632-21.504 177.664-109.312 0.7808-1.9584-1.8432-3.456-3.136-1.792-29.9904 38.1824-77.0304 47.7184-103.3216 29.312-28.864-20.2112 5.0176-54.8224 22.4896-73.6128 18.2528-19.6224 95.5264-83.2128 111.5648-198.0416z" fill="#FF7443" ></path><path d="M348.5696 373.7088zM345.9072 380.5824c-0.4864 1.344-0.9472 2.7136-1.3824 4.096 0.448-1.3824 0.9088-2.752 1.3824-4.096zM352.0768 365.9392zM343.6928 387.3408zM341.8112 394.2528z" fill="#E17547" ></path><path d="M269.6704 160.32c-103.9232-15.3984-241.792 80.7552-223.232 213.6192 16.0384 114.8288 93.312 178.4192 111.5776 198.0544 17.472 18.7904 51.3536 53.4016 22.4896 73.6128-26.2912 18.4064-73.3312 8.8704-103.3216-29.312-1.3056-1.6512-3.9168-0.1664-3.136 1.792 34.7008 87.808 95.3088 138.5856 177.664 109.312 86.6048-30.7968 50.9952-146.2528 14.4384-191.488-36.16-44.7232-59.1488-66.8928-85.7088-108.3264-38.1568-14.208-59.6224-38.656-73.0624-66.4832 26.944-20.5312 78.2592-33.3568 109.056-23.7312 76.736 19.1872 127.5136 11.0464 150.4128 4.7744 9.5616-12.5696 20.5824-23.0656 31.6288-31.68l0.2176 0.0256c12.736-35.6992 50.0352-51.584 84.096-56.3968-63.9232-37.8368-152.768-84.8256-213.12-93.7728z" fill="#FF7443" ></path><path d="M364.288 345.664c-0.256 0.3584-0.5248 0.7168-0.7936 1.088 0.2688-0.3712 0.5376-0.7168 0.7936-1.088zM355.0848 360.2048zM358.2592 354.752c-0.6272 1.024-1.2416 2.0736-1.856 3.1232 0.6144-1.0624 1.2288-2.0992 1.856-3.1232zM361.5232 349.6576z" fill="#E17547" ></path><path d="M346.7904 393.2288c-1.7792 0-3.5712-0.32-5.3376-0.9856-6.0288-2.2784-9.7408-8.0256-9.7408-14.1056 0-1.7664 0.32-3.5712 0.9856-5.3376 0.6272-1.664 1.2928-3.3024 1.9712-4.928 3.2256-7.68 12.0448-11.2896 19.7376-8.064 5.7728 2.4192 9.2544 8.0128 9.2544 13.9136 0 1.9456-0.384 3.9168-1.1776 5.824-0.5504 1.3056-1.0752 2.6112-1.5744 3.9552-2.304 6.016-8.0384 9.728-14.1184 9.728z" fill="#333B44" ></path><path d="M344.5376 399.7568c-1.5232 0-3.072-0.2304-4.5952-0.7168-7.936-2.5344-12.3008-11.0208-9.7664-18.944v-0.0128c0.4864-1.536 0.9984-3.0464 1.536-4.544 2.7904-7.8464 11.392-11.9552 19.2512-9.152 6.1696 2.2016 10.0224 8 10.0224 14.208 0 1.6768-0.2816 3.3792-0.8832 5.056-0.4224 1.2032-0.832 2.4192-1.2288 3.648-2.0352 6.3744-7.9616 10.4576-14.336 10.4576z" fill="#333B44" ></path><path d="M349.312 386.9696a14.848 14.848 0 0 1-5.9904-1.2544 15.08096 15.08096 0 0 1-9.0752-13.8368c0-2.0096 0.3968-4.0448 1.2544-5.9904 0.9728-2.2272 1.984-4.416 3.0336-6.5536 0.0128-0.0256 0.0256-0.0384 0.0256-0.064v-0.0128c3.6864-7.4624 12.7232-10.5216 20.1984-6.8352 7.4624 3.6864 10.5216 12.7232 6.8352 20.1856-0.8448 1.7024-1.6384 3.4304-2.4064 5.1968-0.0128 0.0256-0.0256 0.064-0.0384 0.0896a15.08096 15.08096 0 0 1-13.8368 9.0752z" fill="#333B44" ></path><path d="M342.5408 406.6304c-1.2672 0-2.56-0.1664-3.8528-0.4992-6.7584-1.7792-11.2384-7.8848-11.2384-14.5536 0-1.2672 0.1664-2.5728 0.4992-3.8528 0.4224-1.5744 0.8448-3.136 1.2928-4.672 2.3808-7.9744 10.752-12.5312 18.752-10.1504 6.5408 1.9456 10.7776 7.9488 10.7776 14.4384 0 1.4208-0.2048 2.8672-0.6272 4.3008-0.3712 1.2416-0.7168 2.496-1.0368 3.7504-1.7792 6.7584-7.8976 11.2384-14.5664 11.2384z" fill="#333B44" ></path><path d="M340.4544 415.616c-0.9472 0-1.92-0.0896-2.88-0.2816-7.2064-1.3952-12.2112-7.7056-12.2112-14.784 0-0.9472 0.0896-1.9072 0.2816-2.88 0.448-2.304 0.9344-4.5696 1.472-6.8096l0.0384-0.1664c1.9584-8.0896 10.0992-13.0688 18.2016-11.0976 8.0896 1.9584 13.0688 10.0992 11.1104 18.2016v0.0128a108.9536 108.9536 0 0 0-1.2032 5.5424c0 0.0128 0 0.0256-0.0128 0.0512-1.3952 7.2064-7.7184 12.2112-14.7968 12.2112zM363.4944 361.6c-2.9952 0-6.0032-0.8832-8.6144-2.7392-4.16-2.9696-6.4128-7.5904-6.4128-12.3008 0-2.9568 0.8832-5.9392 2.752-8.5504l0.5504-0.7424c4.8384-6.784 14.3616-8.5376 21.1456-3.712 4.16 2.9696 6.4128 7.5904 6.4128 12.3008 0 2.9568-0.8832 5.9392-2.752 8.5504l-0.5504 0.7424c-2.9696 4.1856-7.7312 6.4512-12.5312 6.4512z" fill="#333B44" ></path><path d="M352.8192 379.5712c-2.2912 0-4.6208-0.5248-6.8096-1.6256-7.424-3.7632-10.3936-12.8128-6.6432-20.2368 0.8192-1.6128 1.6512-3.2128 2.5088-4.7744 4.0192-7.296 13.184-9.9456 20.48-5.9264 4.9792 2.752 7.7952 7.8976 7.7952 13.2224 0 2.4576-0.6144 4.9536-1.8816 7.2576-0.6912 1.2544-1.3568 2.5472-2.0224 3.84-2.6496 5.2224-7.936 8.2432-13.4272 8.2432z" fill="#333B44" ></path><path d="M356.4032 372.9408c-2.56 0-5.1584-0.6528-7.5392-2.0352-7.2064-4.1728-9.664-13.3888-5.504-20.5952 0 0 0-0.0128 0.0128-0.0128 0.3584-0.6016 0.704-1.216 1.0624-1.8048 0.32-0.5376 0.64-1.0752 0.9728-1.6128 4.3392-7.104 13.6192-9.344 20.7104-5.0048 7.104 4.3392 9.3568 13.6064 5.0176 20.7104 0 0 0 0.0128-0.0128 0.0128 0 0.0128-0.0128 0.0128-0.0128 0.0256-0.2944 0.4736-0.576 0.96-0.8576 1.4464-0.2688 0.448-0.5248 0.9088-0.7936 1.3568a15.07328 15.07328 0 0 1-13.056 7.5136z" fill="#333B44" ></path><path d="M359.8848 367.2064c-2.7904 0-5.6064-0.768-8.1152-2.3936-4.4928-2.88-6.9376-7.744-6.9376-12.7104 0-2.7904 0.768-5.6064 2.3808-8.1152 0.5888-0.9216 1.1904-1.8304 1.8048-2.7392 4.6336-6.912 14.0032-8.768 20.9152-4.1216 4.3392 2.9056 6.6816 7.68 6.6816 12.5312 0 2.8928-0.8192 5.8112-2.56 8.384-0.4864 0.7296-0.9728 1.472-1.4592 2.2144a15.06176 15.06176 0 0 1-12.7104 6.9504z" fill="#333B44" ></path><path d="M262.6432 531.6224c0.0896 0.192 37.0944 82.2784-34.9824 116.8768-29.824 12.5056-77.9136 19.8016-108.5056 0-0.0128-0.0256-0.0128-0.064-0.0256-0.0896-15.104-6.144-29.9136-16.8064-41.9584-32.1408-1.2928-1.6512-3.904-0.1408-3.136 1.8048 34.7008 87.8208 95.3088 138.6112 177.6768 109.3248 86.6048-30.7968 50.9952-146.2528 14.4384-191.488-1.2032-1.472-2.3424-2.8672-3.5072-4.288z" fill="#FED590" ></path><path d="M761.1392 531.6224c-0.0896 0.192-37.0944 82.2784 34.9824 116.8768 29.824 12.5056 77.9136 19.8016 108.5056 0 0.0128-0.0256 0.0128-0.064 0.0256-0.0896 15.104-6.144 29.9136-16.8064 41.9584-32.1408 1.2928-1.6512 3.904-0.1408 3.136 1.8048-34.7008 87.8208-95.3088 138.6112-177.6768 109.3248-86.6048-30.7968-50.9952-146.2528-14.4384-191.488 1.1904-1.472 2.3424-2.8672 3.5072-4.288z" fill="#FED590" ></path><path d="M515.8272 252.6976c-44.6336-2.7904-121.0624 14.1184-121.7024 84.672s71.2064 48.1152 85.9648 47.4752c14.7584-0.64 37.2096-4.4928 67.9936-0.64 30.7968 3.8528 73.1264 14.1184 83.392-26.304 8.3328-34.6368-2.5728-98.1504-115.648-105.2032z" fill="#FED590" ></path><path d="M754.112 160.32c-60.928 9.024-150.8992 56.832-214.9504 94.8608 44.6336 6.7712 69.568 23.808 82.4448 43.2384 63.552-36.6464 147.8272-76.928 215.8976-80.3584 34.5984 0 116.0832 12.8128 141.44 134.2848 1.792-121.4976-126.6432-206.5664-224.832-192.0256zM482.7904 254.1056c-63.936-37.8496-152.768-84.8384-213.12-93.7728-98.1888-14.5408-226.624 70.5152-224.832 192.0256 25.3568-121.4848 106.8416-134.2848 141.44-134.2848 68.6592 3.4688 153.7664 44.4032 217.5104 81.3056 15.8592-27.968 48.7168-40.9984 79.0016-45.2736z" fill="#FED590" ></path><path d="M343.104 429.376s76.1856-26.4576 90.1504 66.3936c-7.2192 68.3136-10.5728 75.2384-10.5728 75.2384s-86.9632-20.8768-79.5776-141.632z" fill="#FFFFFF" ></path><path d="M678.5024 429.376s-76.1856-26.4576-90.1504 66.3936c7.2192 68.3136 10.5728 75.2384 10.5728 75.2384s86.976-20.8768 79.5776-141.632z" fill="#FFFFFF" ></path><path d="M694.5024 447.2064c0.3072-29.5808 39.4496 47.2064 47.1552 94.4768-32.7168 70.4512-26.944 147.968-5.7728 171.7248 6.7328 30.5024-57.728 182.272-213.5936 182.272s-210.6752-112.128-241.152-176.2048c43.6864-56.768 20.2112-107.4176 2.9824-155.1616s45.696-117.12 45.696-117.12 34.432 108.6976 80.7168 124.416c-3.4176 58.3808-8.2304 110.656-8.2304 110.656s38.1696 94.1952 122.8416 94.1952c32.1408-12.3392 104.8832-47.36 96.2176-132.0448-17.3184-58.0352-8.8192-71.3216-8.8192-71.3216s80.9984-32.832 81.9584-125.888z" fill="#FF8431" ></path><path d="M366.8864 342.144c-22.8864 6.272-73.6768 14.4256-150.4512-4.7616-30.7968-9.6256-82.112 3.2128-109.056 23.7312 25.9712 53.7984 81.7792 95.0528 230.5536 73.8304-1.536-39.04 11.1616-69.504 28.9536-92.8z" fill="#FDD59A" ></path><path d="M660.7488 342.144c22.8864 6.272 73.6768 14.4256 150.4512-4.7616 30.7968-9.6256 82.112 3.2128 109.056 23.7312-25.9712 53.7984-81.7792 95.0528-230.5536 73.8304 1.536-39.04-11.1616-69.504-28.9536-92.8z" fill="#FDD59A" ></path><path d="M107.3792 361.1136c25.9712 53.7984 81.7792 95.0528 230.5536 73.8304-103.0272-119.9104-230.5536-73.8304-230.5536-73.8304z" fill="#FDF2D6" ></path><path d="M920.256 361.1136c-25.9712 53.7984-81.7792 95.0528-230.5536 73.8304 103.0272-119.9104 230.5536-73.8304 230.5536-73.8304z" fill="#FDF2D6" ></path><path d="M385.408 329.7792s-39.1168 39.3472-41.7152 87.2448c53.7984 4.4928 106.2656-7.7824 94.4768 64.1536-11.776 71.9232-26.5984 153.5488-19.5072 193.088s41.6256 97.5104 95.232 97.5104 97.856-60.4672 93.376-108.8128c-4.4928-48.3456-21.4912-159.9616-17.4848-174.6432 4.0064-14.6816-0.4736-73.216 97.024-66.1504-3.8528-58.3808-36.928-86.272-47.0144-88.0384-3.0208 25.8176-20.4288 65.9712-62.3616 57.4336s-108.0704-2.7904-119.6288-2.816c-11.584-0.0384-72.2944 7.104-72.3968-58.9696z" fill="#FDF2D6" ></path><path d="M464.1792 599.9872c15.552 3.8016 52.7616 10.4832 98.112 1.8304 3.8784-0.7424 7.6928 1.7408 8.3712 5.632 3.3536 19.52-0.448 29.2224-19.0592 38.7968-17.1776 8.8448-29.7088 22.3232-30.6048 44.6336-0.1664 4.1472 3.4688 7.5136 7.6032 7.2192 34.944-2.4832 44.736-9.3696 48.3328-2.7648 3.8528 7.0528-15.2064 30.7968-64.0512 30.7968s-67.456-17.3184-63.6032-28.864c3.456-10.3552 20.1728-0.7296 42.432 1.0112 4.2624 0.3328 7.7824-3.3408 7.4752-7.6032-1.664-23.2704-6.1312-39.0656-22.336-46.0032-16.1664-6.9248-22.976-14.8992-21.376-38.4 0.32-4.352 4.4928-7.3088 8.704-6.2848z" fill="#F7935C" ></path><path d="M762.8416 455.7312c-22.848 0-47.8976-1.9712-75.264-5.8752-7.6544-1.088-13.2352-7.7952-12.9408-15.5136 1.216-31.0272-7.488-58.9696-25.8688-83.0592a15.05536 15.05536 0 0 1-0.512-17.5744c3.6224-5.3632 10.2272-7.8208 16.4864-6.1056 21.9264 6.016 69.5808 13.3888 142.4128-4.7488 37.4912-11.4432 93.376 4.2752 122.24 26.2656 5.696 4.3392 7.552 12.096 4.4416 18.5472-28.6464 59.3408-83.7504 88.064-170.9952 88.064z m-58.0736-33.9968c127.9744 15.6672 173.6064-18.7264 195.6608-55.5264-25.6-14.1568-63.4112-21.1072-84.736-14.4384-0.2688 0.0896-0.5504 0.1664-0.8448 0.2432-53.2864 13.312-94.8864 13.9648-124.032 10.8928 8.4608 18.2912 13.12 37.952 13.952 58.8288z" fill="#333B44" ></path><path d="M876.8 582.272c1.9584-2.0992 4.6336-4.736 7.8464-7.9104 27.7376-27.3664 92.6976-91.456 107.6224-198.336 6.0672-43.4176-3.0464-85.7984-25.7664-123.2128-0.1664-0.2816-0.3328-0.5504-0.4992-0.832-1.6384-2.6752-3.3408-5.312-5.12-7.9232-0.3584-0.5376-0.7296-1.0752-1.1008-1.6-1.6512-2.3808-3.3536-4.7488-5.1328-7.0912-0.5504-0.7296-1.1264-1.4592-1.6896-2.1888-1.6768-2.1632-3.392-4.3136-5.1712-6.4256-0.704-0.832-1.4208-1.6512-2.1376-2.4832-1.7664-2.0352-3.5456-4.0576-5.4016-6.0544-0.7168-0.7808-1.472-1.536-2.2016-2.304-1.408-1.472-2.7776-2.9824-4.2368-4.4288-0.5504-0.5504-1.1392-1.0496-1.7024-1.6-0.7936-0.768-1.6128-1.5104-2.4192-2.2656a239.1552 239.1552 0 0 0-32.256-25.536c-1.2544-0.832-2.4832-1.7024-3.7504-2.5088-1.5744-0.9984-3.1872-1.92-4.7744-2.88-2.0608-1.2416-4.1088-2.496-6.1952-3.6736-1.2928-0.7296-2.6112-1.3952-3.9168-2.0992-2.432-1.3184-4.8768-2.624-7.3472-3.84-1.1392-0.5632-2.2912-1.088-3.4432-1.6384-2.6624-1.2672-5.3376-2.5088-8.0384-3.6736-1.0496-0.4608-2.112-0.8832-3.1744-1.3184-2.816-1.1648-5.632-2.2912-8.4736-3.3408-1.0112-0.3712-2.0224-0.7296-3.0464-1.088-2.8928-1.024-5.7856-1.9968-8.6912-2.8928-0.9984-0.3072-2.0096-0.6144-3.0208-0.9088-2.9184-0.8576-5.8368-1.6512-8.768-2.3808-1.024-0.256-2.048-0.512-3.072-0.7552-2.9056-0.6784-5.8112-1.2928-8.7168-1.8432-1.0496-0.2048-2.0992-0.4096-3.1616-0.5888-2.8672-0.4992-5.7344-0.9216-8.6016-1.3056-1.088-0.1408-2.1632-0.2944-3.2512-0.4224-2.8288-0.32-5.6448-0.5632-8.4608-0.7552-1.1008-0.0768-2.2144-0.1792-3.3152-0.2432-2.816-0.1536-5.6064-0.192-8.3968-0.2176-1.0752-0.0128-2.1632-0.0512-3.2384-0.0384-2.9056 0.0384-5.7984 0.1792-8.6656 0.3584-0.9216 0.0512-1.856 0.064-2.7776 0.1408-3.776 0.2944-7.5264 0.704-11.2256 1.2544-61.7344 9.152-150.4896 55.5776-215.7952 94.08-6.208-0.8064-12.6464-1.4208-19.3408-1.8432-9.4464-0.5888-19.9424-0.3712-30.784 0.832-64.7296-38.0544-152.768-83.9936-214.0928-93.0816-3.6864-0.5504-7.3984-0.9472-11.1488-1.2416-1.1648-0.0896-2.3296-0.1024-3.5072-0.1664-2.624-0.1536-5.248-0.2944-7.8848-0.32-1.3184-0.0128-2.6496 0.0384-3.9808 0.0512-2.5344 0.0256-5.056 0.064-7.6032 0.192-1.344 0.064-2.688 0.192-4.032 0.2944-2.56 0.192-5.12 0.3968-7.6928 0.6912-1.3184 0.1536-2.624 0.3456-3.9424 0.512-2.624 0.3456-5.2608 0.7296-7.8848 1.1904-1.2672 0.2176-2.5216 0.4608-3.776 0.704-2.688 0.5248-5.3888 1.088-8.0768 1.7152-1.216 0.2816-2.432 0.5888-3.648 0.8832-2.7264 0.6912-5.4528 1.4336-8.1792 2.2272-1.1776 0.3456-2.3552 0.6912-3.5328 1.0624-2.7392 0.8448-5.4656 1.7664-8.192 2.7264-1.1648 0.4096-2.3296 0.8192-3.4944 1.2416-2.688 0.9984-5.3632 2.0608-8.0384 3.1616-1.1904 0.4864-2.3808 0.96-3.5584 1.472-2.5728 1.1136-5.1328 2.304-7.68 3.5072-1.2544 0.5888-2.5088 1.1648-3.7632 1.7792-2.368 1.1776-4.7104 2.432-7.0528 3.6864-1.3952 0.7424-2.7904 1.4592-4.1728 2.24-2.0096 1.1264-3.9808 2.3424-5.952 3.5328-1.664 0.9984-3.3536 1.9712-5.0048 3.008-1.1776 0.7424-2.3168 1.5488-3.4816 2.3168a238.2784 238.2784 0 0 0-32.5248 25.7152c-0.7936 0.7552-1.6256 1.4976-2.4064 2.2528-0.5632 0.5376-1.152 1.0496-1.7024 1.6-1.4592 1.4464-2.8288 2.9568-4.2368 4.4288-0.7296 0.768-1.4848 1.5232-2.2016 2.304-1.856 1.9968-3.6352 4.0192-5.4016 6.0544-0.7168 0.832-1.4336 1.6512-2.1376 2.4832-1.7792 2.1248-3.4944 4.2624-5.1712 6.4256-0.5632 0.7296-1.1392 1.4592-1.6896 2.1888-1.7664 2.3424-3.4688 4.7104-5.1328 7.0912-0.3712 0.5376-0.7424 1.0624-1.1008 1.6-1.7792 2.6112-3.4816 5.2608-5.12 7.9232-0.1664 0.2688-0.3328 0.5504-0.4992 0.832-22.7328 37.4528-31.8464 79.8464-25.792 123.2512 14.9248 106.88 79.8848 170.9696 107.6224 198.336 3.2128 3.1744 5.888 5.8112 7.8464 7.9104l1.7408 1.8816c9.4464 10.1248 29.0944 31.1808 27.8912 42.7136-0.1024 0.9856-0.3456 3.3152-4.7488 6.4-11.776 8.2432-31.1808 8.4608-50.2016-0.2304-0.1792-0.0768-0.3584-0.1536-0.5248-0.2304-1.8048-0.8448-3.6096-1.7536-5.4016-2.7648-0.064-0.0384-0.128-0.064-0.1792-0.1024a84.58752 84.58752 0 0 1-10.688-7.1552c-0.5504-0.4224-1.0752-0.8832-1.6128-1.3184-1.088-0.896-2.176-1.8176-3.2512-2.7776-0.6656-0.6016-1.3312-1.216-1.984-1.8432-0.9472-0.896-1.8688-1.8432-2.7904-2.8032-0.64-0.6656-1.2928-1.3312-1.9072-2.0224-1.1904-1.3184-2.368-2.7008-3.5072-4.1216-0.2688-0.3328-0.5504-0.6272-0.8064-0.96-5.2352-6.6432-14.3616-8.3968-21.696-4.1856-6.4256 3.6992-9.5744 10.88-8.1664 17.8944 0.2048 0.9984 0.4992 2.0096 0.8832 2.9952 5.0944 12.9024 10.7136 24.7552 16.6912 35.7504 32.4992 59.776 77.5168 91.4432 129.6384 91.4304 13.6832 0 27.8656-2.2016 42.4192-6.6048 2.6496-0.8064 5.312-1.6512 7.9872-2.6112 4.288-1.5232 8.32-3.3152 12.2112-5.248 21.056 52.4544 93.0944 174.5024 246.848 174.5024 151.0016 0 220.3392-126.5536 240.8704-173.5296a113.0368 113.0368 0 0 0 10.3168 4.2752c17.3824 6.1824 34.2272 9.216 50.4064 9.216 55.232 0 102.4896-35.52 135.3216-102.4256 3.8528-7.8592 7.5648-16.064 11.008-24.7808 0.32-0.7936 0.5248-1.6 0.704-2.4192 1.6896-7.1936-1.4208-14.6688-8.0256-18.4448-7.3472-4.224-16.4608-2.4448-21.696 4.1984-0.1664 0.2176-0.3456 0.4096-0.512 0.6144-1.2416 1.5616-2.5216 3.0464-3.8144 4.4928-0.5888 0.6528-1.2032 1.2672-1.8048 1.8944-0.96 0.9984-1.92 1.9712-2.9056 2.9184-0.6272 0.6016-1.2672 1.1904-1.9072 1.7792-1.1008 0.9856-2.2016 1.9328-3.328 2.8544-0.512 0.4224-1.024 0.8576-1.5488 1.2672a86.46016 86.46016 0 0 1-10.688 7.1552c-0.0768 0.0384-0.1536 0.0768-0.2304 0.128-1.7664 0.9856-3.5456 1.8944-5.3248 2.7264-0.2048 0.0896-0.4096 0.1792-0.6144 0.2816-19.008 8.6656-38.3744 8.4608-50.1504 0.2048-4.4032-3.0848-4.6464-5.4016-4.7488-6.4-1.216-11.5328 18.4448-32.5888 27.8912-42.7136l1.7664-1.8816z m9.1904-371.6096c-19.0336-6.2336-36.4544-7.68-48.4864-7.68-0.256 0-0.4992 0.0128-0.7552 0.0256-67.9808 3.4304-150.4512 41.7792-211.328 75.904-0.3968-0.4224-0.8192-0.8192-1.2288-1.2416a93.0688 93.0688 0 0 0-2.496-2.5344c-0.6912-0.6784-1.4208-1.3312-2.1376-1.9968a94.3616 94.3616 0 0 0-2.9312-2.5984c-0.6272-0.5248-1.2672-1.0368-1.9072-1.5488-1.1648-0.9472-2.3552-1.8688-3.584-2.7776-0.4608-0.3456-0.9472-0.6656-1.4208-0.9984-1.4592-1.0368-2.944-2.0608-4.48-3.0336-0.1792-0.1152-0.3584-0.2176-0.5248-0.32-7.6288-4.8128-16.1408-8.9472-25.6-12.3648 50.688-28.5312 109.6576-57.8048 156.3392-69.888 0.5248-0.1408 1.0752-0.3072 1.5872-0.4352 2.0096-0.4992 3.9296-0.9088 5.888-1.344 1.3184-0.2944 2.6752-0.64 3.968-0.9088 3.2128-0.6528 6.3616-1.216 9.4208-1.664 2.9952-0.448 6.0288-0.7552 9.088-0.9984 0.8448-0.064 1.7024-0.1024 2.56-0.1536 2.2656-0.1408 4.5312-0.2304 6.8224-0.2688 0.9472-0.0128 1.8816-0.0128 2.8288-0.0128 2.3424 0.0128 4.7104 0.0768 7.0784 0.2048 0.7936 0.0384 1.5872 0.064 2.3808 0.1152 6.3744 0.4224 12.8128 1.216 19.2512 2.4064 0.7168 0.128 1.4208 0.2944 2.1376 0.4352 2.4704 0.4864 4.928 1.0112 7.3984 1.6 1.0112 0.2432 2.0096 0.4992 3.0208 0.7552 2.2144 0.5632 4.416 1.1904 6.6304 1.8432 1.0496 0.3072 2.0992 0.6144 3.1616 0.9472 2.3296 0.7296 4.6592 1.536 6.9888 2.368 0.8576 0.3072 1.7024 0.576 2.56 0.896 2.9696 1.1008 5.9136 2.2912 8.8448 3.5328 1.3952 0.5888 2.7648 1.2416 4.1472 1.8688 1.5872 0.7168 3.1744 1.4336 4.7488 2.2016 1.6384 0.7936 3.2768 1.6256 4.9024 2.4704 1.2416 0.64 2.4832 1.3056 3.7248 1.9712 1.7792 0.9728 3.5712 1.9456 5.3248 2.9696 0.9088 0.5248 1.8048 1.0752 2.7136 1.6256 4.5184 2.6624 8.9984 5.5424 13.3632 8.6272zM671.872 401.9968c0.4352 2.112 0.832 4.2368 1.1648 6.3744-17.5744-1.6-42.9824-0.3328-63.9744 15.104-9.5488 7.0144-16.9984 16.2176-22.5792 27.2768-1.7536-4.3904-3.456-8.1408-5.0944-11.008-4.1344-7.232-13.3248-9.7664-20.5696-5.632-7.232 4.1216-9.7536 13.3248-5.632 20.5568 14.6176 25.6384 42.2784 160 42.2784 205.3632 0 10.2656-1.8432 21.6832-5.4528 33.024-0.384-1.728-0.9856-3.392-1.8432-4.9664-7.296-13.3632-21.1456-10.9312-32.256-8.96-5.1712 0.9088-11.7632 2.0736-20.3904 3.008 2.7776-9.4592 9.5232-16.6016 20.9792-22.5024 23.7696-12.2368 31.6032-28.096 27.008-54.7456-0.9984-5.8496-4.2496-10.9312-9.1392-14.3232-4.8896-3.392-11.0336-4.6848-16.9088-3.5712-43.0464 8.2176-78.4768 1.5744-91.712-1.664-6.3872-1.5616-13.056-0.2304-18.3424 3.6352-5.248 3.84-8.5248 9.7664-8.96 16.2432-1.92 28.1216 6.6304 43.0592 30.4768 53.2864 6.0032 2.5728 10.112 7.552 12.2624 23.4112-3.2-0.5888-6.2592-1.2544-9.1264-1.8944-12.16-2.688-32.5376-7.1808-39.0784 12.4544-0.2432 0.7296-0.4096 1.4848-0.5888 2.2272-3.456-10.6624-5.4016-21.1712-5.9648-30.336-0.9088-28.672 3.3152-61.2224 9.3952-92.0576 0.6656-1.6768 1.0752-3.5072 1.1008-5.4272v-0.064c12.4928-60.8512 31.616-113.6384 31.9104-114.4448 2.8672-7.8208-1.1648-16.4736-8.9856-19.328-7.8336-2.8672-16.4736 1.1648-19.3408 8.9728-0.256 0.6912-1.28 3.5456-2.8416 8.0768-7.232-14.7328-17.152-25.8432-29.7088-33.2032-19.1872-11.2512-40.1024-10.9184-55.5136-8.1664 3.1488-20.928 11.2512-40.192 24.4224-57.4464 0.0384-0.0512 0.064-0.1024 0.1024-0.1536 0.256-0.3456 0.5632-0.6656 0.8192-1.0112 1.984 16.8832 8.32 30.1568 19.072 39.4112 13.0816 11.264 29.76 14.3104 45.0432 14.3104 11.4048 0 22.0288-1.6896 29.7856-2.9312 2.7776-0.448 5.9136-0.9472 7.04-0.9984 3.6352-0.1536 7.7056-0.4992 12.224-0.8704 13.9008-1.1648 31.2192-2.624 53.248 0.128 2.8288 0.3584 5.76 0.768 8.7552 1.1776 29.3504 4.096 78.4896 10.9696 91.1744-38.912 0.6528-2.7264 1.3696-6.4512 1.8944-10.8288l0.4224 0.5376c11.776 15.4496 19.6352 32.448 23.424 50.8672z m29.7856-5.9264c-2.3552-11.4944-5.9904-22.5792-10.8672-33.1776 17.5232 1.856 39.5776 2.3296 65.9328-0.448-18.1504 9.1904-36.5184 21.568-54.4896 37.9904-0.0896-0.5248-0.2048-1.0368-0.3072-1.5616-0.0128-0.9344-0.0768-1.8688-0.2688-2.8032z m135.7312 19.0208c-0.8448 0.2816-1.6512 0.6528-2.432 1.0752-26.8544 8.4608-63.2448 12.0832-113.4592 7.3856 68.608-63.7568 142.6048-59.264 175.8464-52.8128-14.2208 21.1328-33.5872 35.4816-59.9552 44.352z m-79.4112 96.6656c-7.5008-21.6576-20.3648-41.9712-32.0512-57.5872 12.8896 1.0368 25.2032 1.5616 36.9152 1.5616 15.7696 0 30.4512-0.9728 44.16-2.8544-9.2672 11.9552-18.8288 23.2064-29.6448 35.9168-5.9392 6.976-12.4416 14.6176-19.3792 22.9632zM267.52 513.8176c-7.616-9.1904-14.6944-17.5232-21.1328-25.0752-10.9824-12.9024-20.6976-24.3456-30.1312-36.544 14.9376 2.3168 31.0656 3.52 48.5504 3.52 10.6368 0 21.7984-0.4736 33.3952-1.3184-11.7376 15.1168-23.8976 35.2384-30.6816 59.4176z m13.3504-150.464c7.168 0.5632 13.9776 0.8832 20.4416 0.9984 0.5888 0.0128 1.1776 0.0128 1.7664 0.0256 6.4256 0.0768 12.4928-0.0384 18.1888-0.3072l1.536-0.0768c4.928-0.2688 9.6128-0.6272 13.9904-1.088-0.704 1.5232-1.3312 3.072-1.9712 4.608-0.4608 1.088-0.9216 2.176-1.3568 3.2768-0.6272 1.5872-1.216 3.1744-1.7792 4.7744-0.4096 1.1392-0.7808 2.2784-1.1648 3.4176-0.5504 1.6512-1.088 3.3024-1.5872 4.9792-0.128 0.4352-0.2304 0.896-0.3584 1.3312-1.1264 3.9936-2.0736 8.0384-2.88 12.1344-0.1152 0.6016-0.2432 1.2032-0.3584 1.8176-0.064 0.32-0.128 0.64-0.192 0.9728-17.8816-16.32-36.1728-28.6208-54.2336-37.7728 2.6368 0.2816 5.248 0.5248 7.7952 0.7424 0.7168 0.0512 1.4464 0.1152 2.1632 0.1664z m17.2928 60.864c-2.2272 0.1792-4.4032 0.32-6.5792 0.4608-1.2288 0.0768-2.4832 0.1664-3.6864 0.2304-2.3936 0.1408-4.7232 0.2432-7.0528 0.3328-0.9344 0.0384-1.8944 0.0896-2.8288 0.1152-2.8288 0.1024-5.5936 0.1664-8.32 0.2048-0.384 0-0.7936 0.0256-1.1776 0.0256-6.3872 0.0768-12.5056-0.0256-18.3552-0.256l-0.6912-0.0384c-2.6112-0.1152-5.1712-0.256-7.68-0.4352-0.5888-0.0384-1.1648-0.0896-1.7536-0.1408-2.1248-0.1536-4.224-0.3328-6.2592-0.5376-0.7168-0.0768-1.408-0.1536-2.112-0.2304-1.8816-0.2048-3.7376-0.4096-5.5552-0.6528l-2.2272-0.3072c-1.7408-0.2432-3.4432-0.4992-5.12-0.768-0.7424-0.1152-1.472-0.2432-2.1888-0.3712-1.6384-0.2816-3.2512-0.5888-4.8384-0.896-0.704-0.1408-1.3952-0.2816-2.0864-0.4224-1.5872-0.3328-3.136-0.6784-4.6592-1.0368-0.64-0.1536-1.28-0.2944-1.9072-0.448-1.5744-0.384-3.0976-0.7936-4.608-1.216-0.5376-0.1536-1.088-0.2944-1.6128-0.4352-1.6512-0.4736-3.2512-0.96-4.8384-1.472-0.3584-0.1152-0.7168-0.2176-1.0752-0.3328-0.9856-0.32-1.92-0.6656-2.8672-0.9984-0.7552-0.448-1.5488-0.832-2.3808-1.152-24.064-8.96-41.9584-22.7456-55.3216-42.5984 33.3184-6.1696 107.5968-10.3424 175.6928 52.6464-1.1904 0.1152-2.3936 0.2304-3.584 0.3328-1.4464 0.1536-2.8928 0.2816-4.3264 0.3968z m57.4592 15.0144c0.832 10.9824 5.0816 24.4992 20.224 29.0048 14.8736 4.4288 25.344-4.4416 31.7568-13.2864 8.0768 11.2384 13.184 27.8528 15.2832 49.6256-3.7248 13.5296-7.552 28.5696-11.0464 44.4032-18.4704-6.5152-51.8144-29.12-58.5088-107.6736-0.0384-0.4992-0.0512-0.9856-0.0896-1.472 0.768-0.2048 1.5488-0.4096 2.3808-0.6016z m97.8048 292.0192c-0.64-1.1648-1.4592-2.24-2.4192-3.2128-0.2816-0.384-0.5632-0.7552-0.8448-1.152 13.8496 9.3056 35.4432 14.3104 62.72 14.3104 31.5392 0 53.376-9.1648 65.9584-19.6864a108.20224 108.20224 0 0 1-4.672 6.7968c-0.6528 0.704-1.216 1.4592-1.7152 2.2528-14.1568 17.9584-34.0864 30.848-59.2384 30.848-26.5216-0.0128-46.1312-12.7744-59.7888-30.1568z m103.3472-113.1776c0.192 7.232-2.7776 9.984-12.0704 14.7712-16.4096 8.4352-27.6608 19.8016-33.6768 33.9072-3.7504-15.4368-11.4432-28.7744-28.2112-35.968-7.6672-3.2768-11.584-4.9664-12.352-14.0032 19.3536 3.7504 49.9712 6.9888 86.3104 1.2928z m-38.4128 92.8512c-5.2096 0.2176-10.9312 0.1024-15.7568-0.1792 1.856-0.9984 3.584-2.2656 5.1072-3.7888 0.9088-0.896 1.728-1.856 2.4448-2.88 0.7296 0.9984 1.5488 1.9328 2.4448 2.816 1.7152 1.664 3.6736 3.0208 5.76 4.032z m85.696-200.2944c0.448-1.408 0.768-2.8672 0.7936-4.416 0.2688-22.6944 5.184-39.744 14.5024-51.072 6.4256 8.7808 16.8576 17.4976 31.616 13.1072 15.5008-4.608 19.5712-18.6624 20.2624-29.7728 1.0112 0.1024 1.984 0.2176 2.9184 0.3328-0.064 0.832-0.064 1.6512-0.1408 2.496-7.0656 82.9312-43.84 103.5136-61.3632 108.6336-2.688-13.4016-5.5808-26.7264-8.5888-39.3088z m-97.7152-243.1488c2.9568 0 5.824 0.0896 8.5376 0.256 7.7184 0.4864 15.0272 1.28 21.9648 2.3296 0.0128 0 0.0384 0.0128 0.0512 0.0128 3.84 0.576 7.488 1.28 11.072 2.0352 0.8704 0.1792 1.7664 0.3584 2.624 0.5504 2.9952 0.6784 5.8752 1.4208 8.6784 2.2144 1.4848 0.4224 2.9312 0.8576 4.3648 1.3184 1.3824 0.4352 2.7008 0.9088 4.032 1.3824 2.816 0.9984 5.5552 2.048 8.1536 3.1872 0.448 0.192 0.896 0.3968 1.3312 0.6016 8.768 3.9808 16.2048 8.7808 22.272 14.336 0.6528 0.6016 1.2672 1.216 1.8816 1.8304 1.3824 1.3696 2.688 2.7904 3.904 4.2496 0.9472 1.152 1.8688 2.3168 2.7264 3.52 2.4704 3.4688 4.5696 7.1296 6.1824 11.0208 0.0256 0.0768 0.0768 0.128 0.1152 0.2048 6.5024 15.8976 4.2112 31.0528 2.6368 37.632-5.0688 19.968-19.52 21.632-57.728 16.2944-3.136-0.4352-6.208-0.8704-9.1776-1.2416-25.1648-3.1488-45.0176-1.472-59.5072-0.256-4.0832 0.3456-7.744 0.6528-11.0208 0.7936-2.8544 0.128-6.2208 0.6656-10.4832 1.344-13.3376 2.1248-38.1696 6.0928-50.4064-4.4544-6.3232-5.44-9.4592-15.2576-9.3312-29.1712 0.0768-8.1024 1.3696-15.4112 3.7632-22.08 0.704-1.9712 1.5104-3.8528 2.3936-5.6576l0.1536-0.3072c0.7168-1.4464 1.536-2.816 2.3552-4.16 0.448-0.7296 0.896-1.4592 1.3696-2.1632 0.5888-0.8704 1.2032-1.7152 1.8304-2.5344 0.5888-0.7808 1.1776-1.5616 1.8048-2.304 0.5504-0.6528 1.1136-1.2672 1.6896-1.8816 0.2688-0.2944 0.5504-0.5888 0.832-0.8704 0.6272-0.6528 1.2288-1.3056 1.8944-1.9456 0.2944-0.2816 0.5888-0.5376 0.8832-0.8192 0.5504-0.4992 1.1008-0.9856 1.664-1.472 0.5888-0.512 1.1648-1.0368 1.7664-1.5232 0.64-0.5248 1.3184-0.9984 1.984-1.4976 0.768-0.576 1.5232-1.1648 2.3168-1.7152 0.7168-0.4864 1.4464-0.9472 2.176-1.408 0.7424-0.4736 1.472-0.9728 2.2272-1.4336 1.28-0.768 2.5856-1.4848 3.8912-2.176 0.2048-0.1024 0.3968-0.2304 0.6016-0.3328 4.6208-2.4064 9.3824-4.3776 14.0672-6.0032 0.1152-0.0384 0.2432-0.0896 0.3584-0.128 1.4208-0.4864 2.816-0.9344 4.2112-1.3568l0.7552-0.2304c1.2928-0.384 2.56-0.7424 3.8272-1.0752 0.3712-0.1024 0.7296-0.192 1.1008-0.2816 1.152-0.2944 2.2784-0.576 3.392-0.832 0.4864-0.1152 0.96-0.2176 1.4336-0.32 0.9984-0.2176 1.984-0.4352 2.944-0.6144 0.6016-0.1152 1.1776-0.2176 1.7664-0.3328 0.8192-0.1536 1.6384-0.3072 2.4192-0.4352 0.8064-0.1408 1.5744-0.2432 2.3552-0.3712 0.4992-0.0768 1.024-0.1664 1.5104-0.2304 0.1024-0.0128 0.192-0.0512 0.2944-0.064 7.2704-0.96 14.4512-1.4336 21.0944-1.4336zM276.8256 176.896c30.9504 6.3104 68.6976 21.7216 106.24 40.0768 20.5696 10.0608 41.0752 20.992 60.3648 31.8208-7.2192 2.8544-14.1952 6.3232-20.7488 10.4448-0.9728 0.6144-1.9584 1.2032-2.9312 1.856-0.8448 0.576-1.664 1.1904-2.496 1.7792-1.1648 0.832-2.3296 1.664-3.4688 2.56-0.7808 0.6144-1.5488 1.2672-2.3168 1.9072-1.088 0.9088-2.176 1.8304-3.2384 2.7904-0.2944 0.2688-0.6272 0.512-0.9216 0.7936-0.4096 0.384-0.7552 0.7936-1.152 1.1776-1.3312 1.28-2.624 2.6112-3.8912 3.9936-0.7936 0.8704-1.6 1.728-2.3552 2.624-0.2048 0.2432-0.448 0.4736-0.6528 0.7296-61.2864-34.4448-144.0512-72.9984-212.2496-76.4288-0.256-0.0128-0.4992-0.0256-0.7552-0.0256-12.032 0-29.4528 1.4464-48.4864 7.68 4.4928-3.1744 9.1008-6.1312 13.7728-8.9216 0.7168-0.4224 1.4208-0.8704 2.1376-1.28 1.92-1.1136 3.84-2.176 5.7856-3.2256 1.0368-0.5632 2.0736-1.1008 3.1104-1.6512 1.8176-0.9472 3.6352-1.8688 5.4656-2.752 1.2416-0.6016 2.496-1.1648 3.7504-1.7408 1.7024-0.7808 3.4048-1.5744 5.12-2.304 2.7904-1.1904 5.6064-2.3168 8.4224-3.3664 1.2672-0.4736 2.5344-0.8832 3.8016-1.3184 1.8816-0.6656 3.776-1.3184 5.6704-1.92 1.3184-0.4224 2.6368-0.7936 3.9552-1.1776 1.9072-0.5632 3.8016-1.088 5.7088-1.5872 1.2544-0.32 2.496-0.64 3.7504-0.9344 2.1248-0.4992 4.2496-0.96 6.3616-1.3824 1.024-0.2048 2.048-0.4352 3.072-0.6144 3.136-0.576 6.272-1.0752 9.408-1.4592 0.32-0.0384 0.64-0.064 0.96-0.1024 2.8288-0.3328 5.6576-0.6016 8.4736-0.7936 0.9728-0.064 1.9456-0.1024 2.9184-0.1408 2.1888-0.1024 4.3648-0.1664 6.5408-0.1792 1.0624 0 2.112 0 3.1616 0.0128 2.1888 0.0384 4.352 0.128 6.5152 0.256 0.9216 0.0512 1.856 0.0896 2.7648 0.1664 3.0336 0.2432 6.0544 0.5632 9.0368 0.9984 3.072 0.4352 6.1952 0.9856 9.3952 1.6384z m-106.048 386.6752l-1.728-1.8432c-2.176-2.3424-5.1584-5.2864-8.7552-8.832-25.5616-25.216-85.4272-84.2752-98.944-181.0432-0.832-5.9648-1.2928-11.9168-1.4464-17.8304 22.4256-104.768 88.32-120.7808 125.9904-120.8832 61.5808 3.2384 138.2656 38.8736 196.2368 71.2704-0.9088 0.7808-1.8304 1.5616-2.7264 2.3424-1.2416 1.1008-2.432 2.2272-3.648 3.3536-1.4208 1.3184-2.8672 2.6368-4.2368 3.9936-0.6784 0.6784-1.3184 1.3696-1.984 2.048-4.0448 4.1216-7.9104 8.32-11.4432 12.672-1.2288 0.2944-2.5344 0.5888-3.8784 0.8704-0.448 0.1024-0.896 0.192-1.3568 0.2816-1.5232 0.32-3.1104 0.6272-4.7872 0.9216-0.7168 0.128-1.5104 0.2432-2.2528 0.3712-1.216 0.2048-2.432 0.4096-3.7248 0.6016-0.896 0.128-1.856 0.2432-2.7904 0.3712-1.2288 0.1664-2.4576 0.3328-3.7376 0.4736-1.024 0.1152-2.112 0.2176-3.1744 0.32-1.2928 0.128-2.5984 0.256-3.9424 0.3712-1.1264 0.0896-2.2912 0.1664-3.456 0.256-1.3952 0.1024-2.7904 0.192-4.2368 0.2688-1.2032 0.064-2.4576 0.1024-3.6992 0.1536-1.4976 0.0512-3.008 0.1024-4.5568 0.1408-1.2928 0.0256-2.624 0.0384-3.9552 0.0512-1.5872 0.0128-3.2128 0-4.8512-0.0128-1.3824-0.0128-2.7904-0.0384-4.2112-0.0768-1.7024-0.0384-3.4432-0.1024-5.1968-0.1792-1.4592-0.064-2.9184-0.128-4.4032-0.2176-1.8176-0.1024-3.6864-0.2432-5.568-0.384-1.5232-0.1152-3.0464-0.2304-4.608-0.3712-1.9584-0.1792-3.968-0.384-5.9904-0.6016-1.5744-0.1664-3.136-0.3328-4.7488-0.5248-2.1248-0.256-4.3008-0.5632-6.4896-0.8704-1.5872-0.2176-3.1616-0.4224-4.7872-0.6784-2.3424-0.3584-4.7616-0.7808-7.1808-1.1904-1.5616-0.2688-3.0848-0.512-4.672-0.8064-2.7136-0.4992-5.5168-1.088-8.32-1.664-1.3696-0.2816-2.7008-0.5248-4.0832-0.832-4.224-0.9216-8.5376-1.92-12.9536-3.008-37.504-11.4432-93.376 4.2752-122.24 26.2656-0.2816 0.2176-0.512 0.4736-0.7808 0.704-0.2688 0.2304-0.5376 0.4608-0.7808 0.7168-0.128 0.128-0.2688 0.2304-0.3968 0.3584-0.3712 0.3968-0.6656 0.8448-0.9856 1.2672-0.1536 0.2048-0.32 0.384-0.4608 0.6016-0.5376 0.8064-0.9984 1.664-1.3696 2.5472-0.0128 0.0384-0.0384 0.064-0.0512 0.1024-0.064 0.1664-0.0896 0.3328-0.1408 0.4992-0.256 0.7168-0.4736 1.4336-0.6272 2.176-0.064 0.3328-0.1024 0.6528-0.1536 0.9856-0.0896 0.64-0.1408 1.28-0.1408 1.92 0 0.3456 0 0.6784 0.0128 1.0112 0.0384 0.6784 0.1408 1.344 0.2688 2.0096 0.0512 0.2944 0.0896 0.576 0.1664 0.8576 0.2432 0.9344 0.5632 1.8688 0.9984 2.7648 1.9456 4.0192 4.0192 7.872 6.208 11.6096 0.7552 1.2928 1.5744 2.496 2.3552 3.7504 1.472 2.3552 2.9568 4.6976 4.5184 6.9376 1.024 1.472 2.112 2.8672 3.1872 4.288 1.4464 1.92 2.9312 3.8016 4.4544 5.6192 1.1776 1.3952 2.3936 2.7648 3.6096 4.1088 1.6 1.7664 3.264 3.4688 4.9536 5.1456 1.216 1.2032 2.432 2.3936 3.6992 3.5456 1.9968 1.8304 4.0832 3.5712 6.1824 5.2864 1.0368 0.832 2.0352 1.7024 3.0976 2.5088 3.1744 2.432 6.464 4.7488 9.8944 6.912 0.0384 0.0256 0.064 0.0512 0.1024 0.064 7.5264 4.7744 15.6672 8.9088 24.3968 12.4672 17.5744 26.816 34.048 46.1568 52.9664 68.3776 8.2176 9.6512 16.7424 19.6864 26.1888 31.232 5.0688 12.3136 25.0496 69.3888-28.16 95.2064-5.5296 2.2912-11.5072 4.3008-17.728 5.952 1.6768-3.8656 2.5216-7.552 2.8544-10.6752 2.6624-25.1648-20.48-49.984-35.8016-66.4064z m75.8912 149.6192c-1.984 0.704-3.9552 1.3568-5.9008 1.9584-0.6656 0.2048-1.3184 0.3712-1.9712 0.5632-1.2672 0.3712-2.5472 0.7552-3.8016 1.0752-0.704 0.1792-1.3824 0.32-2.0736 0.4864-1.2032 0.2944-2.3936 0.5888-3.584 0.8448-0.7552 0.1536-1.4848 0.2688-2.2272 0.4096-1.1008 0.2048-2.2144 0.4352-3.3024 0.6144-0.7808 0.128-1.5488 0.2048-2.3168 0.32-1.0368 0.1408-2.0736 0.3072-3.0976 0.4224-0.7936 0.0896-1.5616 0.128-2.3424 0.2048-0.9856 0.0896-1.9712 0.192-2.944 0.256-0.8064 0.0512-1.6 0.0512-2.4064 0.0896-0.9216 0.0384-1.856 0.0896-2.7648 0.0896-0.8064 0.0128-1.6-0.0256-2.3936-0.0384-0.8832-0.0128-1.792-0.0128-2.6624-0.0512-0.7936-0.0384-1.5616-0.1024-2.3424-0.1536-0.8704-0.064-1.7408-0.1024-2.5984-0.1792-0.768-0.0768-1.536-0.1792-2.2912-0.2688-0.8448-0.1024-1.7024-0.1792-2.5344-0.3072-0.7424-0.1024-1.4592-0.256-2.1888-0.3712-0.8448-0.1408-1.7024-0.2816-2.5344-0.448-0.704-0.1408-1.3824-0.32-2.0736-0.4736-0.8448-0.192-1.6896-0.3712-2.5216-0.576-0.6784-0.1792-1.344-0.384-2.0224-0.5632-0.8192-0.2304-1.6512-0.448-2.4576-0.704-0.6656-0.2048-1.3056-0.4352-1.9712-0.6656-0.8064-0.2688-1.6128-0.5248-2.4064-0.8192-0.6528-0.2304-1.28-0.4992-1.92-0.7552-0.7808-0.3072-1.5744-0.6016-2.3424-0.9216-0.6272-0.256-1.2288-0.5504-1.8432-0.8192-0.7808-0.3456-1.5616-0.6784-2.3168-1.0496-0.576-0.2816-1.1392-0.576-1.7152-0.8704-0.7808-0.3968-1.5616-0.7808-2.3296-1.1904-0.5504-0.2944-1.088-0.6144-1.6256-0.9088-0.7808-0.4352-1.5488-0.8576-2.3168-1.3056-0.5248-0.3072-1.0368-0.64-1.5616-0.96-0.768-0.4736-1.536-0.9344-2.2912-1.4336-0.4864-0.32-0.96-0.6528-1.4336-0.9728-0.768-0.5248-1.536-1.0368-2.304-1.5744-0.4608-0.32-0.896-0.6656-1.3568-0.9984-0.768-0.5632-1.5232-1.1136-2.2784-1.6896-0.4352-0.3328-0.8576-0.6912-1.2928-1.0368-0.7552-0.6016-1.4976-1.1904-2.24-1.8048-0.3968-0.3328-0.7808-0.6784-1.1776-1.0112-0.7552-0.64-1.5104-1.28-2.2528-1.9456-0.384-0.3456-0.7552-0.6912-1.1264-1.0368-0.7296-0.6656-1.472-1.344-2.1888-2.0352-0.3712-0.3584-0.7296-0.7168-1.1008-1.0752-0.7168-0.704-1.4336-1.3952-2.1248-2.112-0.3456-0.3456-0.6784-0.704-1.0112-1.0624-0.704-0.7424-1.4208-1.472-2.112-2.2272-0.3328-0.3584-0.64-0.7168-0.9728-1.0752-0.6912-0.768-1.3824-1.5232-2.048-2.304-0.32-0.3712-0.6272-0.7424-0.9472-1.1264-0.6656-0.7808-1.3184-1.5488-1.9712-2.3296-0.32-0.384-0.6272-0.7808-0.9344-1.1648-0.64-0.7808-1.2672-1.5744-1.8944-2.368-0.3072-0.384-0.6016-0.7808-0.896-1.1648-0.6144-0.8064-1.2416-1.6128-1.8432-2.432-0.2944-0.4096-0.5888-0.8192-0.896-1.2288-0.5888-0.7936-1.1648-1.6-1.7408-2.4064-0.32-0.448-0.6272-0.9088-0.9344-1.3568-0.4608-0.6656-0.9216-1.3312-1.3696-1.9968 34.0736 19.712 83.9936 14.0544 119.2704-0.7424 0.2304-0.1024 0.4608-0.2048 0.6912-0.32 29.0944-13.9648 43.712-35.136 49.7408-57.3568 0.2816 0.9472 0.5504 1.8944 0.8192 2.8416 0.3712 1.344 0.7424 2.688 1.088 4.032 0.384 1.5488 0.7296 3.0976 1.0752 4.6592 0.2944 1.3312 0.6016 2.6496 0.8576 3.9808 0.32 1.6 0.576 3.2128 0.832 4.8128 0.2176 1.2928 0.448 2.5984 0.6144 3.8912 0.2304 1.6512 0.384 3.2896 0.5504 4.9408 0.128 1.2672 0.2816 2.5216 0.3712 3.7888 0.1152 1.6896 0.1536 3.3792 0.2048 5.056 0.0384 1.2032 0.1024 2.4064 0.1024 3.5968 0 1.7664-0.1024 3.4944-0.192 5.2352-0.0512 1.1008-0.064 2.2144-0.1536 3.3024-0.1536 1.9072-0.4352 3.776-0.704 5.6448-0.128 0.896-0.192 1.8176-0.3584 2.7008-0.4736 2.7392-1.0752 5.44-1.8304 8.0896-5.7856 20.544-19.0464 34.24-40.5376 41.8816z m269.1584 167.5264c-150.2464 0-209.8304-132.0704-221.4656-162.6624 10.2144-10.5216 17.6128-23.4496 21.8624-38.5408 1.9072-6.7584 3.1232-13.7216 3.7504-20.8128 0.32-3.5456 0.4864-7.1168 0.512-10.7136 0-0.1024-0.0128-0.2048-0.0128-0.3072 0.2304-35.5584-12.8512-72.768-28.096-99.5712 1.4464-34.4704 19.0336-62.5408 33.9072-80.2944 13.4528 79.9232 55.2704 103.7952 79.6416 110.9248-5.1584 29.1456-8.4736 59.4432-7.6032 87.0528 0.0256 0.512 0.0896 1.024 0.128 1.536-2.0352-2.8544-3.7888-5.3888-5.1328-7.3728-4.6592-6.8992-14.0288-8.704-20.928-4.0448-6.8992 4.6592-8.704 14.0288-4.0448 20.928 1.4464 2.1376 34.6752 51.0592 60.544 71.9232 19.648 25.3184 48.2048 42.8032 84.3392 42.8032 35.7248 0 63.424-17.5104 82.6368-41.792 26.5856-16.192 59.3792-64.7168 63.2064-70.464 4.608-6.9248 2.7392-16.2816-4.1984-20.9024-6.9248-4.6336-16.2944-2.7392-20.9024 4.1984-2.048 3.0848-4.4416 6.528-7.04 10.1504 0.448-4.3264 0.6912-8.576 0.6912-12.6976 0-17.664-3.7632-47.7952-9.4336-80.448 23.4496-5.8752 67.7248-27.7888 82.3296-109.0176 15.36 20.2752 31.9104 47.7952 33.6256 72.1536 0.0128 0.2048 0.0768 0.384 0.1024 0.5888-21.1584 34.8672-39.5648 90.4832-26.7008 136.1664 4.5184 16.0256 12.5952 29.632 23.8208 40.4864-14.2592 35.2384-74.9568 160.7296-215.5392 160.7296z m246.6944-174.4c-13.0688-8.0384-21.6192-19.5968-25.9456-34.9952-0.7424-2.6624-1.3568-5.376-1.8304-8.128-0.128-0.704-0.1792-1.4464-0.2816-2.1504-0.3072-2.048-0.6016-4.096-0.768-6.1824-0.0896-1.024-0.0896-2.0608-0.1408-3.0848-0.0896-1.8048-0.2048-3.6224-0.2048-5.4528 0-1.1648 0.064-2.3424 0.1024-3.5072 0.0512-1.7152 0.0896-3.4176 0.2048-5.1328 0.0896-1.2544 0.2432-2.5216 0.3712-3.7888 0.1664-1.6384 0.32-3.2768 0.5376-4.928 0.1792-1.3184 0.4096-2.624 0.6272-3.9424 0.256-1.5872 0.512-3.1872 0.832-4.7744 0.2688-1.344 0.5632-2.6752 0.8704-4.0192 0.3456-1.5488 0.6784-3.0848 1.0752-4.6208 0.3456-1.3568 0.7168-2.7008 1.088-4.0576l0.8064-2.8416c6.0288 22.2208 20.6464 43.392 49.7408 57.3568l0.6912 0.3072c35.2896 14.7968 85.2096 20.4672 119.2832 0.7424l-1.088 1.5872c-0.4224 0.6144-0.8448 1.2288-1.28 1.8432-0.4352 0.6272-0.896 1.2416-1.344 1.856-0.4352 0.6016-0.8576 1.1904-1.2928 1.7792l-1.4208 1.8816c-0.4352 0.576-0.8704 1.152-1.3056 1.7152-0.4992 0.64-0.9984 1.2544-1.5104 1.8816-0.4352 0.5504-0.8704 1.1008-1.3184 1.6384-0.5248 0.6272-1.0496 1.2544-1.5744 1.8688-0.448 0.5248-0.8832 1.0624-1.344 1.5744-0.5376 0.6272-1.1008 1.2288-1.6512 1.8432-0.4608 0.512-0.9088 1.024-1.3824 1.536-0.5632 0.6016-1.1392 1.2032-1.7024 1.792-0.4736 0.4992-0.9344 0.9984-1.4208 1.4848-0.5888 0.6016-1.1904 1.1904-1.792 1.7792-0.4736 0.4608-0.9344 0.9344-1.4208 1.3952-0.6144 0.5888-1.2416 1.152-1.8688 1.728-0.4864 0.448-0.96 0.9088-1.4592 1.344-0.6144 0.5504-1.2544 1.088-1.8816 1.6384-0.512 0.4352-1.024 0.896-1.536 1.3184-0.6528 0.5504-1.3184 1.0624-1.984 1.6-0.512 0.4096-1.0112 0.8192-1.5232 1.216-0.6912 0.5376-1.3952 1.0368-2.0992 1.5616-0.512 0.3712-1.0112 0.768-1.536 1.1264-0.7296 0.512-1.4592 1.0112-2.2016 1.5104-0.512 0.3456-1.0112 0.704-1.5232 1.0368-0.768 0.4992-1.5488 0.9728-2.3296 1.4592-0.4992 0.3072-0.9984 0.6272-1.4976 0.9344-0.7936 0.4736-1.6128 0.9216-2.432 1.3696-0.4992 0.2816-0.9984 0.576-1.5104 0.8448-0.832 0.448-1.6768 0.8576-2.5216 1.28-0.512 0.256-1.0112 0.5248-1.5232 0.768-0.8704 0.4224-1.7664 0.8064-2.6624 1.2032-0.4992 0.2176-0.9856 0.4608-1.4976 0.6656-0.9216 0.384-1.856 0.7424-2.7904 1.1008-0.4992 0.192-0.9728 0.3968-1.472 0.576-0.96 0.3584-1.9456 0.6656-2.9312 0.9984-0.4864 0.1536-0.96 0.3328-1.4464 0.4864-1.0112 0.32-2.048 0.5888-3.0848 0.8704-0.4736 0.128-0.9344 0.2688-1.3952 0.3968-1.088 0.2816-2.2016 0.512-3.3024 0.7552-0.4352 0.0896-0.8576 0.2048-1.2928 0.2944-1.1776 0.2304-2.368 0.4352-3.5712 0.6272-0.384 0.064-0.7552 0.1408-1.1392 0.192-1.2288 0.1792-2.4832 0.32-3.7248 0.448-0.3712 0.0384-0.7296 0.1024-1.1008 0.128-1.3184 0.128-2.6496 0.2048-3.9808 0.2688-0.32 0.0128-0.6272 0.0512-0.9472 0.064-1.3824 0.064-2.7776 0.0768-4.1728 0.0768-0.2944 0-0.5888 0.0128-0.8832 0.0128-1.4592-0.0128-2.9312-0.0768-4.4032-0.1536-0.256-0.0128-0.512-0.0128-0.768-0.0256-1.5488-0.0896-3.1232-0.2304-4.7104-0.3968-0.192-0.0256-0.384-0.0256-0.5888-0.0512-1.6384-0.1792-3.3024-0.4096-4.9792-0.6784-0.1536-0.0256-0.2944-0.0384-0.4352-0.064-1.7664-0.2816-3.5456-0.6144-5.3504-0.9984l-0.192-0.0384c-1.728-0.3584-3.4816-0.7808-5.248-1.2288-0.1408-0.0384-0.2816-0.064-0.4224-0.1024-3.8144-0.9856-7.7056-2.1888-11.6864-3.5968-5.3888-1.856-10.24-4.1472-14.6048-6.8224z m100.9536-153.4208c-3.5968 3.5456-6.5664 6.4896-8.7552 8.832l-1.728 1.8432c-15.3216 16.4224-38.4768 41.2416-35.8272 66.432 0.32 3.1232 1.1648 6.8096 2.8544 10.688-6.2208-1.6512-12.2112-3.6608-17.728-5.952-53.2096-25.8176-33.216-82.9056-28.1472-95.2192 9.4336-11.5328 17.9456-21.5424 26.1504-31.1808 18.5088-21.7344 34.6112-40.6528 51.6992-66.4448l0.2688-0.1152c4.288-1.6 8.4352-3.328 12.4416-5.2096 0.5376-0.256 1.088-0.4992 1.6256-0.768 3.6608-1.7664 7.2064-3.648 10.6368-5.6448 0.576-0.3328 1.1776-0.6528 1.7408-0.9856 7.616-4.5824 14.656-9.7536 21.12-15.5392 0.9984-0.896 1.92-1.856 2.8928-2.7776 2.0864-1.984 4.1472-4.0192 6.1056-6.144 1.1392-1.2288 2.24-2.5088 3.3408-3.7888 1.728-2.0096 3.4048-4.0704 5.0304-6.1952 1.024-1.344 2.0608-2.7008 3.0464-4.096 1.6896-2.3808 3.3024-4.8512 4.8768-7.36 0.768-1.2288 1.5616-2.4064 2.304-3.6736 2.2656-3.8528 4.4288-7.808 6.4256-11.9552 0.0384-0.0768 0.0512-0.1536 0.0896-0.2304 0.384-0.8192 0.6784-1.664 0.896-2.5088 0.0768-0.3072 0.1152-0.6272 0.1792-0.9344 0.128-0.6528 0.2304-1.2928 0.2688-1.9456 0.0256-0.3456 0.0256-0.6912 0.0128-1.0496 0-0.64-0.0512-1.2672-0.1408-1.8944-0.0512-0.3328-0.0896-0.6656-0.1536-1.0112-0.1536-0.7296-0.3712-1.4464-0.6272-2.1632-0.064-0.1664-0.0768-0.3456-0.1536-0.512-0.0128-0.0384-0.0384-0.064-0.0512-0.1024-0.3712-0.8832-0.832-1.7408-1.3696-2.5472-0.1408-0.2176-0.3072-0.3968-0.4608-0.6016-0.4224-0.5632-0.8704-1.1136-1.3824-1.6256-0.256-0.256-0.512-0.4736-0.7808-0.7168-0.2688-0.2304-0.4992-0.4864-0.7808-0.704-28.864-21.9904-84.7744-37.7216-122.24-26.2656-68.2112 16.9856-114.304 11.6096-137.9072 5.9136-4.3392-5.3248-9.088-10.4704-14.208-15.4496-0.3328-0.32-0.6912-0.64-1.0368-0.96-2.176-2.0864-4.4032-4.16-6.72-6.1824-1.0752-0.9472-2.2144-1.856-3.328-2.7776-0.064-0.0512-0.128-0.1152-0.2048-0.1664 57.4464-31.9232 133.1712-66.88 194.112-70.08 37.6704 0.1024 103.552 16.128 125.9904 120.8832-0.1536 5.9136-0.6144 11.8656-1.4464 17.8304-13.504 96.7808-73.3696 155.84-98.9312 181.056z" fill="#333B44" ></path></symbol><symbol id="icon-shengxiaoji" viewBox="0 0 1024 1024"><path d="M905.664 708.6208c-64.4608-23.0912-121.1136-63.936-149.632-126.5792-0.6656-1.4592 0.9472-2.9568 2.3552-2.176 41.1136 22.976 75.4816 5.2224 85.1456-0.8192 1.152-0.7296 1.0112-2.4448-0.256-2.9568-18.624-7.5264-119.3216-54.9376-140.6592-206.7712-19.9168-143.0272-50.3296-168.2688-75.4304-186.7776-6.4512-4.9152-14.7072-9.1648-24.2304-12.736 6.0544 41.408-22.7712 73.3056-39.1296 89.6768-23.3472 23.3472-42.8288 48.384-58.2784 93.12-0.5248 1.5104-2.6112 1.5488-3.1616 0.0512-16.8576-45.9136-66.6624-106.24-93.3376-140.7104-0.0768-0.0896-0.128-0.192-0.192-0.2944-5.9904-11.4816-8.3712-22.5152-8.2688-32.9728-14.2208 6.2208-27.072 13.8112-37.7216 22.8736-38.2464 32.5376-44.352 55.2192-57.024 177.4208C298.624 448.2944 248.32 525.056 160.9856 548.1728c-0.8448 0.2176-1.4208 1.0624-1.2544 1.92 5.8112 31.232 66.176 33.344 78.016 33.472 1.0752 0.0128 1.8432 0.9984 1.5872 2.048-2.5728 10.752-19.4048 62.0032-112.7424 108.288-1.3696 0.6784-1.216 2.7136 0.256 3.136 40.256 11.6096 72.1408 15.4368 101.6448 5.0048 1.5744-0.5504 2.9312 1.1904 1.9584 2.5472-18.0352 25.1776-28.8896 39.2448-50.8544 51.3536-1.344 0.7424-1.1136 2.752 0.384 3.1232 26.7392 6.6816 39.1296 4.6976 43.9296 3.0976 1.1776-0.3968 2.3296 0.5888 2.1504 1.8304-1.6128 10.9568-8.448 50.688-28.8256 98.432-0.576 1.3568 0.7168 2.8032 2.0992 2.2912 35.9936-13.2224 68.608-41.6 82.6624-54.9504 1.28-1.216 3.3024 0.0768 2.7264 1.7536-3.7376 10.8544-6.6688 32.2688 5.3376 68.2496 0.4096 1.2416 2.0608 1.5488 2.9056 0.5376 38.144-45.504 74.304-56.2048 83.2-58.24 1.0624-0.2432 2.0736 0.576 2.048 1.6768-0.8576 35.6736-23.424 85.2096-59.264 112.6144-1.3056 0.9984-0.64 3.072 0.9984 3.0336 37.0304-0.8064 112.0256-27.7504 144.832-102.4384 0.7552-1.7152 3.3024-1.0752 3.1744 0.7936-3.4688 53.3248 4.2624 77.1968 25.1904 95.6032 1.0752 0.9472 2.752 0.1664 2.7776-1.2672 0.7168-27.7248 16.3072-69.2224 23.936-87.9616 0.7168-1.7408 3.3024-1.1776 3.2256 0.704-1.1008 25.0112 2.5216 88.0256 62.8608 115.2128 1.088 0.4864 2.3296-0.2944 2.368-1.4848 1.728-59.1232 33.6768-120.8448 53.504-132.416 0.8704-0.512 1.9456-0.064 2.3168 0.8576 11.7632 29.8368 56 84.3264 110.72 87.7568 1.2416 0.0768 2.112-1.2288 1.6384-2.368-15.7568-38.1568-21.1072-70.7968-18.3296-102.4384 0.128-1.4336 1.92-2.0096 2.9184-0.9728 45.2224 46.7456 95.4112 27.1616 117.632 18.3424 1.2544-0.4992 1.4208-2.1504 0.3072-2.9184-32.0512-21.9904-61.2736-57.7408-70.4512-69.4912-0.9728-1.2416 0.1536-2.9824 1.6896-2.6368 27.9936 6.3744 84.3008 1.728 116.1984-41.0496 0.6656-0.896 0.256-2.2144-0.7936-2.5984z" fill="#FF7300" ></path><path d="M486.144 58.4576c0.448 6.5408 1.344 25.4208-2.2144 38.272-0.448 1.6128-2.7136 1.6256-3.2256 0.0128-1.92-6.1184-5.952-9.7024-7.7312-11.0464-0.5376-0.3968-1.216-0.4352-1.792-0.1024-9.9328 5.6832-97.6384 58.3424-62.336 126.0672 0.0512 0.1024 0.1152 0.2048 0.192 0.2944 26.6752 34.4704 76.48 94.7968 93.3376 140.7104 0.5504 1.4976 2.6368 1.4592 3.1616-0.0512 15.4496-44.736 34.9312-69.7728 58.2784-93.12 23.9616-23.9616 74.6624-81.2032 3.456-152.8576-0.7936-0.8064-2.1632-0.6016-2.7008 0.3968-3.9168 7.2448-8.9216 13.888-11.9424 17.664-0.9344 1.1648-2.8032 0.6272-2.9696-0.8576-1.3952-13.0944-9.8944-53.8752-61.376-67.1488-1.1136-0.2816-2.2144 0.6144-2.1376 1.7664zM581.9136 613.1328c-12.1088-17.3824-37.5424-88.9728-50.6496-129.792-5.6448 9.4592-13.3888 18.9184-23.808 25.088-11.0848-6.656-20.8256-17.9456-28.2752-28.4544-5.7088 25.6512-21.1968 85.9648-48.1408 125.9136-34.9952 51.904-60.3392 117.6704 15.6928 141.8112 34.9952 9.0496 66.5344 2.4192 69.4656-13.2736 16.8192 19.9168 95.2704 22.9376 101.9136-41.6384 0.0128-30.1696-22.3104-59.7376-36.1984-79.6544z" fill="#EF2E1F" ></path><path d="M485.696 395.3408c-5.0816-16.96-19.136-65.28-45.5936-89.984-23.3856-21.824-47.6672-57.088-53.9648-66.4576-0.7168-1.0752-2.3168-0.96-2.88 0.2048-2.688 5.5552-8.4224 19.456-6.7456 34.3296 0.1024 0.9472-0.5888 1.7792-1.5488 1.8432-53.5296 3.648-53.888 76.4928-53.2992 92.6848 0.0512 1.344 1.536 2.0736 2.624 1.2928 3.008-2.1504 9.2288-6.2976 21.0176-13.0944 1.472-0.8448 3.1616 0.768 2.3296 2.2528-17.5232 31.2832-16.4224 54.9376-8.3328 93.3248 0.3456 1.6 2.5344 1.8048 3.1616 0.3072 14.0544-33.472 57.3312-41.408 83.1488-36.2368 10.7904 2.1632 21.1968 2.0352 30.4 0.1408 7.9488-8.9088 19.6608-15.9616 29.6832-20.608zM631.0784 275.2768c-0.96-0.064-1.6512-0.896-1.5488-1.8432 1.664-14.8736-4.0576-28.7744-6.7456-34.3296-0.5632-1.1648-2.1632-1.28-2.88-0.2048-6.2848 9.3568-30.5664 44.6208-53.9648 66.4576-26.752 24.9728-37.696 73.3696-42.624 89.8048 12.0192 4.5184 25.3824 11.648 33.9712 21.6448 7.0528 0.896 14.8352 0.6528 23.1296-1.0112 25.8176-5.1584 69.1072 2.7648 83.1488 36.2368 0.6272 1.5104 2.8288 1.3056 3.1616-0.3072 8.0896-38.3872 9.1776-62.0416-8.3328-93.3248-0.832-1.4848 0.8576-3.0976 2.3296-2.2528 11.7888 6.8096 18.0096 10.944 21.0176 13.0944 1.088 0.7808 2.5856 0.0512 2.624-1.2928 0.6016-16.1664 0.2432-89.0112-53.2864-92.672z" fill="#FE9220" ></path><path d="M504.5248 436.0064s-13.12 6.784-26.7008 23.0784c-7.6928 7.6928-23.5392 11.7632-30.3232-15.8464-7.36-29.952 41.4336-51.1488 54.656-53.8624 15.9488 2.2656 60.7488 16.7424 63.9744 46.6176 2.4448 11.3152-14.08 36.8896-34.2272 19.456-18.6112-16.0768-27.3792-19.4432-27.3792-19.4432z" fill="#FFBC13" ></path><path d="M531.904 455.4752c-18.6112-16.1024-27.3792-19.456-27.3792-19.456s-13.1328 6.784-26.7008 23.0784c-2.304 2.304-5.3504 4.2624-8.6528 5.1584 7.0528 12.3392 21.1072 33.856 38.2976 44.1728 19.4816-11.5456 29.7472-34.6112 34.0352-47.68-3.072-0.7808-6.272-2.4064-9.6-5.2736z" fill="#FFBC13" ></path><path d="M549.8752 376.5376c-0.2688-9.4208 1.0752-73.792 90.1376-63.0272 0.896 0.1024 1.6128 0.896 1.536 1.792-2.2528 28.1344-32.6144 82.9952-90.5216 62.7712-0.6528-0.2304-1.1264-0.832-1.152-1.536zM456.3968 376.5376c0.2688-9.4208-1.0752-73.792-90.1376-63.0272-0.896 0.1024-1.6128 0.896-1.536 1.792 2.2528 28.1344 32.6144 82.9952 90.5216 62.7712 0.6656-0.2304 1.1392-0.832 1.152-1.536z" fill="#FFFFFF" ></path><path d="M507.4688 523.4944c-2.688 0-5.3632-0.7168-7.744-2.1504-19.1872-11.5072-34.304-33.3312-43.6224-49.6128-2.304-4.0448-2.624-8.9344-0.8448-13.2352 1.7792-4.3136 5.4528-7.552 9.9584-8.768 0.384-0.1024 1.0112-0.448 1.6384-0.9728 14.8864-17.6128 29.1712-25.2928 30.7712-26.112a15.0656 15.0656 0 0 1 12.3008-0.6912c1.8816 0.7168 12.2368 5.1712 31.8592 22.1312v0.0128c1.2928 1.1136 2.4576 1.8176 3.4944 2.0736 4.032 1.0368 7.4496 3.6992 9.4464 7.36 1.9968 3.648 2.3936 7.9616 1.1008 11.9296-4.8384 14.7584-16.5632 41.664-40.6656 55.936a15.25888 15.25888 0 0 1-7.6928 2.0992z m-17.9072-54.9632c5.8752 8.6528 11.9808 15.872 17.856 21.12 6.9248-6.5408 11.904-15.0144 15.2704-22.2464-0.2176-0.1792-0.4224-0.3584-0.64-0.5504-7.4752-6.464-13.12-10.624-16.9728-13.184-4.1088 3.1104-9.7536 7.9872-15.5136 14.8608z" fill="#333B44" ></path><path d="M921.1264 705.3696c-1.536-5.056-5.4144-9.1392-10.3808-10.9184-39.8976-14.2976-90.816-40.9088-124.1856-89.0624 31.8848 4.6848 56.5504-8.2944 64.9856-13.568 5.3632-3.3664 8.3456-9.3568 7.7824-15.6544a16.6784 16.6784 0 0 0-10.3936-14.0288c-18.4192-7.4496-111.2832-51.84-131.392-194.88-19.6096-140.7872-49.6896-173.44-81.2288-196.6848-5.6192-4.2752-12.3648-8.1664-20.1472-11.6096-5.9904-24.6784-21.3632-45.9776-38.2464-62.9632a16.86784 16.86784 0 0 0-14.2848-4.736c-2.4704 0.3584-4.8128 1.28-6.8608 2.6368-8.7808-19.3792-26.9824-42.048-64.7424-51.776-5.2096-1.3312-10.7776-0.0896-14.912 3.3536a16.8128 16.8128 0 0 0-6.016 14.0288v0.0128c0.2304 3.328 0.384 7.04 0.3968 10.8288-2.7008 0.0768-5.3888 0.8064-7.8208 2.2016-36.8512 21.0944-72.3328 55.8848-77.6192 96.384-12.5824 6.208-23.6928 13.2736-32.9856 21.184-43.2 36.7616-49.472 64.1024-62.2464 187.3408-6.208 59.8144-50.7008 134.208-133.7472 156.1856-8.384 2.24-13.7344 10.6752-12.1728 19.2384 5.9904 32.2176 46.2592 41.856 73.3824 44.672-10.2528 18.9312-35.9168 51.8912-98.3808 82.8672-6.2464 3.0976-9.8816 9.5744-9.2672 16.5248 0.6144 6.9248 5.3376 12.6592 12.0192 14.592 23.0144 6.6304 48.704 12.5696 74.5344 11.4944-7.5264 8.32-14.8352 14.2208-24.8704 19.7504-6.08 3.3536-9.4336 9.9584-8.5376 16.8448 0.896 6.8736 5.8112 12.3904 12.544 14.0928 12.096 3.0208 22.7072 4.7104 31.744 5.0688-3.7504 17.7792-11.0976 45.888-24.6912 77.7472a16.77696 16.77696 0 0 0 3.2896 18.176c4.608 4.8384 11.648 6.4768 17.856 4.1728 23.3856-8.5888 45.12-22.7968 62.2336-36.1216 0.896 11.5968 3.5584 25.4464 9.0112 41.8048 1.9328 5.7472 6.8352 10.0224 12.8128 11.136 5.9776 1.1136 12.096-1.088 15.9232-5.7088 21.1328-25.2032 41.3952-38.7328 55.6928-45.8752-6.7712 27.8016-24.7424 60.6592-50.3936 80.2816a16.7552 16.7552 0 0 0-5.6704 18.8928 16.6784 16.6784 0 0 0 15.7824 11.1744h0.3584c34.3168-0.7424 93.2096-20.9792 133.12-70.1568 3.2128 27.1232 12.5824 45.2224 29.7856 60.3648 4.8512 4.2752 11.8272 5.3632 17.7408 2.7648 5.952-2.5984 9.8944-8.4864 10.0608-14.9504 0.2304-8.6656 2.1376-19.0464 4.8384-29.632 8.9088 26.624 27.2384 54.4 63.9232 70.9376 2.2016 0.9856 4.544 1.4848 6.8736 1.4848 3.0976 0 6.1696-0.8576 8.8832-2.56a16.7168 16.7168 0 0 0 7.8592-13.696c1.3184-45.3376 20.9408-88.5888 35.5456-108.8128 20.8128 35.0592 64.1664 76.416 114.9824 79.6032 5.8112 0.384 11.2768-2.24 14.656-6.976 3.392-4.7616 4.0832-10.816 1.856-16.1664-10.1504-24.5888-15.872-46.8992-17.4464-68.4672 45.888 29.12 92.1728 10.7392 111.2704 3.1744 5.7728-2.2784 9.7792-7.5136 10.4832-13.6576 0.704-6.1696-2.048-12.1728-7.168-15.68-17.4464-11.968-34.24-28.5696-46.9376-42.5216 32.5632-1.7024 72.128-14.6304 97.9328-49.2288 3.1488-4.3136 4.1216-9.8688 2.5856-14.9248zM468.1984 105.28c3.0208 4.7744 8.2688 7.7312 14.1312 7.7312h0.32c7.4624-0.1408 13.8112-5.0688 15.7952-12.2496 1.984-7.1296 2.8416-15.3856 3.1104-23.1296 26.3808 13.504 31.9744 37.0688 33.1264 47.7824 0.7168 6.7712 5.3888 12.3776 11.9168 14.2976 6.5152 1.9072 13.5168-0.2688 17.792-5.6064 1.024-1.2928 2.1888-2.7776 3.4048-4.416 11.904 14.7328 18.0992 28.48 20.224 41.2928 0.0256 0.3456-0.0384 0.6784 0.0128 1.0112 4.1856 28.6336-12.3392 52.6592-28.096 69.7856-0.1024 0.1152-0.2048 0.2176-0.3072 0.3328-0.96 1.0368-1.9072 2.048-2.8672 3.0336-0.1664 0.1664-0.32 0.3456-0.4864 0.512-1.0496 1.088-2.0992 2.1504-3.1232 3.1872-13.9264 13.9136-26.2656 28.2496-37.2608 45.9904-4.4928 7.2576-8.7936 15.0272-12.8512 23.6544-11.0976-20.3136-25.6-41.4592-40.0384-61.056-11.2256-15.2448-22.4256-29.5808-31.9488-41.728-0.7296-0.9344-1.408-1.792-2.112-2.7008-2.5216-3.2256-4.9664-6.3488-7.2576-9.3056 0-0.0128-0.0128-0.0128-0.0128-0.0256-0.8448-1.7024-1.5488-3.392-2.2272-5.0816-0.32-0.8192-0.6272-1.6384-0.896-2.4576-0.2432-0.7296-0.448-1.4464-0.6656-2.176-11.7888-40.4864 29.4912-74.5088 50.3168-88.6784z m361.9584 715.7632c-21.952 5.3632-51.0848 5.5296-78.2464-22.5408-4.5696-4.7232-11.52-6.3616-17.6768-4.16-6.144 2.176-10.496 7.7824-11.072 14.2848-2.4832 28.1728 0.9856 56.128 10.8928 86.5024-37.824-13.504-67.5968-52.5824-75.904-73.6768-1.792-4.5568-5.4784-8.0896-10.0864-9.6896-4.5696-1.5744-9.6128-1.1008-13.824 1.344-23.0912 13.4784-51.5328 68.16-59.1104 123.2256-35.4304-26.4192-37.8368-71.0912-36.9664-90.8544 0.3584-8.1536-5.1584-15.3472-13.1328-17.088-1.216-0.2688-2.4192-0.3968-3.6096-0.3968-6.6816 0-12.8512 4.0064-15.4752 10.432-5.7472 14.1056-14.0032 36.0832-19.456 57.8048-3.8528-12.7744-5.2224-30.5664-3.4688-57.5104 0.5376-8.1408-4.8256-15.4368-12.7232-17.3696a16.6592 16.6592 0 0 0-19.264 9.536c-20.1984 45.9904-58.3168 72.6528-91.584 85.0048 21.5936-29.6448 33.2288-65.0368 33.8688-91.8144 0.1152-5.2096-2.1248-10.0736-6.1568-13.3632-4.032-3.2768-9.2416-4.48-14.3104-3.3408-9.5872 2.2016-40.1408 11.4432-74.4448 44.9408-3.4816-18.7904-1.3824-30.1184 0.5888-35.8784 1.4976-4.3392 1.1008-8.9088-0.7936-12.8 7.296-43.2384 23.6416-64.6016 42.432-89.088 10.4064-13.568 21.1584-27.584 31.0272-46.0416 18.5984-34.816 21.7984-72.1152 24.6144-105.024 1.7408-20.2752 3.3792-39.424 8.256-56.3072 6.9248-23.9872 23.2576-37.184 34.7904-43.7888 5.6704 9.7408 12.864 13.8368 18.7264 15.4752 1.8944 0.5248 3.84 0.7808 5.7984 0.896-5.7728 25.28-20.5568 81.1136-45.2352 117.7216-32.064 47.5392-43.0336 86.848-32.6016 116.8128 7.7824 22.336 26.688 38.4128 56.2176 47.7824 0.256 0.0896 0.5248 0.1536 0.7936 0.2304 11.8656 3.072 23.5904 4.5824 34.4192 4.5824 15.5904 0 29.3376-3.136 38.9632-9.2544 1.2672-0.8064 2.432-1.6384 3.5072-2.496 16.8704 7.7696 40.9472 9.3952 61.8112 2.944 29.4656-9.1008 48.2048-32.3328 51.4432-63.7312 0.0512-0.512 0.0768-1.024 0.0768-1.536 0-32.8832-20.8128-62.5024-36.0064-84.1216l-2.9056-4.1472c-9.4848-13.6192-32.64-75.8912-48.6656-125.7856-0.2688-0.8576-0.64-1.6512-1.0496-2.432 5.9264 0.2304 11.8144-1.152 17.2928-4.3904 3.648-2.1632 6.8864-5.0816 9.6896-8.3968 10.4832 8.192 26.176 26.56 31.6672 65.3952 18.2016 128.6784 77.5936 209.0496 176.4736 239.04 9.8432 12.3392 28.416 34.1248 50.4192 53.0688zM464.256 429.888c7.616-12.0448 28.5056-22.1568 38.4768-25.1136 15.168 3.0336 46.528 15.3728 48.4096 32.8576 0.0384 0.3328 0.0768 0.6528 0.1408 0.9728-0.2176 2.1504-2.7392 6.5152-5.184 7.5904-1.1648 0.5248-3.6224-1.4848-4.3392-2.112-19.6224-16.9728-29.9776-21.4144-31.8592-22.1312a15.0144 15.0144 0 0 0-12.3008 0.6912c-1.6 0.832-15.8976 8.512-30.784 26.1248-0.2816 0.2432-0.5504 0.4352-0.7936 0.5888-0.8704-1.152-2.4704-3.904-3.904-9.7024-0.5248-2.1376-0.7552-5.184 2.1376-9.7664z m22.5408 81.7408c4.2752 3.8656 8.5888 7.1168 12.9152 9.7152 4.736 2.8544 10.6624 2.8672 15.424 0.0384 3.6224-2.1504 7.104-4.6592 10.4064-7.5264 11.4816 33.6896 31.744 90.304 44.0064 107.8912l2.9696 4.2368c12.7488 18.1376 30.1568 42.9056 30.528 66.048-2.2144 19.1872-12.3904 31.7184-30.272 37.2352-19.9552 6.1696-40.8192 0.4736-45.056-4.5696-3.7504-4.4416-9.728-6.336-15.3472-4.8384a15.04 15.04 0 0 0-10.8672 11.328c-2.9824 3.5968-22.1056 9.2928-50.5984 2.0352-20.0448-6.4384-31.9744-15.872-36.4928-28.8512-7.04-20.224 3.0336-51.3664 29.12-90.0608 20.6976-30.6944 34.88-72.3968 43.264-102.6816z m31.5264-36.0064c-3.3408 5.6064-6.9888 10.2912-10.9184 14.016-5.1968-4.6464-10.5856-10.8544-15.9232-18.3808-0.64-0.9088-1.3952-1.6896-2.1888-2.4192 0.0256-0.0384 0.064-0.064 0.1024-0.1024 5.8112-6.976 11.52-11.9168 15.68-15.0656 3.8528 2.5728 9.4976 6.72 16.9728 13.184 1.1136 0.9728 2.2784 1.7792 3.4432 2.6112a15.0144 15.0144 0 0 0-7.168 6.1568z m275.2896 261.9648c-2.9056-0.6656-5.8496-0.4864-8.5888 0.3456-84.608-27.2256-135.7952-98.8288-151.9872-213.248-8.1792-57.7408-36.5824-81.92-52.0192-90.9824-2.0736-16.8448-12.7104-29.4656-25.6896-38.6944 7.0784 1.728 13.7344 2.5216 19.8656 2.5216 17.2544 0 30.6944-5.824 40.0256-11.904 25.9584-16.9088 39.6288-47.6672 41.344-69.0816 0.7296-8.9984-5.7472-16.896-14.7456-17.9712-36.2752-4.3776-64.2176 2.1632-83.136 19.4432-23.1424 21.1328-24.1152 50.4832-23.8592 58.9824 0.0768 2.688 0.8448 5.2608 2.0992 7.5392-12.9024-5.8368-25.4464-9.024-32.6528-10.0352-1.7152-0.2432-3.456-0.192-5.1456 0.1536-6.1696 1.2672-19.904 6.1184-33.3568 14.3232 3.392-3.0208 5.5424-7.3216 5.6832-11.9808 0.256-8.4992-0.7296-37.8496-23.8592-58.9824-18.9312-17.28-46.8992-23.8336-83.1232-19.456-9.0112 1.0752-15.5008 8.9728-14.7584 17.9584 1.7152 21.4272 15.3856 52.1984 41.344 69.0944 9.3312 6.08 22.784 11.904 40.0384 11.904 8.7424 0 18.4704-1.4976 29.12-5.2224 0.4096-0.1408 0.7808-0.3456 1.1776-0.512-8.7808 5.9008-17.0624 13.2608-22.592 22.016-3.9552 6.2592-6.2464 12.8768-6.8864 19.5584-16.2048 7.6928-45.0816 26.3808-56.3712 65.4848-5.6832 19.7248-7.4496 40.3072-9.3184 62.0928-2.7008 31.488-5.4912 64.0512-21.1712 93.4016-8.704 16.2816-18.7008 29.312-28.3648 41.9072-19.9808 26.048-40.5632 53.0176-48.7808 106.0736-9.408 8.6272-25.5488 22.3488-44.5056 33.856 11.6992-34.4064 16.256-61.0944 17.5616-69.9648 0.8576-5.7984-1.3056-11.5072-5.7856-15.2576-4.4672-3.7504-10.4448-4.9024-16.0256-3.0464-0.3456 0.1152-1.7792 0.5376-4.6976 0.7168 9.7024-9.6512 18.0736-21.0176 28.2368-35.2128 4.288-5.9776 4.1984-13.9264-0.2048-19.7888-4.416-5.888-12.0448-8.2048-19.0208-5.7344-16.8064 5.9392-35.1744 6.8864-59.4304 2.6112 70.8224-43.3792 86.6432-87.5776 89.9328-101.312 1.2032-4.992 0.0768-10.1632-3.072-14.208a16.64128 16.64128 0 0 0-13.0048-6.4256c-20.8128-0.2048-43.264-4.1728-55.0912-11.3536 85.696-30.8224 130.9952-109.056 138.0096-176.6016 12.4672-120.192 18.2784-138.9696 51.8144-167.5008 4.7232-4.0192 10.0736-7.808 16.0128-11.3536 0.7552 2.6112 1.7024 5.2352 2.752 7.8592 0.1792 0.4608 0.3712 0.9216 0.5632 1.3824 1.0624 2.5728 2.2144 5.1456 3.5584 7.7312 0.4096 0.7808 1.0752 1.8176 1.6128 2.5216 1.6768 2.176 3.4688 4.4672 5.3248 6.8352 1.5872 2.0352 3.2128 4.1216 4.9152 6.2848 9.0624 11.5584 19.6992 25.1648 30.3488 39.552 20.608 27.8528 41.2416 58.7392 50.5344 84.032 0.6016 1.6256 1.4336 3.1104 2.4576 4.4288 0.0128 0.0128 0.0128 0.0128 0.0128 0.0256 0.4864 0.6272 1.024 1.2032 1.5872 1.7536 0.0384 0.0384 0.0768 0.0896 0.1152 0.128 0.5248 0.4992 1.088 0.9344 1.664 1.3696 0.1024 0.0768 0.1792 0.1664 0.2816 0.2304 0.5632 0.3968 1.1648 0.7296 1.7664 1.0496 0.1408 0.0768 0.256 0.1664 0.3968 0.2304 0.576 0.2816 1.1776 0.4992 1.7792 0.7168 0.192 0.064 0.3712 0.1664 0.5632 0.2304 0.6144 0.192 1.2544 0.3328 1.9072 0.448 0.192 0.0384 0.3712 0.1024 0.576 0.1408 0.8448 0.128 1.7152 0.2048 2.5856 0.2048h0.1664c0.4352 0 0.8576-0.0768 1.2928-0.1152 0.4352-0.0384 0.8832-0.0384 1.3056-0.1152 0.3072-0.0512 0.5888-0.1536 0.8832-0.2176 0.5376-0.128 1.088-0.2304 1.6128-0.3968 0.2048-0.064 0.3968-0.1792 0.6016-0.256 0.5888-0.2176 1.1904-0.448 1.7536-0.7296 0.1664-0.0896 0.32-0.2048 0.4736-0.2944 0.576-0.32 1.152-0.64 1.6896-1.024 0.3328-0.2304 0.6144-0.5248 0.9344-0.7808 0.3328-0.2816 0.6912-0.5376 1.0112-0.8576 1.8176-1.7792 3.2512-3.9936 4.1344-6.5024 8.0512-23.3088 17.2288-40.9344 27.7248-55.8976 8.1664-11.6352 17.1264-21.6576 26.9568-31.488 10.304-10.304 37.8368-37.8496 43.3792-75.7632 0.128 0.1024 0.2688 0.2048 0.3968 0.2944 21.0944 15.552 49.984 36.8384 69.4528 176.7424 16.9856 120.8832 82.2528 179.2256 122.048 204.1088-12.1344 1.728-27.3792 0.4864-44.0192-8.8192a16.70016 16.70016 0 0 0-19.4816 2.3296 16.68608 16.68608 0 0 0-3.9168 19.2512c25.3696 55.7184 73.4336 99.4304 139.6352 127.2704-27.84 24-67.2 26.7776-88.3584 21.952z m-227.968-371.136c1.2544-7.6928 4.608-18.2144 13.3504-26.2016 9.8304-8.9728 24.8064-13.248 44.416-12.8768-4.16 11.5712-12.3776 25.0112-24.6272 32.9984-9.728 6.336-20.8512 8.3712-33.1392 6.08z m-125.0048 0c-12.288 2.2912-23.3984 0.256-33.152-6.0928-12.2496-7.9744-20.4672-21.4144-24.6272-32.9984 19.712-0.384 34.5984 3.904 44.416 12.8768 8.7552 8 12.1088 18.5216 13.3632 26.2144z" fill="#333B44" ></path></symbol></svg>',function(c){var a=(a=document.getElementsByTagName("script"))[a.length-1],l=a.getAttribute("data-injectcss"),a=a.getAttribute("data-disable-injectsvg");if(!a){var h,t,p,i,z,F=function(a,l){l.parentNode.insertBefore(a,l)};if(l&&!c.__iconfont__svg__cssinject__){c.__iconfont__svg__cssinject__=!0;try{document.write("<style>.svgfont {display: inline-block;width: 1em;height: 1em;fill: currentColor;vertical-align: -0.1em;font-size:16px;}</style>")}catch(a){console&&console.log(a)}}h=function(){var a,l=document.createElement("div");l.innerHTML=c._iconfont_svg_string_4604429,(l=l.getElementsByTagName("svg")[0])&&(l.setAttribute("aria-hidden","true"),l.style.position="absolute",l.style.width=0,l.style.height=0,l.style.overflow="hidden",l=l,(a=document.body).firstChild?F(l,a.firstChild):a.appendChild(l))},document.addEventListener?~["complete","loaded","interactive"].indexOf(document.readyState)?setTimeout(h,0):(t=function(){document.removeEventListener("DOMContentLoaded",t,!1),h()},document.addEventListener("DOMContentLoaded",t,!1)):document.attachEvent&&(p=h,i=c.document,z=!1,M(),i.onreadystatechange=function(){"complete"==i.readyState&&(i.onreadystatechange=null,m())})}function m(){z||(z=!0,p())}function M(){try{i.documentElement.doScroll("left")}catch(a){return void setTimeout(M,50)}m()}}(window);]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/js/diytitle.js"/>
      <url>/js/diytitle.js</url>
      
        <content type="html"><![CDATA[//动态标题var OriginTitile = document.title;var titleTime;document.addEventListener("visibilitychange", function () {    if (document.hidden) {        //离开当前页面时标签显示内容        document.title = "w(ﾟДﾟ)w 不要走！再看看嘛！";        clearTimeout(titleTime);    } else {        //返回当前页面时标签显示内容        document.title = "♪(^∇^*)欢迎肥来！" + OriginTitile;        //两秒后变回正常标题        titleTime = setTimeout(function () {            document.title = OriginTitile;        }, 2000);    }});]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/css/coin/coin.css"/>
      <url>/css/coin/coin.css</url>
      
        <content type="html"><![CDATA[.tip-button {    border: 0;    border-radius: 0.25rem;    cursor: pointer;    font-size: 20px;    font-weight: 600;    height: 2.6rem;    margin-bottom: -4rem;    outline: 0;    position: relative;    top: 0;    transform-origin: 0% 100%;    transition: transform 50ms ease-in-out;    width: auto;    -webkit-tap-highlight-color: transparent;}.tip-button:active {    transform: rotate(4deg);}.tip-button.clicked {    animation: 150ms ease-in-out 1 shake;    pointer-events: none;}.tip-button.clicked .tip-button__text {    opacity: 0;    transition: opacity 100ms linear 200ms;}.tip-button.clicked::before {    height: 0.5rem;    width: 60%;    background: $button-hover-color;}.tip-button.clicked .coin {    transition: margin-bottom 1s linear 200ms;    margin-bottom: 0;}.tip-button.shrink-landing::before {    transition: width 200ms ease-in;    width: 0;}.tip-button.coin-landed::after {    opacity: 1;    transform: scale(1);    transform-origin: 50% 100%;}.tip-button.coin-landed .coin-wrapper {    background: radial-gradient(circle at 35% 97%, rgba(3, 16, 50, 0.4) 0.04rem, transparent 0.04rem), radial-gradient(circle at 45% 92%,            rgba(3, 16, 50, 0.4) 0.04rem,            transparent 0.02rem), radial-gradient(circle at 55% 98%, rgba(3, 16, 50, 0.4) 0.04rem, transparent 0.04rem), radial-gradient(circle at 65% 96%, rgba(3, 16, 50, 0.4) 0.06rem, transparent 0.06rem);    background-position: center bottom;    background-size: 100%;    bottom: -1rem;    opacity: 0;    transform: scale(2) translateY(-10px);}.tip-button__text {    color: #fff;    margin-right: 1.8rem;    opacity: 1;    position: relative;    transition: opacity 100ms linear 500ms;    z-index: 3;}.tip-button::before {    border-radius: 0.25rem;    bottom: 0;    content: "";    display: block;    height: 100%;    left: 50%;    position: absolute;    transform: translateX(-50%);    transition: height 250ms ease-in-out 400ms, width 250ms ease-in-out 300ms;    width: 100%;    z-index: 2;}.tip-button::after {    bottom: -1rem;    color: white;    content: "ヾ(≧O≦)〃嗷~";    /*点击后显示的内容*/    height: 110%;    left: 0;    opacity: 0;    position: absolute;    pointer-events: none;    text-align: center;    transform: scale(0);    transform-origin: 50% 20%;    transition: transform 200ms cubic-bezier(0, 0, 0.35, 1.43);    width: 100%;    z-index: 1;}.coin-wrapper {    background: none;    bottom: 0;    height: 18rem;    left: 0;    opacity: 1;    overflow: hidden;    pointer-events: none;    position: absolute;    transform: none;    transform-origin: 50% 100%;    transition: opacity 200ms linear 100ms, transform 300ms ease-out;    width: 100%;}.coin {    --front-y-multiplier: 0;    --back-y-multiplier: 0;    --coin-y-multiplier: 0;    --coin-x-multiplier: 0;    --coin-scale-multiplier: 0;    --coin-rotation-multiplier: 0;    --shine-opacity-multiplier: 0.4;    --shine-bg-multiplier: 50%;    bottom: calc(var(--coin-y-multiplier) * 1rem - 3.5rem);    height: 3.5rem;    margin-bottom: 3.05rem;    position: absolute;    right: calc(var(--coin-x-multiplier) * 34% + 16%);    transform: translateX(50%) scale(calc(0.4 + var(--coin-scale-multiplier))) rotate(calc(var(--coin-rotation-multiplier) * -1deg));    transition: opacity 100ms linear 200ms;    width: 3.5rem;    z-index: 3;}.coin__front,.coin__middle,.coin__back,.coin::before,.coin__front::after,.coin__back::after {    border-radius: 50%;    box-sizing: border-box;    height: 100%;    left: 0;    position: absolute;    width: 100%;    z-index: 3;}.coin__front {    background: radial-gradient(circle at 50% 50%, transparent 50%, rgba(115, 124, 153, 0.4) 54%, #c2cadf 54%),        linear-gradient(210deg, #8590b3 32%, transparent 32%), linear-gradient(150deg, #8590b3 32%, transparent 32%),        linear-gradient(to right, #8590b3 22%, transparent 22%, transparent 78%, #8590b3 78%), linear-gradient(to bottom,            #fcfaf9 44%,            transparent 44%,            transparent 65%,            #fcfaf9 65%,            #fcfaf9 71%,            #8590b3 71%), linear-gradient(to right, transparent 28%, #fcfaf9 28%, #fcfaf9 34%, #8590b3 34%, #8590b3 40%, #fcfaf9 40%, #fcfaf9 47%, #8590b3 47%, #8590b3 53%, #fcfaf9 53%, #fcfaf9 60%, #8590b3 60%, #8590b3 66%, #fcfaf9 66%, #fcfaf9 72%, transparent 72%);    background-color: #8590b3;    background-size: 100% 100%;    transform: translateY(calc(var(--front-y-multiplier) * 0.3181818182rem / 2)) scaleY(var(--front-scale-multiplier));}.coin__front::after {    background: rgba(0, 0, 0, 0.2);    content: "";    opacity: var(--front-y-multiplier);}.coin__middle {    background: #737c99;    transform: translateY(calc(var(--middle-y-multiplier) * 0.3181818182rem / 2)) scaleY(var(--middle-scale-multiplier));}.coin__back {    background: radial-gradient(circle at 50% 50%, transparent 50%, rgba(115, 124, 153, 0.4) 54%, #c2cadf 54%),        radial-gradient(circle at 50% 40%, #fcfaf9 23%, transparent 23%), radial-gradient(circle at 50% 100%, #fcfaf9 35%, transparent 35%);    background-color: #8590b3;    background-size: 100% 100%;    transform: translateY(calc(var(--back-y-multiplier) * 0.3181818182rem / 2)) scaleY(var(--back-scale-multiplier));}.coin__back::after {    background: rgba(0, 0, 0, 0.2);    content: "";    opacity: var(--back-y-multiplier);}.coin::before {    background: radial-gradient(circle at 25% 65%, transparent 50%, rgba(255, 255, 255, 0.9) 90%), linear-gradient(55deg, transparent calc(var(--shine-bg-multiplier) + 0%), #e9f4ff calc(var(--shine-bg-multiplier) + 0%), transparent calc(var(--shine-bg-multiplier) + 50%));    content: "";    opacity: var(--shine-opacity-multiplier);    transform: translateY(calc(var(--middle-y-multiplier) * 0.3181818182rem / -2)) scaleY(var(--middle-scale-multiplier)) rotate(calc(var(--coin-rotation-multiplier) * 1deg));    z-index: 10;}.coin::after {    background: #737c99;    content: "";    height: 0.3181818182rem;    left: 0;    position: absolute;    top: 50%;    transform: translateY(-50%);    width: 100%;    z-index: 2;}@keyframes shake {    0% {        transform: rotate(4deg);    }    66% {        transform: rotate(-4deg);    }    100% {        transform: rotate();    }}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/js/coin/coin.js"/>
      <url>/js/coin/coin.js</url>
      
        <content type="html"><![CDATA[var tipButtons = document.querySelectorAll(".tip-button");function coinAudio() {    var coinAudio = document.getElementById("coinAudio");    if (coinAudio) {        coinAudio.play(); //有音频时播放    }}// Loop through all buttons (allows for multiple buttons on page)tipButtons.forEach(button => {    var coin = button.querySelector(".coin");    // The larger the number, the slower the animation    coin.maxMoveLoopCount = 90;    button.addEventListener("click", () => {        if (/Android|webOS|BlackBerry/i.test(navigator.userAgent)) return true; //媒体选择        if (button.clicked) return;        button.classList.add("clicked");        // Wait to start flipping th coin because of the button tilt animation        setTimeout(() => {            // Randomize the flipping speeds just for fun            coin.sideRotationCount = Math.floor(Math.random() * 5) * 90;            coin.maxFlipAngle = (Math.floor(Math.random() * 4) + 3) * Math.PI;            button.clicked = true;            flipCoin();            coinAudio();        }, 50);    });    var flipCoin = () => {        coin.moveLoopCount = 0;        flipCoinLoop();    };    var resetCoin = () => {        coin.style.setProperty("--coin-x-multiplier", 0);        coin.style.setProperty("--coin-scale-multiplier", 0);        coin.style.setProperty("--coin-rotation-multiplier", 0);        coin.style.setProperty("--shine-opacity-multiplier", 0.4);        coin.style.setProperty("--shine-bg-multiplier", "50%");        coin.style.setProperty("opacity", 1);        // Delay to give the reset animation some time before you can click again        setTimeout(() => {            button.clicked = false;        }, 300);    };    var flipCoinLoop = () => {        coin.moveLoopCount++;        var percentageCompleted = coin.moveLoopCount / coin.maxMoveLoopCount;        coin.angle = -coin.maxFlipAngle * Math.pow(percentageCompleted - 1, 2) + coin.maxFlipAngle;        // Calculate the scale and position of the coin moving through the air        coin.style.setProperty("--coin-y-multiplier", -11 * Math.pow(percentageCompleted * 2 - 1, 4) + 11);        coin.style.setProperty("--coin-x-multiplier", percentageCompleted);        coin.style.setProperty("--coin-scale-multiplier", percentageCompleted * 0.6);        coin.style.setProperty("--coin-rotation-multiplier", percentageCompleted * coin.sideRotationCount);        // Calculate the scale and position values for the different coin faces        // The math uses sin/cos wave functions to similate the circular motion of 3D spin        coin.style.setProperty("--front-scale-multiplier", Math.max(Math.cos(coin.angle), 0));        coin.style.setProperty("--front-y-multiplier", Math.sin(coin.angle));        coin.style.setProperty("--middle-scale-multiplier", Math.abs(Math.cos(coin.angle), 0));        coin.style.setProperty("--middle-y-multiplier", Math.cos((coin.angle + Math.PI / 2) % Math.PI));        coin.style.setProperty("--back-scale-multiplier", Math.max(Math.cos(coin.angle - Math.PI), 0));        coin.style.setProperty("--back-y-multiplier", Math.sin(coin.angle - Math.PI));        coin.style.setProperty("--shine-opacity-multiplier", 4 * Math.sin((coin.angle + Math.PI / 2) % Math.PI) - 3.2);        coin.style.setProperty("--shine-bg-multiplier", -40 * (Math.cos((coin.angle + Math.PI / 2) % Math.PI) - 0.5) + "%");        // Repeat animation loop        if (coin.moveLoopCount < coin.maxMoveLoopCount) {            if (coin.moveLoopCount === coin.maxMoveLoopCount - 6) button.classList.add("shrink-landing");            window.requestAnimationFrame(flipCoinLoop);        } else {            button.classList.add("coin-landed");            coin.style.setProperty("opacity", 0);            setTimeout(() => {                button.classList.remove("clicked", "shrink-landing", "coin-landed");                setTimeout(() => {                    resetCoin();                }, 300);            }, 1500);        }    };});]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/js/runtime/runtime.js"/>
      <url>/js/runtime/runtime.js</url>
      
        <content type="html"><![CDATA[var now = new Date();function createtime() {    var grt = new Date("06/30/2024 23:00:00");    now.setTime(now.getTime() + 250);    var days = (now - grt) / 1e3 / 60 / 60 / 24,        dnum = Math.floor(days),        hours = (now - grt) / 1e3 / 60 / 60 - 24 * dnum,        hnum = Math.floor(hours);    hnum = hnum < 10 ? "0" + hnum : hnum;    var minutes = (now - grt) / 1e3 / 60 - 1440 * dnum - 60 * hnum,        mnum = Math.floor(minutes);    mnum = mnum < 10 ? "0" + mnum : mnum;    var seconds = (now - grt) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,        snum = Math.round(seconds);    snum = snum < 10 ? "0" + snum : snum;    let currentTimeHtml = `本站运行了 ${dnum} 天${hnum} 小时 ${mnum} 分${snum} 秒`;    document.getElementById("workboard") && (document.getElementById("workboard").innerHTML = currentTimeHtml);}setInterval(() => {    createtime();}, 250);]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/js/runtime/runtime.min.css"/>
      <url>/js/runtime/runtime.min.css</url>
      
        <content type="html"><![CDATA[div#runtime {    width: 180px;    margin: auto;    color: #fff;    padding-inline: 5px;    border-radius: 10px;    background-color: rgba(0, 0, 0, .7)}#workboard {    font-size: 12px}[data-theme=dark] div#runtime {    color: #28b4c8;    box-shadow: 0 0 5px rgba(28, 69, 218, .71);    animation: flashlight 1s linear infinite alternate}#ghbdages .github-badge img {    height: 20px}@-moz-keyframes flashlight {    from {        box-shadow: 0 0 5px #1478d2    }    to {        box-shadow: 0 0 2px #1478d2    }}@-webkit-keyframes flashlight {    from {        box-shadow: 0 0 5px #1478d2    }    to {        box-shadow: 0 0 2px #1478d2    }}@-o-keyframes flashlight {    from {        box-shadow: 0 0 5px #1478d2    }    to {        box-shadow: 0 0 2px #1478d2    }}@keyframes flashlight {    from {        box-shadow: 0 0 5px #1478d2    }    to {        box-shadow: 0 0 2px #1478d2    }}]]></content>
      
    </entry>
    
    
  
</search>
